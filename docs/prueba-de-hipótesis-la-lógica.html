<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 11 Prueba de hipótesis: la lógica | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R</title>
  <meta name="description" content="Capítulo 11 Prueba de hipótesis: la lógica | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 11 Prueba de hipótesis: la lógica | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/imagenes/cover.jpg" />
  
  <meta name="github-repo" content="jcrodriguez1989/EstadisticaParaCienciasSocialesConR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 11 Prueba de hipótesis: la lógica | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  
  
  <meta name="twitter:image" content="/imagenes/cover.jpg" />

<meta name="author" content="Eduardo Bologna" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimación-por-intervalo.html"/>
<link rel="next" href="prueba-de-hipótesis-las-aplicaciones.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística para Ciencias Sociales con R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Colaboradores</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#comit%C3%A9-editorial"><i class="fa fa-check"></i>Comité Editorial</a></li>
<li class="chapter" data-level="" data-path=""><a href="#edici%C3%B3n-en-bookdown"><i class="fa fa-check"></i>Edición en bookdown</a></li>
<li class="chapter" data-level="" data-path=""><a href="#revisi%C3%B3n-de-lenguaje-incluyente"><i class="fa fa-check"></i>Revisión de lenguaje incluyente</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#presentaci%C3%B3n"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="presentación.html"><a href="presentación.html"><i class="fa fa-check"></i>Recorridos posibles</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#introducci%C3%B3n"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html"><i class="fa fa-check"></i>Antes de empezar</a>
<ul>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#materiales"><i class="fa fa-check"></i>Materiales</a>
<ul>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-permanente-de-hogares"><i class="fa fa-check"></i>Encuesta Permanente de Hogares</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-nacional-de-factores-de-riesgo"><i class="fa fa-check"></i>Encuesta Nacional de Factores de Riesgo</a></li>
<li class="chapter" data-level="" data-path=""><a href="#latinobar%C3%B3metro"><i class="fa fa-check"></i>Latinobarómetro</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-nacional-sobre-prevalencias-de-consumo-de-sustancias-psicoactivas"><i class="fa fa-check"></i>Encuesta Nacional sobre Prevalencias de Consumo de Sustancias Psicoactivas</a></li>
<li class="chapter" data-level="" data-path=""><a href="#aplicaci%C3%B3n-de-la-escala-de-bayley"><i class="fa fa-check"></i>Aplicación de la escala de Bayley</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#tercera-edad"><i class="fa fa-check"></i>Tercera edad</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#herramientas"><i class="fa fa-check"></i>Herramientas</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#la-elecci%C3%B3n-de-r"><i class="fa fa-check"></i>La elección de R</a></li>
<li class="chapter" data-level="" data-path=""><a href="#instalaci%C3%B3n-de-r-y-rstudio"><i class="fa fa-check"></i>Instalación de R y RStudio</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#los-componentes-de-rstudio"><i class="fa fa-check"></i>Los componentes de RStudio</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#operaciones-en-el-script"><i class="fa fa-check"></i>Operaciones en el script</a></li>
<li class="chapter" data-level="" data-path=""><a href="#instalaci%C3%B3n-de-paquetes"><i class="fa fa-check"></i>Instalación de paquetes</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Estadística Descriptiva</b></span></li>
<li class="chapter" data-level="1" data-path="12-capitulo11.html"><a href="#los-datos-estad%C3%ADsticos"><i class="fa fa-check"></i><b>1</b> Los datos estadísticos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="12-capitulo11.html"><a href="#la-selecci%C3%B3n-de-la-informaci%C3%B3n-pertinente"><i class="fa fa-check"></i><b>1.1</b> La selección de la información pertinente</a></li>
<li class="chapter" data-level="1.2" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html"><i class="fa fa-check"></i><b>1.2</b> Las entidades</a></li>
<li class="chapter" data-level="1.3" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-variables"><i class="fa fa-check"></i><b>1.3</b> Las variables</a></li>
<li class="chapter" data-level="1.4" data-path="12-capitulo11.html"><a href="#las-categor%C3%ADas"><i class="fa fa-check"></i><b>1.4</b> Las categorías</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="12-capitulo11.html"><a href="#requisitos-de-las-categor%C3%ADas"><i class="fa fa-check"></i><b>1.4.1</b> Requisitos de las categorías</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="12-capitulo11.html"><a href="#los-s%C3%ADmbolos-num%C3%A9ricos"><i class="fa fa-check"></i><b>1.5</b> Los símbolos numéricos</a></li>
<li class="chapter" data-level="1.6" data-path="12-capitulo11.html"><a href="#la-medici%C3%B3n"><i class="fa fa-check"></i><b>1.6</b> La medición</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="12-capitulo11.html"><a href="#niveles-de-medici%C3%B3n"><i class="fa fa-check"></i><b>1.6.1</b> Niveles de medición</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="12-capitulo11.html"><a href="#resumen-de-los-niveles-de-medici%C3%B3n"><i class="fa fa-check"></i><b>1.7</b> Resumen de los niveles de medición</a></li>
<li class="chapter" data-level="1.8" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#hacerlo-en-r"><i class="fa fa-check"></i><b>1.8</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#lectura-de-la-base"><i class="fa fa-check"></i><b>1.8.1</b> Lectura de la base</a></li>
<li class="chapter" data-level="1.8.2" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-variables-1"><i class="fa fa-check"></i><b>1.8.2</b> Las variables</a></li>
<li class="chapter" data-level="1.8.3" data-path="12-capitulo11.html"><a href="#los-niveles-de-medici%C3%B3n-en-r"><i class="fa fa-check"></i><b>1.8.3</b> Los niveles de medición en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html"><i class="fa fa-check"></i><b>2</b> Distribuciones de frecuencia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="12-capitulo11.html"><a href="#tablas-de-distribuci%C3%B3n-de-frecuencia"><i class="fa fa-check"></i><b>2.1</b> Tablas de distribución de frecuencia</a></li>
<li class="chapter" data-level="2.2" data-path="12-capitulo11.html"><a href="#recategorizaci%C3%B3n"><i class="fa fa-check"></i><b>2.2</b> Recategorización</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="12-capitulo11.html"><a href="#variable-discreta-con-muchas-categor%C3%ADas"><i class="fa fa-check"></i><b>2.2.1</b> Variable discreta con muchas categorías</a></li>
<li class="chapter" data-level="2.2.2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#variable-continua"><i class="fa fa-check"></i><b>2.2.2</b> Variable continua</a></li>
<li class="chapter" data-level="2.2.3" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#formas-de-recategorizar"><i class="fa fa-check"></i><b>2.2.3</b> Formas de recategorizar</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="12-capitulo11.html"><a href="#la-presentaci%C3%B3n-gr%C3%A1fica-de-los-resultados"><i class="fa fa-check"></i><b>2.3</b> La presentación gráfica de los resultados</a></li>
<li class="chapter" data-level="2.4" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#hacerlo-en-r-1"><i class="fa fa-check"></i><b>2.4</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#tablas-univariadas"><i class="fa fa-check"></i><b>2.4.1</b> Tablas univariadas</a></li>
<li class="chapter" data-level="2.4.2" data-path="12-capitulo11.html"><a href="#recategorizaci%C3%B3n-1"><i class="fa fa-check"></i><b>2.4.2</b> Recategorización</a></li>
<li class="chapter" data-level="2.4.3" data-path="12-capitulo11.html"><a href="#representaciones-gr%C3%A1ficas"><i class="fa fa-check"></i><b>2.4.3</b> Representaciones gráficas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="12-capitulo11.html"><a href="#la-expresi%C3%B3n-resumida-de-la-informaci%C3%B3n"><i class="fa fa-check"></i><b>3</b> La expresión resumida de la información</a>
<ul>
<li class="chapter" data-level="3.1" data-path="12-capitulo11.html"><a href="#medidas-de-posici%C3%B3n"><i class="fa fa-check"></i><b>3.1</b> Medidas de posición</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html"><i class="fa fa-check"></i><b>3.1.1</b> Variables nominales: proporciones</a></li>
<li class="chapter" data-level="3.1.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-tasas"><i class="fa fa-check"></i><b>3.1.2</b> Variables nominales: tasas</a></li>
<li class="chapter" data-level="3.1.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-razones"><i class="fa fa-check"></i><b>3.1.3</b> Variables nominales: razones</a></li>
<li class="chapter" data-level="3.1.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-el-modo"><i class="fa fa-check"></i><b>3.1.4</b> Variables nominales: el modo</a></li>
<li class="chapter" data-level="3.1.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-ordinales-cuantiles"><i class="fa fa-check"></i><b>3.1.5</b> Variables ordinales: cuantiles</a></li>
<li class="chapter" data-level="3.1.6" data-path="12-capitulo11.html"><a href="#variables-m%C3%A9tricas-la-media-o-promedio"><i class="fa fa-check"></i><b>3.1.6</b> Variables métricas: la media o promedio</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="12-capitulo11.html"><a href="#la-forma-de-la-distribuci%C3%B3n"><i class="fa fa-check"></i><b>3.2</b> La forma de la distribución</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="12-capitulo11.html"><a href="#asimetr%C3%ADa"><i class="fa fa-check"></i><b>3.2.1</b> Asimetría</a></li>
<li class="chapter" data-level="3.2.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#curtosis"><i class="fa fa-check"></i><b>3.2.2</b> Curtosis</a></li>
<li class="chapter" data-level="3.2.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#box-plots"><i class="fa fa-check"></i><b>3.2.3</b> Box-plots</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="12-capitulo11.html"><a href="#medidas-de-dispersi%C3%B3n"><i class="fa fa-check"></i><b>3.3</b> Medidas de dispersión</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#recorrido"><i class="fa fa-check"></i><b>3.3.1</b> Recorrido</a></li>
<li class="chapter" data-level="3.3.2" data-path="12-capitulo11.html"><a href="#amplitud-intercuart%C3%ADlica"><i class="fa fa-check"></i><b>3.3.2</b> Amplitud intercuartílica</a></li>
<li class="chapter" data-level="3.3.3" data-path="12-capitulo11.html"><a href="#medidas-de-dispersi%C3%B3n-basadas-en-la-media"><i class="fa fa-check"></i><b>3.3.3</b> Medidas de dispersión basadas en la media</a></li>
<li class="chapter" data-level="3.3.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#varianza"><i class="fa fa-check"></i><b>3.3.4</b> Varianza</a></li>
<li class="chapter" data-level="3.3.5" data-path="12-capitulo11.html"><a href="#desviaci%C3%B3n-est%C3%A1ndar"><i class="fa fa-check"></i><b>3.3.5</b> Desviación estándar</a></li>
<li class="chapter" data-level="3.3.6" data-path="12-capitulo11.html"><a href="#coeficiente-de-variaci%C3%B3n"><i class="fa fa-check"></i><b>3.3.6</b> Coeficiente de variación</a></li>
<li class="chapter" data-level="3.3.7" data-path="12-capitulo11.html"><a href="#box-plots-y-dispersi%C3%B3n"><i class="fa fa-check"></i><b>3.3.7</b> Box-plots y dispersión</a></li>
<li class="chapter" data-level="3.3.8" data-path="12-capitulo11.html"><a href="#medida-de-la-dispersi%C3%B3n-cuando-no-hay-distancias"><i class="fa fa-check"></i><b>3.3.8</b> Medida de la dispersión cuando no hay distancias</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="12-capitulo11.html"><a href="#el-individuo-en-relaci%C3%B3n-a-su-grupo"><i class="fa fa-check"></i><b>3.4</b> El individuo en relación a su grupo</a></li>
<li class="chapter" data-level="3.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#resumen-de-medidas-descriptivas"><i class="fa fa-check"></i><b>3.5</b> Resumen de medidas descriptivas</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="12-capitulo11.html"><a href="#medidas-de-posici%C3%B3n-1"><i class="fa fa-check"></i><b>3.5.1</b> Medidas de posición</a></li>
<li class="chapter" data-level="3.5.2" data-path="12-capitulo11.html"><a href="#medidas-de-dispersi%C3%B3n-1"><i class="fa fa-check"></i><b>3.5.2</b> Medidas de dispersión</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#hacerlo-en-r-2"><i class="fa fa-check"></i><b>3.6</b> Hacerlo en R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="12-capitulo11.html"><a href="#relaci%C3%B3n-entre-variables-los-fundamentos"><i class="fa fa-check"></i><b>4</b> Relación entre variables: los fundamentos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html"><i class="fa fa-check"></i><b>4.1</b> Tablas de contingencia</a></li>
<li class="chapter" data-level="4.2" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#frecuencias-relativas"><i class="fa fa-check"></i><b>4.2</b> Frecuencias relativas</a></li>
<li class="chapter" data-level="4.3" data-path="12-capitulo11.html"><a href="#una-clasificaci%C3%B3n-en-referencia-al-tiempo"><i class="fa fa-check"></i><b>4.3</b> Una clasificación en referencia al tiempo</a></li>
<li class="chapter" data-level="4.4" data-path="12-capitulo11.html"><a href="#la-direcci%C3%B3n-de-la-relaci%C3%B3n"><i class="fa fa-check"></i><b>4.4</b> La dirección de la relación</a></li>
<li class="chapter" data-level="4.5" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#concepto-de-riesgo-relativo"><i class="fa fa-check"></i><b>4.5</b> Concepto de riesgo relativo</a></li>
<li class="chapter" data-level="4.6" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#la-intensidad"><i class="fa fa-check"></i><b>4.6</b> La intensidad</a></li>
<li class="chapter" data-level="4.7" data-path="12-capitulo11.html"><a href="#el-concepto-de-independencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>4.7</b> El concepto de independencia estadística</a></li>
<li class="chapter" data-level="4.8" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#hacerlo-en-r-3"><i class="fa fa-check"></i><b>4.8</b> Hacerlo en R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="12-capitulo11.html"><a href="#relaci%C3%B3n-entre-variables-el-an%C3%A1lisis"><i class="fa fa-check"></i><b>5</b> Relación entre variables: el análisis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="12-capitulo11.html"><a href="#relaciones-entre-variables-vs.-comparaci%C3%B3n-de-grupos"><i class="fa fa-check"></i><b>5.1</b> Relaciones entre variables vs. comparación de grupos</a></li>
<li class="chapter" data-level="5.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html"><i class="fa fa-check"></i><b>5.2</b> Variables nominales</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="12-capitulo11.html"><a href="#coeficientes-de-asociaci%C3%B3n-para-variables-nominales"><i class="fa fa-check"></i><b>5.2.1</b> Coeficientes de asociación para variables nominales</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#variables-de-nivel-ordinal"><i class="fa fa-check"></i><b>5.3</b> Variables de nivel ordinal</a></li>
<li class="chapter" data-level="5.4" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#nivel-intervalar-o-proporcional"><i class="fa fa-check"></i><b>5.4</b> Nivel intervalar o proporcional</a></li>
<li class="chapter" data-level="5.5" data-path="12-capitulo11.html"><a href="#dicotom%C3%ADas-reales-y-artificiales"><i class="fa fa-check"></i><b>5.5</b> Dicotomías reales y artificiales</a></li>
<li class="chapter" data-level="5.6" data-path="12-capitulo11.html"><a href="#niveles-de-medici%C3%B3n-combinados"><i class="fa fa-check"></i><b>5.6</b> Niveles de medición combinados</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="12-capitulo11.html"><a href="#una-variable-dicot%C3%B3mica-real-y-una-proporcional"><i class="fa fa-check"></i><b>5.6.1</b> Una variable dicotómica real y una proporcional</a></li>
<li class="chapter" data-level="5.6.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#una-variable-continua-dicotomizada-y-una-proporcional"><i class="fa fa-check"></i><b>5.6.2</b> Una variable continua dicotomizada y una proporcional</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="12-capitulo11.html"><a href="#resumen-de-coeficientes-de-asociaci%C3%B3n"><i class="fa fa-check"></i><b>5.7</b> Resumen de coeficientes de asociación</a></li>
<li class="chapter" data-level="5.8" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>5.8</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="5.9" data-path="12-capitulo11.html"><a href="#la-forma-de-la-relaci%C3%B3n"><i class="fa fa-check"></i><b>5.9</b> La forma de la relación</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#ordenada-al-origen"><i class="fa fa-check"></i><b>5.9.1</b> Ordenada al origen</a></li>
<li class="chapter" data-level="5.9.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#pendiente"><i class="fa fa-check"></i><b>5.9.2</b> Pendiente</a></li>
<li class="chapter" data-level="5.9.3" data-path="12-capitulo11.html"><a href="#obtenci%C3%B3n-de-la-recta-de-regresi%C3%B3n"><i class="fa fa-check"></i><b>5.9.3</b> Obtención de la recta de regresión</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="12-capitulo11.html"><a href="#la-visualizaci%C3%B3n-de-los-datos"><i class="fa fa-check"></i><b>5.10</b> La visualización de los datos</a></li>
<li class="chapter" data-level="5.11" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#hacerlo-en-r-4"><i class="fa fa-check"></i><b>5.11</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#distancia-chi2"><i class="fa fa-check"></i><b>5.11.1</b> Distancia <span class="math inline">\(\chi^{2}\)</span></a></li>
<li class="chapter" data-level="5.11.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#coeficientes"><i class="fa fa-check"></i><b>5.11.2</b> Coeficientes</a></li>
<li class="chapter" data-level="5.11.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#modelo-lineal"><i class="fa fa-check"></i><b>5.11.3</b> Modelo lineal</a></li>
<li class="chapter" data-level="5.11.4" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#cuarteto-de-anscombe"><i class="fa fa-check"></i><b>5.11.4</b> Cuarteto de Anscombe</a></li>
<li class="chapter" data-level="5.11.5" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#datasaurus"><i class="fa fa-check"></i><b>5.11.5</b> Datasaurus</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II De la descripción a la inferencia</b></span></li>
<li class="chapter" data-level="6" data-path="12-capitulo11.html"><a href="#obtenci%C3%B3n-de-la-muestra"><i class="fa fa-check"></i><b>6</b> Obtención de la muestra</a>
<ul>
<li class="chapter" data-level="6.1" data-path="12-capitulo11.html"><a href="#poblaci%C3%B3n"><i class="fa fa-check"></i><b>6.1</b> Población</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html"><i class="fa fa-check"></i><b>6.1.1</b> Muestra</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="12-capitulo11.html"><a href="#muestreos-probabil%C3%ADsticos"><i class="fa fa-check"></i><b>6.2</b> Muestreos probabilísticos</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-irrestricto-aleatorio-o-aleatorio-simple"><i class="fa fa-check"></i><b>6.2.1</b> Muestreo irrestricto aleatorio o aleatorio simple</a></li>
<li class="chapter" data-level="6.2.2" data-path="12-capitulo11.html"><a href="#muestreo-sistem%C3%A1tico"><i class="fa fa-check"></i><b>6.2.2</b> Muestreo sistemático</a></li>
<li class="chapter" data-level="6.2.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-estratificado"><i class="fa fa-check"></i><b>6.2.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="6.2.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-por-conglomerados"><i class="fa fa-check"></i><b>6.2.4</b> Muestreo por conglomerados</a></li>
<li class="chapter" data-level="6.2.5" data-path="12-capitulo11.html"><a href="#m%C3%A9todo-de-kish"><i class="fa fa-check"></i><b>6.2.5</b> Método de Kish</a></li>
<li class="chapter" data-level="6.2.6" data-path="12-capitulo11.html"><a href="#uso-combinado-de-t%C3%A9cnicas-de-muestreo"><i class="fa fa-check"></i><b>6.2.6</b> Uso combinado de técnicas de muestreo</a></li>
<li class="chapter" data-level="6.2.7" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-de-panel"><i class="fa fa-check"></i><b>6.2.7</b> Muestreo de panel</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="12-capitulo11.html"><a href="#muestreos-no-probabil%C3%ADsticos"><i class="fa fa-check"></i><b>6.3</b> Muestreos no probabilísticos</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-por-cuotas"><i class="fa fa-check"></i><b>6.3.1</b> Muestreo por cuotas</a></li>
<li class="chapter" data-level="6.3.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-de-juicio-o-intencional"><i class="fa fa-check"></i><b>6.3.2</b> Muestreo de juicio o intencional</a></li>
<li class="chapter" data-level="6.3.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-autoelegido"><i class="fa fa-check"></i><b>6.3.3</b> Muestreo autoelegido</a></li>
<li class="chapter" data-level="6.3.4" data-path="12-capitulo11.html"><a href="#muestreo-accidental-o-seg%C3%BAn-disponibilidad"><i class="fa fa-check"></i><b>6.3.4</b> Muestreo accidental o según disponibilidad</a></li>
<li class="chapter" data-level="6.3.5" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-bola-de-nieve"><i class="fa fa-check"></i><b>6.3.5</b> Muestreo bola de nieve</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#hacerlo-en-r-5"><i class="fa fa-check"></i><b>6.4</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#aleatorio-simple"><i class="fa fa-check"></i><b>6.4.1</b> Aleatorio simple</a></li>
<li class="chapter" data-level="6.4.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#estratificado"><i class="fa fa-check"></i><b>6.4.2</b> Estratificado</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html"><i class="fa fa-check"></i><b>7</b> Probabilidad: los fundamentos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#formas-para-asignar-probabilidades"><i class="fa fa-check"></i><b>7.1</b> Formas para asignar probabilidades</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="12-capitulo11.html"><a href="#asignaci%C3%B3n-a-priori"><i class="fa fa-check"></i><b>7.1.1</b> Asignación a priori</a></li>
<li class="chapter" data-level="7.1.2" data-path="12-capitulo11.html"><a href="#asignaci%C3%B3n-a-posteriori"><i class="fa fa-check"></i><b>7.1.2</b> Asignación a posteriori</a></li>
<li class="chapter" data-level="7.1.3" data-path="12-capitulo11.html"><a href="#la-relaci%C3%B3n-entre-asignaci%C3%B3n-a-priori-y-a-posteriori"><i class="fa fa-check"></i><b>7.1.3</b> La relación entre asignación a priori y a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#operando-con-probabilidades"><i class="fa fa-check"></i><b>7.2</b> Operando con probabilidades</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#con-probabilidades-frecuenciales"><i class="fa fa-check"></i><b>7.2.1</b> Con probabilidades frecuenciales</a></li>
<li class="chapter" data-level="7.2.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#con-probabilidades-a-priori"><i class="fa fa-check"></i><b>7.2.2</b> Con probabilidades a priori</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#el-teorema-de-bayes"><i class="fa fa-check"></i><b>7.3</b> El teorema de Bayes</a></li>
<li class="chapter" data-level="7.4" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#variables-aleatorias"><i class="fa fa-check"></i><b>7.4</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html"><i class="fa fa-check"></i><b>8</b> Probabilidad: los modelos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="12-capitulo11.html"><a href="#concepto-de-modelizaci%C3%B3n"><i class="fa fa-check"></i><b>8.1</b> Concepto de modelización</a></li>
<li class="chapter" data-level="8.2" data-path="12-capitulo11.html"><a href="#distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>8.2</b> Distribución binomial</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#esperanza-y-varianza"><i class="fa fa-check"></i><b>8.2.1</b> Esperanza y varianza</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="12-capitulo11.html"><a href="#distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.3</b> Distribución normal</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#cuantiles"><i class="fa fa-check"></i><b>8.3.1</b> Cuantiles</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#la-idea-de-grados-de-libertad"><i class="fa fa-check"></i><b>8.4</b> La idea de grados de libertad</a></li>
<li class="chapter" data-level="8.5" data-path="12-capitulo11.html"><a href="#la-distribuci%C3%B3n-ji-cuadrado-chi2"><i class="fa fa-check"></i><b>8.5</b> La distribución ji cuadrado (<span class="math inline">\(\chi^{2}\)</span>)</a></li>
<li class="chapter" data-level="8.6" data-path="12-capitulo11.html"><a href="#la-distribuci%C3%B3n-t-de-student"><i class="fa fa-check"></i><b>8.6</b> La distribución t de Student</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="12-capitulo11.html"><a href="#la-distribuci%C3%B3n-f"><i class="fa fa-check"></i><b>8.6.1</b> La distribución F</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#hacerlo-en-r-6"><i class="fa fa-check"></i><b>8.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#probabilidades-exactas"><i class="fa fa-check"></i><b>8.7.1</b> Probabilidades exactas</a></li>
<li class="chapter" data-level="8.7.2" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#probabilidades-acumuladas"><i class="fa fa-check"></i><b>8.7.2</b> Probabilidades acumuladas</a></li>
<li class="chapter" data-level="8.7.3" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#cuantiles-1"><i class="fa fa-check"></i><b>8.7.3</b> Cuantiles</a></li>
<li class="chapter" data-level="8.7.4" data-path="12-capitulo11.html"><a href="#%C3%A1reas-centrales"><i class="fa fa-check"></i><b>8.7.4</b> Áreas centrales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html"><i class="fa fa-check"></i><b>9</b> Distribuciones en el muestreo</a>
<ul>
<li class="chapter" data-level="9.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#variabilidad-muestral"><i class="fa fa-check"></i><b>9.1</b> Variabilidad muestral</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#dos-aspectos-importantes-para-recordar-cuando-se-usan-muestras"><i class="fa fa-check"></i><b>9.1.1</b> Dos aspectos importantes para recordar cuando se usan muestras:</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="12-capitulo11.html"><a href="#caracter%C3%ADsticas-de-los-estimadores"><i class="fa fa-check"></i><b>9.2</b> Características de los estimadores</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#insesgabilidad"><i class="fa fa-check"></i><b>9.2.1</b> Insesgabilidad</a></li>
<li class="chapter" data-level="9.2.2" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#consistencia"><i class="fa fa-check"></i><b>9.2.2</b> Consistencia</a></li>
<li class="chapter" data-level="9.2.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#eficiencia"><i class="fa fa-check"></i><b>9.2.3</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#distribuciones-de-probabilidad-de-los-estimadores"><i class="fa fa-check"></i><b>9.3</b> Distribuciones de probabilidad de los estimadores</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="12-capitulo11.html"><a href="#primera-aproximaci%C3%B3n"><i class="fa fa-check"></i><b>9.3.1</b> Primera aproximación</a></li>
<li class="chapter" data-level="9.3.2" data-path="12-capitulo11.html"><a href="#distribuci%C3%B3n-de-la-media-muestral"><i class="fa fa-check"></i><b>9.3.2</b> Distribución de la media muestral</a></li>
<li class="chapter" data-level="9.3.3" data-path="12-capitulo11.html"><a href="#distribuci%C3%B3n-de-la-proporci%C3%B3n-muestral"><i class="fa fa-check"></i><b>9.3.3</b> Distribución de la proporción muestral</a></li>
<li class="chapter" data-level="9.3.4" data-path="12-capitulo11.html"><a href="#muestras-peque%C3%B1as"><i class="fa fa-check"></i><b>9.3.4</b> Muestras pequeñas</a></li>
<li class="chapter" data-level="9.3.5" data-path="12-capitulo11.html"><a href="#distribuci%C3%B3n-de-la-varianza"><i class="fa fa-check"></i><b>9.3.5</b> Distribución de la varianza</a></li>
<li class="chapter" data-level="9.3.6" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#muestreo-desde-dos-poblaciones"><i class="fa fa-check"></i><b>9.3.6</b> Muestreo desde dos poblaciones</a></li>
<li class="chapter" data-level="9.3.7" data-path="12-capitulo11.html"><a href="#distribuci%C3%B3n-del-cociente-de-varianzas"><i class="fa fa-check"></i><b>9.3.7</b> Distribución del cociente de varianzas</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="12-capitulo11.html"><a href="#resumen-de-la-relaci%C3%B3n-entre-estimadores-y-par%C3%A1metros"><i class="fa fa-check"></i><b>9.4</b> Resumen de la relación entre estimadores y parámetros</a></li>
<li class="chapter" data-level="9.5" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#hacerlo-en-r-7"><i class="fa fa-check"></i><b>9.5</b> Hacerlo en R</a></li>
</ul></li>
<li class="part"><span><b>III Estadística inferencial</b></span></li>
<li class="chapter" data-level="10" data-path="12-capitulo11.html"><a href="#estimaci%C3%B3n-por-intervalo"><i class="fa fa-check"></i><b>10</b> Estimación por intervalo</a>
<ul>
<li class="chapter" data-level="10.1" data-path="12-capitulo11.html"><a href="#estimaci%C3%B3n-puntual"><i class="fa fa-check"></i><b>10.1</b> Estimación puntual</a></li>
<li class="chapter" data-level="10.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html"><i class="fa fa-check"></i><b>10.2</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="10.3" data-path="12-capitulo11.html"><a href="#estimaci%C3%B3n-de-la-media"><i class="fa fa-check"></i><b>10.3</b> Estimación de la media</a></li>
<li class="chapter" data-level="10.4" data-path="12-capitulo11.html"><a href="#estimaci%C3%B3n-de-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.4</b> Estimación de la proporción</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-clopper-pearson"><i class="fa fa-check"></i><b>10.4.1</b> Intervalo de Clopper-Pearson</a></li>
<li class="chapter" data-level="10.4.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-wald"><i class="fa fa-check"></i><b>10.4.2</b> Intervalo de Wald</a></li>
<li class="chapter" data-level="10.4.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-wilson"><i class="fa fa-check"></i><b>10.4.3</b> Intervalo de Wilson</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#la-calidad-de-las-estimaciones-por-intervalo"><i class="fa fa-check"></i><b>10.5</b> La calidad de las estimaciones por intervalo</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="12-capitulo11.html"><a href="#el-error-de-estimaci%C3%B3n-en-la-media"><i class="fa fa-check"></i><b>10.5.1</b> El error de estimación en la media</a></li>
<li class="chapter" data-level="10.5.2" data-path="12-capitulo11.html"><a href="#el-error-de-estimaci%C3%B3n-en-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.5.2</b> El error de estimación en la proporción</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#probabilidad-de-cobertura"><i class="fa fa-check"></i><b>10.6</b> Probabilidad de cobertura</a></li>
<li class="chapter" data-level="10.7" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#hacerlo-en-r-8"><i class="fa fa-check"></i><b>10.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-para-la-media"><i class="fa fa-check"></i><b>10.7.1</b> Intervalo para la media</a></li>
<li class="chapter" data-level="10.7.2" data-path="12-capitulo11.html"><a href="#intervalo-para-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.7.2</b> Intervalo para la proporción</a></li>
<li class="chapter" data-level="10.7.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#cobertura"><i class="fa fa-check"></i><b>10.7.3</b> Cobertura</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="12-capitulo11.html"><a href="#prueba-de-hip%C3%B3tesis-la-l%C3%B3gica"><i class="fa fa-check"></i><b>11</b> Prueba de hipótesis: la lógica</a>
<ul>
<li class="chapter" data-level="11.1" data-path="12-capitulo11.html"><a href="#el-razonamiento-de-la-prueba-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>11.1</b> El razonamiento de la prueba de hipótesis</a></li>
<li class="chapter" data-level="11.2" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html"><i class="fa fa-check"></i><b>11.2</b> Prueba sobre la media</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="12-capitulo11.html"><a href="#la-toma-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>11.2.1</b> La toma de decisión</a></li>
<li class="chapter" data-level="11.2.2" data-path="12-capitulo11.html"><a href="#los-puntos-cr%C3%ADticos-en-t%C3%A9rminos-del-estimador"><i class="fa fa-check"></i><b>11.2.2</b> Los puntos críticos en términos del estimador</a></li>
<li class="chapter" data-level="11.2.3" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#pruebas-unilaterales"><i class="fa fa-check"></i><b>11.2.3</b> Pruebas unilaterales</a></li>
<li class="chapter" data-level="11.2.4" data-path="12-capitulo11.html"><a href="#otros-ejemplos-de-prueba-de-hip%C3%B3tesis-sobre-la-media"><i class="fa fa-check"></i><b>11.2.4</b> Otros ejemplos de prueba de hipótesis sobre la media</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="12-capitulo11.html"><a href="#prueba-sobre-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>11.3</b> Prueba sobre la proporción</a></li>
<li class="chapter" data-level="11.4" data-path="12-capitulo11.html"><a href="#tipos-de-error-en-las-pruebas-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>11.4</b> Tipos de error en las pruebas de hipótesis</a></li>
<li class="chapter" data-level="11.5" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#etii-mu-alpha-y-n"><i class="fa fa-check"></i><b>11.5</b> <em>ETII:</em> <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(n\)</span></a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#curva-de-potencia"><i class="fa fa-check"></i><b>11.5.1</b> Curva de potencia</a></li>
<li class="chapter" data-level="11.5.2" data-path="12-capitulo11.html"><a href="#significaci%C3%B3n-estad%C3%ADstica-y-valor-p"><i class="fa fa-check"></i><b>11.5.2</b> Significación estadística y valor <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="12-capitulo11.html"><a href="#muestras-peque%C3%B1as-y-pruebas-t"><i class="fa fa-check"></i><b>11.6</b> Muestras pequeñas y pruebas <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="11.7" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#hacerlo-en-r-9"><i class="fa fa-check"></i><b>11.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-media-1"><i class="fa fa-check"></i><b>11.7.1</b> Prueba sobre la media</a></li>
<li class="chapter" data-level="11.7.2" data-path="12-capitulo11.html"><a href="#prueba-sobre-la-proporci%C3%B3n-1"><i class="fa fa-check"></i><b>11.7.2</b> Prueba sobre la proporción</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#resumen-de-pruebas-sobre-una-muestra"><i class="fa fa-check"></i><b>11.8</b> Resumen de pruebas sobre una muestra</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="12-capitulo11.html"><a href="#prueba-de-hip%C3%B3tesis-las-aplicaciones"><i class="fa fa-check"></i><b>12</b> Prueba de hipótesis: las aplicaciones</a>
<ul>
<li class="chapter" data-level="12.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html"><i class="fa fa-check"></i><b>12.1</b> Muestras independientes</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-de-diferencia-de-medias"><i class="fa fa-check"></i><b>12.1.1</b> Prueba de diferencia de medias</a></li>
<li class="chapter" data-level="12.1.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#muestras-apareadas"><i class="fa fa-check"></i><b>12.1.2</b> Muestras apareadas</a></li>
<li class="chapter" data-level="12.1.3" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#coeficiente-r-de-pearson"><i class="fa fa-check"></i><b>12.1.3</b> Coeficiente r de Pearson</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#hacerlo-en-r-10"><i class="fa fa-check"></i><b>12.2</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-1."><i class="fa fa-check"></i><b>12.2.1</b> Ejemplo 1.</a></li>
<li class="chapter" data-level="12.2.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-2."><i class="fa fa-check"></i><b>12.2.2</b> Ejemplo 2.</a></li>
<li class="chapter" data-level="12.2.3" data-path="12-capitulo11.html"><a href="#aplicaci%C3%B3n-a-los-datos-de-poblaci%C3%B3n-adulta-mayor"><i class="fa fa-check"></i><b>12.2.3</b> Aplicación a los datos de Población Adulta Mayor</a></li>
<li class="chapter" data-level="12.2.4" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-apareada"><i class="fa fa-check"></i><b>12.2.4</b> Prueba apareada</a></li>
<li class="chapter" data-level="12.2.5" data-path="12-capitulo11.html"><a href="#coeficiente-de-correlaci%C3%B3n"><i class="fa fa-check"></i><b>12.2.5</b> Coeficiente de correlación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html"><i class="fa fa-check"></i><b>13</b> Cuando los supuestos no se cumplen</a>
<ul>
<li class="chapter" data-level="13.0.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#las-pruebas-ji-cuadrado-o-chi-cuadrado"><i class="fa fa-check"></i><b>13.0.1</b> Las pruebas ji cuadrado (o chi cuadrado)</a></li>
<li class="chapter" data-level="13.0.2" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#coeficiente-r_s-de-spearman"><i class="fa fa-check"></i><b>13.0.2</b> Coeficiente <span class="math inline">\(r_s\)</span> de Spearman</a></li>
<li class="chapter" data-level="13.0.3" data-path="12-capitulo11.html"><a href="#alternativas-no-param%C3%A9tricas-a-las-pruebas-t"><i class="fa fa-check"></i><b>13.0.3</b> Alternativas no paramétricas a las pruebas t</a></li>
<li class="chapter" data-level="13.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#hacerlo-en-r-11"><i class="fa fa-check"></i><b>13.1</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#ejemplo-1"><i class="fa fa-check"></i><b>13.1.1</b> Ejemplo 1</a></li>
<li class="chapter" data-level="13.1.2" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#ejemplo-2"><i class="fa fa-check"></i><b>13.1.2</b> Ejemplo 2</a></li>
<li class="chapter" data-level="13.1.3" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#prueba-de-la-mediana-1"><i class="fa fa-check"></i><b>13.1.3</b> Prueba de la mediana</a></li>
<li class="chapter" data-level="13.1.4" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#prueba-de-wilcoxon"><i class="fa fa-check"></i><b>13.1.4</b> Prueba de Wilcoxon</a></li>
<li class="chapter" data-level="13.1.5" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#muestras-apareadas-1"><i class="fa fa-check"></i><b>13.1.5</b> Muestras apareadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="12-capitulo11.html"><a href="#tama%C3%B1o-del-efecto"><i class="fa fa-check"></i><b>14</b> Tamaño del efecto</a>
<ul>
<li class="chapter" data-level="14.1" data-path="12-capitulo11.html"><a href="#significaci%C3%B3n-estad%C3%ADstica-y-significaci%C3%B3n-pr%C3%A1ctica"><i class="fa fa-check"></i><b>14.1</b> Significación estadística y significación práctica</a></li>
<li class="chapter" data-level="14.2" data-path="12-capitulo11.html"><a href="#medidas-de-tama%C3%B1o-del-efecto"><i class="fa fa-check"></i><b>14.2</b> Medidas de tamaño del efecto</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html"><i class="fa fa-check"></i><b>14.2.1</b> Prueba t para diferencia de medias</a></li>
<li class="chapter" data-level="14.2.2" data-path="12-capitulo11.html"><a href="#an%C3%A1lisis-de-la-varianza"><i class="fa fa-check"></i><b>14.2.2</b> Análisis de la varianza</a></li>
<li class="chapter" data-level="14.2.3" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#correlaciones"><i class="fa fa-check"></i><b>14.2.3</b> Correlaciones</a></li>
<li class="chapter" data-level="14.2.4" data-path="12-capitulo11.html"><a href="#regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>14.2.4</b> Regresión lineal</a></li>
<li class="chapter" data-level="14.2.5" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#pruebas-ji-cuadrado"><i class="fa fa-check"></i><b>14.2.5</b> Pruebas ji cuadrado</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="12-capitulo11.html"><a href="#an%C3%A1lisis-de-la-potencia"><i class="fa fa-check"></i><b>14.3</b> Análisis de la potencia</a></li>
<li class="chapter" data-level="14.4" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#hacerlo-en-r-12"><i class="fa fa-check"></i><b>14.4</b> Hacerlo en R</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Generado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prueba-de-hipótesis-la-lógica" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Capítulo 11</span> Prueba de hipótesis: la lógica<a href="#prueba-de-hip%C3%B3tesis-la-l%C3%B3gica" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En este capítulo ingresamos a uno de los procedimientos de mayor difusión en investigación cuantitativa: la prueba de hipótesis, que se en los mismos principios de estimación de parámetros que fundamentan la construcción de intervalos de confianza, por lo que su objetivo también es hacer uso de resultados muestrales para obtener conocimiento acerca de la población. Este procedimiento no está exento de críticas <span class="citation">Greenland (<a href="#ref-greenland2019">2019</a>)</span>; sin embargo es básico para hacer inferencias sobre la población y conserva amplia difusión tanto en ciencias sociales como naturales, <span class="citation">(<a href="#ref-Halsey2019">Halsey 2019</a>)</span>. Las propuestas que existen como técnicas alternativas que superan las falencias que acusan sus críticos <span class="citation">(<a href="#ref-Goedhart2018">Goedhart 2018</a>)</span>, requieren que se tenga dominio de las pruebas de hipótesis.</p>
<div id="el-razonamiento-de-la-prueba-de-hipótesis" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> El razonamiento de la prueba de hipótesis<a href="#el-razonamiento-de-la-prueba-de-hip%C3%B3tesis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La prueba de hipótesis tiene como objetivo el de proveer argumentos para
decidir en contextos de incertidumbre. A partir de lo que sabemos sobre
las distribuciones en el muestreo, ése es el caso cuando necesitamos
concluir acerca de una población, a partir de información que tenemos
disponible en una muestra aleatoria. El resultado de la prueba permitirá
decidir si lo que se observa en la muestra es compatible con una
aseveración hipotética sobre la población. Nunca será posible decidir de
manera taxativa que la hipótesis es verdadera, eso es algo que no
podemos saber; por el contrario, podemos ver hasta qué punto lo que
observamos en la muestra contradice -o no- lo que se afirma a escala
poblacional. Es decir que podremos descartar una hipótesis por no ser
compatible con lo que se observa, pero no a la inversa: no será posible
“confirmar” una hipótesis, solo podremos concluir que la evidencia <em>no la contradice</em>, lo que también se expresa diciendo que <em>no hay evidencia para rechazarla</em>.</p>
<p>Empezaremos con ejemplos no muy cercanos a la investigación social cuantitativa, para mostrar que esta forma de razonar no es ajena a lo cotidiano. Una prueba de hipótesis puede compararse con un juicio penal: la persona acusada no es condenada hasta que no hay evidencia suficiente para hacerlo. La evidencia (las pruebas, en el lenguaje de la justicia) rara vez son completas, se trata de información fragmentada, sujeta a interpretaciones diferentes. En el inicio del juicio, “la persona acusada es inocente”, en nuestra notación llamaremos a esa afirmación, <strong>hipótesis nula</strong>, y la indicaremos <span class="math inline">\(H_{0}\)</span>. Esta expresión indica que se trata de un estado inicial: toda persona es inocente hasta que se prueba lo contrario, por lo que la hipótesis nula señala que esta persona en particular (la acusada), no es diferente de cualquiera que no ha cometido delito. Mientras no haya pruebas suficientes, la hipótesis nula se considerará aceptada. En el juicio, la fiscalía aportará pruebas en dirección contraria a esta hipótesis. Buscará información para probar que debe rechazarse la hipótesis nula y condenar a la persona acusada. Difícilmente estarán a la vista
todos los datos necesarios para reconstruir la situación y dar una
respuesta absolutamente inequívoca, pero si hay suficiente evidencia, se dará la hipótesis nula por rechazada. La decisión de condenar a la persona acusada solo se tomará cuando haya muy poco riesgo de equivocarse, cuando la probabilidad de decidir de manera errada sea muy pequeña.</p>
<p>En este ejemplo, la población es el conjunto completo de información necesaria para tomar la decisión de manera certera, sin error. Se trataría de un conjunto infinito de datos que permitiría la reconstrucción exacta de los hechos en los que participó la persona acusada. Por cierto, esa información nunca está disponible, por lo que la decisión debe tomarse a partir de un fragmento de ella, que son las pruebas que han podido reunirse (la evidencia). En la analogía que hacemos con nuestros procedimientos, esta evidencia constituye la
muestra a partir de la que se juzgará la hipótesis nula: rechazarla o no
rechazarla. La muestra constituye el fragmento de información
disponible, solo que en el caso de la estimación, ésta es obtenida con
procedimientos que buscan su representatividad.</p>
<p>Otro ejemplo: tenemos dudas sobre lo equilibrada que pueda estar una
moneda que va a usarse en un juego de azar. Repitiendo la notación del
ejemplo anterior, formularemos una hipótesis nula que dice que X sale
con la misma frecuencia que C, que equivale a decir que hasta que no se
pruebe lo contrario, X no tiene ninguna diferencia con C, la moneda está
equilibrada. Esta hipótesis nula puede escribirse de manera formal,
porque “salir con la misma frecuencia que C” equivale a decir que, “en
infinitas tiradas, la mitad de la veces saldrá X”, por lo que
escribiremos nuestra hipótesis nula así: <span class="math inline">\(H_0: P=1/2\)</span>, a la que leeremos
“la hipótesis nula afirma que la proporción de veces que saldrá cara es
1/2”. Como no es posible arrojar la moneda infinitas veces, generamos un conjunto de datos para hacer la prueba, tirando al moneda un nùmero finito de veces, digamos cien veces, esa es la muestra de tiradas.<br />
Al arrojarla 100 veces esperaríamos -si la hipótesis nula se sostiene-, que
salga aproximadamente 50 veces X. Las 100 tiradas son una muestra de las
infinitas tiradas de la moneda, por lo que posiblemente no salga
exactamente 50 veces X, podría salir 51 veces ó 52 y serían resultados
esperables, debido a fluctuaciones propias del azar. Pero si de las 100
tiradas sale 80 veces X, concluiremos con pocas dudas que hay que
rechazar la hipótesis nula. A la misma conclusión llegaríamos si, de 100
tiradas, solo sale 25 veces X. La pregunta que nos ayudará a responder
el procedimiento de prueba de hipótesis es ¿cuántas más o menos veces
que 50 debería salir X para que consideremos que tenemos “suficiente
evidencia”, para creer que la moneda no está equilibrada?</p>
<p>La lógica de la prueba de hipótesis consiste en plantear el escenario en el que <span class="math inline">\(H_{0}\)</span> es verdadera y observar cuán probable es lo que hallamos en la muestra en ese caso. En el primer ejemplo el planteo es ¿cuán probable sería haber hallado <em>estas pruebas</em> (la evidencia) contra la persona acusada, si ésta fuera inocente? En el segundo preguntamos ¿cuán probable habría sido hallar <em>esta cantidad de veces</em> que salió <span class="math inline">\(X\)</span>, si la moneda estuviera equilibrada? De manera general la pregunta es ¿cuán probable sería <em>éste resultado muestral</em> si la hipótesis nula fuera cierta?</p>
<p>Si la respuesta a esas preguntas es “muy probable”, la decisión será la
de no rechazar la hipótesis nula, porque los resultados muestrales
hallados serían esperables (muy probables) bajo <span class="math inline">\(H_{0}\)</span>. Al contrario, si la respuesta es “muy poco probable” decidiremos rechazar <span class="math inline">\(H_{0}\)</span>, ya que se trata de un resultado poco esperable si <span class="math inline">\(H_{0}\)</span> fuera cierta.</p>
<p>En investigación, la prueba de hipótesis suele formularse de tal modo
que rechazar <span class="math inline">\(H_{0}\)</span> implica aportar un nuevo hallazgo, por el contrario, no rechazar <span class="math inline">\(H_{0}\)</span> equivale a que no hay cambios respecto de alguna situación inicial.</p>
<p>Algunos ejemplos de hipótesis nulas:</p>
<ul>
<li><p>Esta droga no produce ningún efecto sobre la memoria.</p></li>
<li><p>La técnica terapéutica A es igualmente eficaz que la B.</p></li>
<li><p>Los métodos A y B para enseñar a leer en la escuela primaria producen iguales resultados.</p></li>
<li><p>La proporción de votos que obtendrá un partido politico no ha variado respecto de las últimas elecciones.</p></li>
<li><p>Un programa de potabilización de agua no reduce la diarrea infantil.</p></li>
<li><p>La edad no hace diferencia en las orientaciones políticas de las personas.</p></li>
<li><p>Un plan de capacitación para madres que se ha implementado no tiene efecto en el desarrollo de sus hijas o hijos.</p></li>
</ul>
<p>En casi todos los casos, la expectativa de la investigación está en
rechazar la <span class="math inline">\(H_{0}\)</span>, porque eso significa que se ha hallado algo de interés: que la droga produce efectos, que hay técnicas terapéuticas mejores que otras y por tanto recomendables, que se pueden elegir mejores métodos para enseñar a leer, que el favor del electorado hacia un partido político es más o menos extendido, que el programa de potabilización mejoró la salud infantil, que la edad es un factor explicativo de las diferencias ideológicas, que el plan de capacitación impactó (positivamente).</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">La hipótesis nula es una <strong>afirmación</strong> sobre un <strong>parámetro</strong> que indica ausencia de diferencia en ralción a cierto valor de referencia.</td>
</tr>
</tbody>
</table>
<p>El sentido de esa diferencia difiere según el tipo de prueba, veremos
que hay pruebas que confrontan con valores históricos o con promedios
generales o bien que realizan comparaciones entre grupos. En todos los
casos la hipótesis nula afirma algo que puede expresarse como “no hay
diferencia”, o “no hay cambio” o “no hay relación”.</p>
<p>Hasta este punto se trata de la definición original de estas pruebas,
desarrolladas inicialmente por Sir Ronald <span class="citation">Fisher (<a href="#ref-Fisher">1925</a>)</span> a las que llamó
<em>pruebas de significación</em>. La idea básica es la de comparar los datos
observados con la hipótesis que se pone a prueba. Fisher las ideó como
manera de medir el grado de incompatibilidad de un conjunto de datos con la hipótesis nula, evaluando la probabilidad de hallar resultados como los observados o más extremos, si la hipótesis nula fuera cierta. Si esa probabilidad es muy pequeña, puede suceder que la muestra que se
seleccionó haya sido excepcional, o bien que la afirmación hipotética
sea falsa. Fisher argumentó que se trataba de un método objetivo para
poner a prueba teorías y que puede ser usado en diferentes campos de
conocimiento.</p>
<p>Con posterioridad a Fisher, <span class="citation">Neyman and Pearson (<a href="#ref-neyman1928">1928</a>)</span> introducen dos
cambios importantes en el procedimiento.</p>
<ul>
<li><p>El primero consiste en tratar a las prueba no ya como métodos para
validar teorías, sino como reglas de decisión, es decir, criterios que
permiten decidir en las situaciones en que no se cuenta con toda la
información necesaria.</p></li>
<li><p>El segundo cambio consiste en oponer a la hipótesis nula, otra hipótesis, llamada hipótesis alternativa, a la que se indica como <span class="math inline">\(H_{1}\)</span>, que es hacia la que se suma evidencia cuando se rechaza <span class="math inline">\(H_{0}\)</span>.</p></li>
</ul>
<p>Veamos la aplicación de este modelo, que es el que usaremos a partir de
ahora. La afirmación “los niños y las niñas que provienen de hogares con alto nivel de educación tienen rendimiento en la escuela superior al promedio general” es una hipótesis, porque pretende tener carácter general, hace
referencia a la población de quienes están en la escuela, quienes asisten ahora y quienes asistirán en el futuro; no podemos observar a la población completa, por lo tanto la hipótesis no puede probarse de manera definitiva, solo puede hacerse a partir de una muestra. Para formalizar
esa hipótesis, construiremos una <span class="math inline">\(H_{0}\)</span> que niegue cualquier diferencia: “el rendimiento de los niños y las niñas que provienen de hogares de alto nivel educativo es el mismo que el del promedio”. A esta hipótesis, opondremos otra, que afirme “los niños y las niñas que provienen de hogares de alto nivel educativo tienen rendimiento superior al promedio”. A esta última llamaremos hipótesis alternativa, <span class="math inline">\(H_{1}\)</span>. Así formalizamos el planteo del problema.</p>
<p>Supongamos ahora que conocemos ese rendimiento promedio, medido por el
puntaje en las pruebas y que vale 60 puntos para la población completa
de estudiantes, de un nivel determinado al que se acota la investigación. De modo que podemos formular las hipótesis ahora así:</p>
<p><span class="math inline">\(H_{0}\)</span>: “El rendimiento promedio de los niños y las niñas que provienen de hogares de alto nivel educativo es de 60 puntos”</p>
<p><span class="math inline">\(H_{1}\)</span>: “El rendimiento promedio de los niños y las niñas que provienen de hogares de alto nivel educativo es superior a 60 puntos”</p>
<p>Para poner a prueba la hipótesis tomaremos una muestra de niños y niñas que provienen de hogares de alto nivel educativo y veremos si su rendimiento es superior a 60 puntos. Supongamos que en la muestra hallamos una media de 62 puntos, ¿hay razón suficiente para rechazar la <span class="math inline">\(H_{0}\)</span>? La respuesta no es inmediata, porque, si bien 62 es mayor que 60, una diferencia de solo 2 puntos parece demasiado pequeña y podríamos atribuirla al azar. Aquí nos interesa evaluar la probabilidad de ocurrencia del resultado que se
observa, si la hipótesis nula fuera cierta. En este caso será: “Si quienes provienen de familias con alto nivel de educación tuvieran el mismo rendimiento que el promedio (<span class="math inline">\(H_{0}\)</span> verdadera), entonces una diferencia de 2 puntos en el promedio muestral es probable, es esperable, puede deberse a la variabilidad propia de los datos muestrales. En consecuencia, esa diferencia no es suficiente para rechazar la <span class="math inline">\(H_{0}\)</span>”. En otros términos: “Si quienes vienen de familias con mucha educación tuvieran un rendimiento promedio de 60 puntos, no sería de extrañar que una muestra arroje un resultado de 62 puntos”. Dicho de otro modo: el resultado muestral no se aleja tanto de lo que esperaríamos si la <span class="math inline">\(H_{0}\)</span> fuera cierta, por lo tanto, no podemos rechazarla y concluimos que los niños y las niñas que provienen de hogares de alto nivel educativo no difieren en su rendimiento escolar del promedio general.</p>
<p>Un elemento de mucha importancia es recordar que la hipótesis hace
referencia a la población, mientras que la información disponible es muestral, y sabemos que los resultados muestrales difieren de los valores paramétricos porque son variables aleatorias.</p>
<p>¿Qué habría sucedido si hubiésemos observado que el grupo de quienes vienen de familias muy educadas tiene un rendimiento promedio de 95
puntos? Este resultado se aleja mucho de 60 que es el que sostiene <span class="math inline">\(H_{0}\)</span>, es decir, si el hipotético fuera verdadero, sería muy poco probable hallar una muestra que promedie 95 puntos. En consecuencia seguramente rechazaríamos la <span class="math inline">\(H_{0}\)</span>.</p>
<p>Al realizar pruebas de hipótesis, en lugar de evaluar intuitivamente si
un valor muestral está cerca o lejos del valor hipotético, lo que
haremos será evaluar cuál sería la probabilidad de hallarlo si fuera
cierta la hipótesis nula. Cuando esta probabilidad sea grande no habrá
evidencia para rechazarla, cuando sea pequeña decidiremos rechazarla.
¿Cuán grande o pequeña? Es de lo que nos ocuparemos a continuación.</p>
<p>Para realizar una prueba de hipótesis, necesitamos calcular la
probabilidad del valor observado, si <span class="math inline">\(H_{0}\)</span> fuera cierta, es decir, si el
parámetro tuviera ese valor (el que señala <span class="math inline">\(H_{0}\)</span>). Es una probabilidad condicional que podemos por ahora escribir así:</p>
<p><span class="math display">\[P(observado/la\:hipotesis\:nula\:es\:verdadera)\]</span></p>
<p>Luego haremos más precisa esta expresión.</p>
<p>Comenzaremos con el ejemplo de una prueba de hipótesis sobre la media de una variable cuantitativa y luego acerca de la proporción para una
categoría de una variable nominal.</p>
</div>
<div id="prueba-sobre-la-media" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Prueba sobre la media<a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-media" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ejemplo (datos ficticios): para una determinada carrera universitaria,
el tiempo promedio para completarla ha sido, históricamente, de 7.30 años. Decimos históricamente para indicar que son datos acumulados
por largo tiempo y que provienen de los registros de la facultad de años atrás. Se ha introducido un cambio en el plan de estudios de la carrera
y puede creerse que con esa modificación, el tiempo para terminar la carrera haya cambiado. Tenemos entonces un promedio de la población de
quienes se recibieron en las anteriores condiciones, es una media
poblacional porque describe al conjunto completo de quienes se recibieron con ese plan, que ya caducó. El objetivo es hacer inferencia sobre la media
poblacional de quienes cursan con el nuevo plan, que no son totalmente accesibles, porque hay quienes están cursando y quienes lo harán en el futuro (porque el nuevo plan seguirá vigente durante los próximos años), por lo que de esa población solo puede conocerse a una muestra de quienes ya han egresado y ver cuánto tiempo han tardado en terminar la carrera.</p>
<p>La hipótesis nula es:</p>
<p><span class="math display">\[H_{0}:\mu = 7.30\]</span>
A la que oponemos una hipótesis alternativa:</p>
<p><span class="math display">\[H_{1}:\mu \neq 7.30\]</span></p>
<p>La hipótesis nula indica que la media poblacional de quienes
cursan con el nuevo plan es la misma que antes, que no hay diferencia,
que no hay cambios. La hipótesis alternativa afirma lo contrario: que el tiempo promedio que tardan en terminar la carrera quienes la cursan con el nuevo plan es diferente a los 7.30 años históricos. No anticipamos si aumentó o disminuyó el tiempo para recibirse, solo que no es el mismo que con el plan viejo.</p>
<p>Ambas son afirmaciones sobre la población (sobre el parámetro media poblacional), por eso son hipótesis.</p>
<p>Si la hipótesis nula fuera cierta, por lo que sabemos sobre las
distribuciones en el muestreo, la siguiente sería la distribución de las medias muestrales:</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-497"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-497-1.svg" alt="Distribución de las medias muestrales bajo la hipótesis nula" width="672" />
<p class="caption">
Figura 11.1: Distribución de las medias muestrales bajo la hipótesis nula
</p>
</div>
<p>La campana está centrada en la media hipotética, que es el escenario en el que <span class="math inline">\(H_{0}\)</span> es verdadera. La probabilidad que la curva asigna a los diferentes valores de <span class="math inline">\(\overline{x}\)</span>, quiere decir que “lo más probable” sería hallar a la media muestral (la única que tendremos como dato) alrededor de 7.30. Hay poca probabilidad de encontrar valores muy
lejanos a 7.30, como lo muestran las áreas decrecientes, a medida que
nos alejamos de la media hipotética. Por esta razón, para decidir si un
resultado muestral se aleja mucho o poco del valor paramétrico,
deberemos determinar si es poco probable o muy probable. Será
equivalente decir que un valor se aleja mucho de la media hipotética que decir que se trataría de un valor poco probable, si la media fuera la que propone la <span class="math inline">\(H_{0}\)</span>.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Afirmar que un valor muestral <strong>se aleja mucho del valor poblacional</strong> equivale a decir que <strong>sería muy poco probable si el valor poblacional fuera el hipotético</strong>.</td>
</tr>
</tbody>
</table>
<p>A fin de realizar la prueba de hipótesis debemos obtener una muestra.
Supongamos que seleccionamos 100 personas que han terminado la carrera (usando un muestreo irrestricto aleatorio) y que encontramos un tiempo promedio ha sido de 7.50 años con una desviación estándar de 1.30
años (<span class="math inline">\(\overline{x} = 7.50\)</span> y <span class="math inline">\(s = 1.30\)</span>). Debemos tener un criterio
para decidir si este valor observado es compatible con la hipótesis nula (<span class="math inline">\(\mu = 7.30\)</span>) o si constituye evidencia suficiente para rechazarla en favor de la hipótesis alternativa (<span class="math inline">\(\mu \neq 7.30\)</span>). El criterio es el de ver cuán probable sería este valor observado si la hipótesis nula fuera cierta. En consecuencia, debemos calcular la probabilidad que tiene <span class="math inline">\(\overline{x}\)</span> de asumir el valor observado. Sin embargo, no es posible hallar probabilidades para valores únicos de una variable continua, por lo que buscaremos la probabilidad de hallar valores como el observado (<span class="math inline">\(\overline{x}=7.50\)</span>) <em>o más extremos que él</em>. Esto significa que nos preguntamos por la probabilidad que tiene la variable <span class="math inline">\(\overline{x}\)</span> de asumir el valor 7.50 <em>o uno más extremo</em>, -es decir un valor que se aleje más de la media hipotética-, si <span class="math inline">\(H_{0}\)</span> es verdadera. Tengamos muy presente que:</p>
<p><strong>alejado <span class="math inline">\(\rightarrow\)</span> poco probable si <span class="math inline">\(H_{0}\)</span> fuera cierta</strong></p>
<p>Por eso, los valores alejados se encuentran en los extremos de la distribución de <span class="math inline">\(\overline{x}\)</span>, bajo el supuesto de <span class="math inline">\(H_{0}\)</span> verdadera (es decir, centrada en la media hipotética).</p>
<p>Para decidir si la evidencia hallada en la muestra es suficiente para
rechazar la hipótesis nula, vamos a establecer a priori un valor máximo
para la probabilidad de ocurrencia del valor muestral, o lo que es lo
mismo, un valor máximo para el área extrema donde consideraremos que se
encuentran los valores “alejados”.</p>
<p><strong>¿cuán alejado? <span class="math inline">\(\rightarrow\)</span> ¿cuán poco probable?</strong></p>
<div id="la-toma-de-decisión" class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> La toma de decisión<a href="#la-toma-de-decisi%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La <span class="math inline">\(H_{0}\)</span> se rechaza si hay poca probabilidad de hallar un valor como el observado o uno más extremo que él. Lo que llamamos poca probabilidad,
puede establecerse a priori, por ejemplo en 0.05. Eso indica que
consideraremos a los resultados con probabilidad menor a 0.05 como muy
improbables de hallar si <span class="math inline">\(H_{0}\)</span> fuera cierta y, cuando los hallemos, la decisión será
rechazarla. Por el contrario, si encontramos valores cuya probabilidad
de ocurrencia es superior a 0.05, los trataremos como valores esperables y nos conducirán a no rechazar la <span class="math inline">\(H_{0}\)</span>.</p>
<p>Como sabemos de la distribución normal, los valores de <span class="math inline">\(z = \pm 1.96\)</span> delimitan un área central de 95%, es decir que dejan fuera un área de 5%. Los valores de <span class="math inline">\(z\)</span> superiores a 1.96 ó inferiores a -1.96 tienen una probabilidad de ocurrencia de 0.05, repartida en las dos “colas” de la distribución normal.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-498"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-498-1.svg" alt="Áreas extremas que totalizan una probabilidad de 0.05" width="672" />
<p class="caption">
Figura 11.2: Áreas extremas que totalizan una probabilidad de 0.05
</p>
</div>
<p>Los valores de <span class="math inline">\(\overline{x}\)</span> que correspondan a puntajes <em>z</em> que
superen a 1.96 ó sean inferiores a -1.96 serán valores con probabilidad
menor a 0.05, por lo que serán considerados como poco probables y
conducirán a rechazar <span class="math inline">\(H_{0}\)</span>. Por el contrario, los valores que tengan <span class="math inline">\(z\)</span> comprendido entre -1.96 y 1.96 serán probables y llevarán a no rechazar <span class="math inline">\(H_{0}\)</span>. Estos dos puntos (-1.96 y 1.96) se denominan <strong>valores críticos</strong> de <span class="math inline">\(z\)</span> y se indican con un subíndice: <span class="math inline">\(z_{c}\)</span>.</p>
<p>En nuestro ejemplo, el valor observado es <span class="math inline">\(\overline{x} = 7.50\)</span>, de aquí en adelante lo llamaremos <span class="math inline">\({\overline{x}}_{obs}\)</span> (el valor de la
media observado en la muestra). El puntaje <span class="math inline">\(z\)</span> equivalente a ese
<span class="math inline">\({\overline{x}}_{obs}\)</span> se llama <span class="math inline">\(z\)</span> observado, se indica como <span class="math inline">\(z_{obs}\)</span>, y vale:</p>
<p><span class="math display">\[z_{obs} = \frac{{\overline{x}}_{obs} - \mu}{\frac{s}{\sqrt{n}}} = \frac{7.50 - 7.30}{\frac{1.30}{\sqrt{100}}} = 1.54\]</span></p>
<p>Se trata de la transformación a puntaje <span class="math inline">\(z\)</span> del valor observado de la
media muestral, que mide a cuántas desviaciones estándar se encuentra <span class="math inline">\(\bar{x}\)</span> de la media hipotética <span class="math inline">\(\mu\)</span>. Se conoce con el nombre de <strong>estadístico de prueba</strong>.</p>
<p>Este puntaje no está en la zona extrema, porque no va más allá de 1.96;
por el contrario, está entre -1.96 y 1.96 que pertenece a la parte de
valores centrales de la distribución, los más probables. En
consecuencia, la decisión es la de no rechazar <span class="math inline">\(H_{0}\)</span> y concluir que no hay evidencia para creer que el tiempo se tarda en completar la carrera haya cambiado respecto del valor histórico. Dicho de otra manera, el valor observado de
<span class="math inline">\({\overline{x}}_{obs} = 7.50\)</span> es un resultado esperable si la
media poblacional fuera de <span class="math inline">\(7.30\)</span>. Una media muestral de <span class="math inline">\(7.50\)</span> es compatible con una media problacional de <span class="math inline">\(7.30\)</span>.</p>
<p>Por la forma en que hemos razonado y tomado la decisión, se comprende
que a los valores de <span class="math inline">\(z\)</span> comprendidos entre -1.96 y 1.96 se los denomine <strong>zona de no rechazo de <span class="math inline">\(H_{0}\)</span></strong>. El otro conjunto de valores de <span class="math inline">\(z\)</span>, los mayores a 1.96 junto a los menores a -1.96, constituyen la <strong>zona de rechazo de <span class="math inline">\(H_{0}\)</span></strong>.</p>
<p>Luego de haber considerado a 0.05 como la probabilidad a la que llamamos “pequeña”, quedaron determinados los
valores de <span class="math inline">\(z_{c}\)</span> que indican las zonas de rechazo y de no rechazo.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">La <strong>zona de rechazo de <span class="math inline">\(H_{0}\)</span></strong> es el conjunto de valores extremos de la distribución, donde es poco probable encontrar los valores muestrales si <span class="math inline">\(H_{0}\)</span> es verdadera.</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">La <strong>zona de no rechazo de <span class="math inline">\(H_{0}\)</span></strong> es el conjunto de valores centrales de la distribución, donde es más probable encontrar los valores muestrales si <span class="math inline">\(H_{0}\)</span> es verdadera. Es el conjunto de valores muestrales que son compatibles con el valor paramétrico que sostiene la <span class="math inline">\(H_{0}\)</span>.</td>
</tr>
</tbody>
</table>
<p>Luego de eso, el procedimiento que seguimos fue: calcular el puntaje <span class="math inline">\(z\)</span> que corresponde al valor observado de <span class="math inline">\(\overline{x}\)</span>, y luego ver si éste se encuentra en la zona de rechazo o de no rechazo de <span class="math inline">\(H_{0}\)</span>.</p>
<p>La probabilidad 0.05 como valor pequeño fue una elección y podría haber
sido diferente; ese número tiene una larga tradición histórica, Fisher
lo usaba regularmente, aunque aclarando que no era obligatorio y que no
hay nada especial para elegirlo<a href="#fn69" class="footnote-ref" id="fnref69"><sup>69</sup></a>. Se conoce como <strong>nivel de significación</strong> y se indica con la letra <span class="math inline">\(\alpha\)</span> (alfa). Es la
probabilidad de hallar un valor como el observado o más extremo que él,
si la hipótesis nula fuera cierta, por lo que es una probabilidad
condicional que ahora escribimos como:</p>
<p><span class="math display">\[P(z\leq -1.96 \cup z\geq 1.96 / H_{0} V)=0.05\]</span></p>
<p>De esta expresión es importante recordar que <span class="math inline">\(\alpha\)</span> mide la probabilidad de hallar a <span class="math inline">\(z\)</span> en la región de rechazo (más allá de los puntos críticos) si <span class="math inline">\(H_{0}\)</span> es verdadera.</p>
<p>El valor que elijamos para <span class="math inline">\(\alpha\)</span> indica a qué valores vamos a considerar como poco probables: en este caso se trata de valores tan poco probables como el 5%. Puede usarse un nivel de significación diferente, por ejemplo del 10% y los valores críticos de <span class="math inline">\(z\)</span> serán diferentes. En efecto los puntos que dejan un área extrema del 10% son <span class="math inline">\(z_{c}=\pm1.64\)</span>.</p>
<p>En ese caso escribiremos:</p>
<p><span class="math display">\[P(z\leq -1.64 \cup z\geq 1.64 / H_{0} V)=0.10\]</span></p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Se llama <strong>nivel de significación</strong> a la probabilidad de hallar al valor muestral en la zona de rechazo de <span class="math inline">\(H_{0}\)</span>, si <span class="math inline">\(H_{0}\)</span> es verdadera. Se indica como <span class="math inline">\(\alpha\)</span>, y es elegido por el equipo de investigación.</td>
</tr>
</tbody>
</table>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-499"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-499-1.svg" alt="Áreas extremas que totalizan una probabilidad de 0.10" width="672" />
<p class="caption">
Figura 11.3: Áreas extremas que totalizan una probabilidad de 0.10
</p>
</div>
<p>Por lo que, si el nivel de significación es <span class="math inline">\(0.10\)</span> (<span class="math inline">\(\alpha=0.10\)</span>), la zona de no rechazo de <span class="math inline">\(H_{0}\)</span> es el conjunto de valores <span class="math inline">\(z\)</span> comprendidos entre -1.64 y 1.64 (centrales), mientras que la zona de rechazo de <span class="math inline">\(H_{0}\)</span> son los <span class="math inline">\(z\)</span> menores a -1.64 y los mayores a 1.64 (los valores extremos cuya probabilidad es el área sombreada en el gráfico). El valor muestral del ejemplo (<span class="math inline">\(z_{obs} = - 1.54\)</span>) está también en la zona de no rechazo para este nivel, por lo que tampoco se rechaza la <span class="math inline">\(H_{0}\)</span> a un nivel de significación de 0.10.</p>
<p>Otro nivel de significación que suele usarse es del 1%. Para él, los
valores de <span class="math inline">\(z\)</span> son <span class="math inline">\(\pm2.56\)</span>, por lo que la regla de decisión será: “si el valor de <span class="math inline">\(z\)</span> correspondiente al valor observado de <span class="math inline">\(\overline{x}\)</span> está entre -2.56 y 2.56 no se debe rechazar la <span class="math inline">\(H_{0}\)</span>, mientras que si es menor a -2.56 o superior a 2.56 sí debe rechazarse la <span class="math inline">\(H_{0}\)</span>.</p>
<p>Expresamos la probabilidad condicional como:</p>
<p><span class="math display">\[P(z\leq -2.56 \cup z\geq 2.56 / H_{0} V)=0.01\]</span></p>
<p>Al igual que en los casos anteriores, cuando se expresan en términos de
puntajes <em>z</em>, estos valores son fijos; no dependen de los resultados
muestrales que se encuentren, constituyen una regla de decisión
establecida a priori.<br />
Cuanto más pequeño se elige <span class="math inline">\(\alpha\)</span>, tanto más exigente
es la prueba, en el sentido de que solo rechaza la hipótesis de
no-diferencia si se observan valores muy alejados del hipotético. Por el contrario, un <span class="math inline">\(\alpha=0.10\)</span> se considera un nivel tolerante, porque demanda menos alejamiento para decidir rechazar la <span class="math inline">\(H_0\)</span>.</p>
<p>De manera general, si llamamos <span class="math inline">\(z_{\alpha/2}\)</span> al puntaje <span class="math inline">\(z\)</span> que corresponde a un área acumulada de <span class="math inline">\(\alpha/2\)</span> de la distribución normal estándar (el percentil <span class="math inline">\(\alpha/2\)</span>) y <span class="math inline">\(z_{(1-\alpha/2)}\)</span> al percentil: <span class="math inline">\((1-\alpha/2)\)</span>, la expresión queda:</p>
<p><span class="math display">\[P(z\leq z_{\alpha/2} \cup z\geq z_{(1-\alpha/2)} / H_{0} V)=\alpha \]</span></p>
<p>Y las representaciones gráficas de las áreas de rechazo para los tres niveles de significación mencionados son:</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-500-1"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-500-1.svg" alt="Comparación de las zonas de rechazo de $H_{0}$ con niveles de significación del 10, del 5 y del 1%" width="672" />
<p class="caption">
Figura 11.4: Comparación de las zonas de rechazo de <span class="math inline">\(H_{0}\)</span> con niveles de significación del 10, del 5 y del 1%
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-500-2"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-500-2.svg" alt="Comparación de las zonas de rechazo de $H_{0}$ con niveles de significación del 10, del 5 y del 1%" width="672" />
<p class="caption">
Figura 11.5: Comparación de las zonas de rechazo de <span class="math inline">\(H_{0}\)</span> con niveles de significación del 10, del 5 y del 1%
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-500-3"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-500-3.svg" alt="Comparación de las zonas de rechazo de $H_{0}$ con niveles de significación del 10, del 5 y del 1%" width="672" />
<p class="caption">
Figura 11.6: Comparación de las zonas de rechazo de <span class="math inline">\(H_{0}\)</span> con niveles de significación del 10, del 5 y del 1%
</p>
</div>
<p>Ejemplo (datos ficticios): para la misma carrera universitaria del
ejemplo anterior, el promedio de calificaciones al egreso era, según registros históricos, de 6.50. Nos
preguntamos si, luego del cambio en el plan de estudios, esta nota
promedio ha cambiado o sigue siendo la misma. El planteo de las
hipótesis será ahora:</p>
<p><span class="math display">\[H_{0}:\ \mu = 6.50\]</span></p>
<p><span class="math display">\[H_{1}:\ \mu \neq 6.50\]</span></p>
<p>Por la misma razón que antes, no podemos analizar a la población
completa, usaremos los datos obtenidos en una muestra. En ella
encontramos, por ejemplo, que el promedio de 100 egresadas y egresados es de
6.65 con desviación estándar de 0.60, es decir:
<span class="math inline">\(\overline{x} = 6.65\)</span> y <span class="math inline">\(s = 0.60\)</span>. A un nivel de significación del 5%,
los puntos críticos vuelven a ser <span class="math inline">\(Z_{c}=\pm1.96\)</span>. Buscamos el
estadístico de prueba transformando el valor observado de <span class="math inline">\(\overline{x}\)</span> a puntaje <span class="math inline">\(z\)</span> y encontramos:</p>
<p><span class="math display">\[z_{obs} = \frac{{\overline{x}}_{obs} - \mu}{\frac{s}{\sqrt{n}}} = \frac{6.65 - 6.50}{\frac{0.6}{\sqrt{100}}} = 2.50\]</span></p>
<p>El valor observado de <span class="math inline">\(\overline{x}\)</span> corresponde entonces a un <span class="math inline">\(z\)</span> que
supera al punto crítico (que es <span class="math inline">\(z_{c}=1.96\)</span>), por lo que está en la zona de rechazo de <span class="math inline">\(H_{0}\)</span>. La decisión es rechazar <span class="math inline">\(H_{0}\)</span> y concluir que el promedio al egreso es actualmente diferente del promedio histórico.</p>
<p>En los dos ejemplos vemos que la regla de decisión depende del nivel de
significación. Cuando se fija en el 5% entonces se puede expresar como
“si el valor de <span class="math inline">\(z\)</span> correspondiente al valor observado de <span class="math inline">\(\overline{x}\)</span> está entre -1.96 y 1.96 no se puede rechazar <span class="math inline">\(H_{0}\)</span>, si es menor a -1.96 o superior a 1.96 se debe rechazar la <span class="math inline">\(H_{0}\)</span>”. Cuando el nivel de significación es del 10%, diremos que “si el valor <span class="math inline">\(z\)</span> correspondiente al valor observado de <span class="math inline">\(\overline{x}\)</span> está entre -1.64 y 1.64 no se puede rechazar <span class="math inline">\(H_{0}\)</span>, si es menor a -1.64 o superior a 1.64 se debe rechazar <span class="math inline">\(H_{0}\)</span>.</p>
<p>Veamos más en detalle el significado de esta probabilidad que hemos
fijado en 0.05 y que puede también elegirse en 0.10 ó en 0.01 y que
llamamos <span class="math inline">\(\alpha\)</span>. Se trata de la probabilidad de hallar el valor observado en la muestra (o uno más extremo a él) si <span class="math inline">\(H_{0}\)</span> fuera verdadera, por lo que cada vez que hallemos valores muestrales que se encuentran allí, tomaremos la decisión de rechazar <span class="math inline">\(H_{0}\)</span>. Si la hipótesis nula fuera efectivamente verdadera, la decisión sería incorrecta, pero a eso no lo sabemos, porque nunca conocemos el verdadero valor del parámetro. Aunque sí podemos afirmar que al fijar <span class="math inline">\(\alpha\)</span> en el 5%, ésas serán las chances de equivocarnos rechazando una hipótesis nula que era verdadera. En el
segundo ejemplo, cuyo resultado fue el de rechazar <span class="math inline">\(H_{0}\)</span>, es muy
importante indicar a qué nivel de significación se toma la decisión,
porque ese número (5%) indica la probabilidad de haber tomado la
decisión erróneamente. Mide la probabilidad de haber encontrado el
promedio muestral de 6.65 por azar. Como esa probabilidad es pequeña,
decidimos rechazar <span class="math inline">\(H_{0}\)</span>.</p>
</div>
<div id="los-puntos-críticos-en-términos-del-estimador" class="section level3 hasAnchor" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Los puntos críticos en términos del estimador<a href="#los-puntos-cr%C3%ADticos-en-t%C3%A9rminos-del-estimador" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hay una manera diferente de establecer las zonas de aceptación y
rechazo, que consiste en fijar los puntos críticos en términos de
<span class="math inline">\(\overline{x}\)</span>, en lugar de hacerlo como puntajes <span class="math inline">\(z\)</span>. Por lo que en lugar
de determinar los dos <span class="math inline">\(z_{c}\)</span>, hallaremos los dos valores críticos de
<span class="math inline">\(\overline{x}\)</span>, a los que llamaremos <span class="math inline">\({\overline{x}}_{c}\)</span>:</p>
<p><span class="math display">\[{\overline{x}}_{c} = \mu \pm z_{c}*\frac{s}{\sqrt{n}}\]</span></p>
<p>En el ejemplo sobre el tiempo que se tarda en terminar una
carrera y a un nivel de significación de 5%, los valores de
<span class="math inline">\({\overline{x}}_{c}\)</span> son:</p>
<p><span class="math display">\[{\overline{x}}_{c} = \mu \pm z_{c}*\frac{s}{\sqrt{n}} = 7.30 \pm 1.96*\frac{1.30}{\sqrt{100}} = 7.30 \pm 0.25\]</span></p>
<p>Al sumar obtenemos 7.55 y al restar 7.05. Estos son los puntos críticos
expresados en términos de la variable original. La regla de decisión es
ahora “si se encuentra un valor de <span class="math inline">\({\overline{x}}_{obs}\)</span>
comprendido entre 7.05 y 7.55 no se puede rechazar la <span class="math inline">\(H_{0}\)</span>. Si el valor observado de <span class="math inline">\({\overline{x}}_{obs}\)</span> es inferior a 7.05 ó superior
a 7.55 se debe rechazar <span class="math inline">\(H_{0}\)</span>.</p>
<p>Para expresarlo como probabilidad condicionada:</p>
<p><span class="math display">\[P((\overline{x} \leq 7.05 \cup \overline{x} \geq 7.55)/\mu=7.30)=0.05\]</span></p>
<p>Que afirma que la probabilidad de hallar a <span class="math inline">\(\overline{x}\)</span> por debajo de
7.05 o por encima de 7.55 si la media de la población es 7.30, vale
0.05.</p>
<p>Al hacer la prueba, vemos que <span class="math inline">\({\overline{x}}_{obs} = 7.50\)</span>, que
no va más allá de los puntos críticos, por lo que pertenece a la zona de no rechazo de <span class="math inline">\(H_{0}\)</span>. Concluimos que no se rechaza <span class="math inline">\(H_{0}\)</span> y que no ha cambiado el tiempo que se tarda en terminar la carrera.</p>
<p>La regla de decisión es la misma que antes, solo que ahora está expresada en el lenguaje de <span class="math inline">\(\overline{x}\)</span> y no de <span class="math inline">\(z\)</span> y la conclusión también es la misma.</p>
<p>Volviendo ahora sobre el caso de los promedios al egreso, para hallar los valores críticos de la media muestral hacemos:</p>
<p><span class="math display">\[{\overline{x}}_{c} = \mu \pm z_{c}*\frac{s}{\sqrt{n}} = 6.50 \pm 1.96*\frac{0.60}{\sqrt{100}} = 6.50 \pm 0.12\]</span></p>
<p>Y resultan: 6.38 y 6.62. El promedio observado fue de 6.65, que supera
al punto crítico superior y se encuentra en la zona de rechazo.
Concluimos que se rechaza la <span class="math inline">\(H_{0}\)</span> y que, con el nuevo plan, la calificación promedio al egreso difiere de la histórica. Nuevamente, es la misma conclusión que si se trabaja sobre <span class="math inline">\(z\)</span>.</p>
<p>Comparemos los dos procedimientos:</p>
<p>A. Usando valores críticos de <span class="math inline">\(z\)</span></p>
<ol style="list-style-type: decimal">
<li><p>Habiendo establecido el nivel de significación, determinar los
valores <span class="math inline">\(z\)</span> que dejan esa probabilidad en los extremos. Éstos son
los <span class="math inline">\(z_{c}\)</span>.</p></li>
<li><p>Para hallar el estadístico de prueba, transformar el valor observado de <span class="math inline">\(\overline{x}\)</span> en puntaje <span class="math inline">\(z\)</span> haciendo:</p></li>
</ol>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\overline{x}}_{\text{obs}} - \mu}{\frac{s}{\sqrt{n}}}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Observar la posición de este valor transformado en la distribución
de probabilidades z</li>
</ol>
<p>Para un nivel de significación de 0.05 (ó 5%), en el ejemplo, el gráfico es el <a href="prueba-de-hipótesis-la-lógica.html#fig:rechZ">11.7</a>:</p>
<div class="figure"><span style="display:block;" id="fig:rechZ"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/rechZ-1.svg" alt="Ubicación de la zona de rechazo de $H_{0}$ a un nivel de significación de 0.05, sobre puntajes estándar ($z$), y del valor observado" width="672" />
<p class="caption">
Figura 11.7: Ubicación de la zona de rechazo de <span class="math inline">\(H_{0}\)</span> a un nivel de significación de 0.05, sobre puntajes estándar (<span class="math inline">\(z\)</span>), y del valor observado
</p>
</div>
<p>B. Usando los valores críticos de <span class="math inline">\(\overline{x}\)</span></p>
<ol style="list-style-type: decimal">
<li><p>Habiendo establecido el nivel de significación, determinar los
valores <span class="math inline">\(z\)</span> que dejan esa probabilidad en los extremos. Éstos son los
<span class="math inline">\(z_{c}\)</span>.</p></li>
<li><p>Usar los <span class="math inline">\(z_{c}\)</span> para determinar los correspondientes <span class="math inline">\({\overline{x}}_{c}\)</span> haciendo:</p></li>
</ol>
<p><span class="math display">\[{\overline{x}}_{c} = \mu \pm z_{c}*\frac{s}{\sqrt{n}}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Ver la posición de <span class="math inline">\({\overline{x}}_{\text{obs}}\)</span> en la distribución
de probabilidades de <span class="math inline">\(\overline{x}\)</span>.</li>
</ol>
<p>Para el nivel de significación de 0.05 y el mismo ejemplo, resulta el gráfico <a href="prueba-de-hipótesis-la-lógica.html#fig:rechX">11.8</a>.</p>
<div class="figure"><span style="display:block;" id="fig:rechX"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/rechX-1.svg" alt="Ubicación de la zona de rechazo de $H_{0}$ a un nivel de significación de 0.05, sobre valores de la variable $\overline{x}$, y del valor observado" width="672" />
<p class="caption">
Figura 11.8: Ubicación de la zona de rechazo de <span class="math inline">\(H_{0}\)</span> a un nivel de significación de 0.05, sobre valores de la variable <span class="math inline">\(\overline{x}\)</span>, y del valor observado
</p>
</div>
<p>La diferencia entre las dos formas de establecer los puntos críticos es
que con la primera se determinan los valores de <span class="math inline">\(z_{c}\)</span> a partir del
nivel de significación y luego se transforma a puntaje <span class="math inline">\(z\)</span> el valor
muestral observado de <span class="math inline">\({\overline{x}}_{obs}\)</span>.</p>
<p>En el segundo modo, los <span class="math inline">\(z_{c}\)</span> se transforman (al revés) en puntos críticos de <span class="math inline">\({\overline{x}}_{c}\)</span> y luego se compara el <span class="math inline">\({\overline{x}}_{obs}\)</span> directamente, sin transformarlo.</p>
<p>Los gráficos <a href="prueba-de-hipótesis-la-lógica.html#fig:rechZ">11.7</a> y <a href="prueba-de-hipótesis-la-lógica.html#fig:rechX">11.8</a> expresan lo mismo, el primero en el lenguaje estandarizado de <span class="math inline">\(z\)</span>, el segundo en el de <span class="math inline">\(\overline{x}\)</span>. Los procedimientos son equivalentes y puede vérselos aplicados de manera indiferenciada. Las campanas tienen la escala del eje horizontal ajustada para que mantengan la misma forma, y así quede clara la equivalencia de los procedimientos, pero no debe olvidarse que la variabilidad es diferente entre las dos distribuciones. La primera está estandarizada a uno y la segunda depende de la varianza poblacional y del tamaño de la muestra. La primera corresponde a una normal estándar, con <span class="math inline">\(\sigma = 1\)</span>, mientras que, en este ejemplo, la segunda es la distribución normal de las <span class="math inline">\(\overline{x}\)</span>, con <span class="math inline">\(\sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}} = 0.13\)</span>.</p>
</div>
<div id="pruebas-unilaterales" class="section level3 hasAnchor" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Pruebas unilaterales<a href="prueba-de-hipótesis-la-lógica.html#pruebas-unilaterales" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A menudo la hipótesis alternativa no expresa solo que la media difiera
del valor hipotético, sino que indica en qué <em>dirección</em> se espera que
difiera. Por ejemplo, puede esperarse, en el ejemplo anterior, que la carrera es termine con promedio superior a 6.50, con lo que ahora la <span class="math inline">\(H_{1}\)</span> dirá que <span class="math inline">\(\mu &gt; 6.50\)</span>. Se trata en este caso de una prueba unilateral y solo rechazaremos la <span class="math inline">\(H_{0}\)</span> si encontramos valores sustancialmente <em>mayores</em> que 6.50. Para el mismo nivel de significación del 5%, el valor <span class="math inline">\(z\)</span> que nos interesa es el que delimita un área <em>superior</em> de 0.05.</p>
<p>Notemos la diferencia con las pruebas que tratamos antes: al nivel de 5% buscábamos dos <span class="math inline">\(z\)</span> que dejaban en total 0.05 de área extrema (por encima y por debajo) o lo que es lo mismo, los dos <span class="math inline">\(z\)</span> que dejan el 95% del área central. Ahora, como la prueba es unilateral y solo nos interesan valores que se excedan, solo buscamos un <span class="math inline">\(z\)</span> crítico, el que deja al 5% por encima. Ese valor de <span class="math inline">\(z_c\)</span> es 1.64.<a href="#fn70" class="footnote-ref" id="fnref70"><sup>70</sup></a></p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-501"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-501-1.svg" alt="Ubicación de la zona de rechazo de Ho para una prueba unilateral derecha a un niel de significación del 5%" width="672" />
<p class="caption">
Figura 11.9: Ubicación de la zona de rechazo de Ho para una prueba unilateral derecha a un niel de significación del 5%
</p>
</div>
<p>Por oposición a las anteriores, las pruebas unilaterales se llaman
<strong>pruebas de una cola</strong>. Como vemos en el gráfico, el conjunto de
valores <span class="math inline">\(z\)</span> que conducen a rechazar <span class="math inline">\(H_{0}\)</span> se encuentran solo a la
derecha.</p>
<p>Ejemplo (datos ficticios): en la situación en que nuestro interés esté
en analizar si el promedio al egreso es
<em>superior</em> al valor histórico (y no solo diferente a él), las hipótesis
de la prueba se expresan:</p>
<p><span class="math display">\[H_{0}:\ \mu = 6.50\]</span></p>
<p><span class="math display">\[H_{1}:\ \mu &gt; 6.50\]</span></p>
<p>Haremos la prueba sobre los valores de <span class="math inline">\(\overline{x}\)</span>, a un nivel de
significación del 5% entonces:</p>
<p><span class="math display">\[{\overline{x}}_{c} = \mu + z_{c}*\frac{s}{\sqrt{n}} = 6.50 + 1.64*\frac{0.60}{\sqrt{100}} = 6.50 + 0.10\]</span></p>
<p>Al sumar obtenemos 6.60, que es el único punto crítico que nos interesa
por tratarse de una prueba unilateral y hemos sumado porque la prueba es derecha. Con lo que resulta la siguiente región de rechazo de <span class="math inline">\(H_{0}\)</span>:</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-502"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-502-1.svg" alt="Región de rechazo unilateral derecha de $H_{0}: \mu = 6.50$ a un nivel de significación del 5%, con una muestra de 100 casos y desviación estándar 0.60, y ubicación del valor observado del estimador" width="672" />
<p class="caption">
Figura 11.10: Región de rechazo unilateral derecha de <span class="math inline">\(H_{0}: \mu = 6.50\)</span> a un nivel de significación del 5%, con una muestra de 100 casos y desviación estándar 0.60, y ubicación del valor observado del estimador
</p>
</div>
<p>El valor observado de <span class="math inline">\(\overline{x}\)</span> había sido 6.65 que es mayor que el punto crítico, con lo que rechazamos la <span class="math inline">\(H_{0}\)</span> y concluimos que el promedio al egreso es significativamente mayor al histórico.</p>
<p>Si hubiésemos planteado la regla de decisión sobre los valores de <span class="math inline">\(z\)</span>, a un nivel de significación del 5%, hay que calcular el puntaje <span class="math inline">\(z\)</span> correspondiente al valor observado de la media muestral:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\overline{x}}_{\text{obs}} - \mu}{\frac{s}{\sqrt{n}}} = \frac{6.65 - 6.50}{\frac{0.60}{\sqrt{100}}} = 2.5\]</span></p>
<p>Dado que este resultado supera al punto crítico <span class="math inline">\(z_c = 1.64\)</span>, concluimos nuevamente que el promedio al egreso es significativamente mayor al histórico.</p>
<p>En los párrafos anteriores hemos introducido una expresión nueva, que
tiene un sentido preciso. Cuando decimos “significativamente mayor” no
nos referimos al uso que suele darse en el lenguaje cotidiano, que es
sinónimo de importante, de gran magnitud, grande, etc. Diremos que un
valor es significativamente mayor o menor si se ha rechazado una prueba
unilateral, o bien que es significativamente diferente o que la
diferencia es significativa, si la <span class="math inline">\(H_{0}\)</span> que fue rechazada pertenece a una prueba bilateral. Además debe indicarse el nivel de significación de la prueba, por lo que diremos: según los datos observados y a un nivel del 5%, la calificación promedio al egreso de la carrera es significativamente superior a la histórica.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Un resultado es <strong>significativo</strong> cuando conduce a rechazar una <span class="math inline">\(H_{0}\)</span> a un determinado nivel de significación.</td>
</tr>
</tbody>
</table>
<p>Un resultado puede ser significativo a un nivel y no serlo a otro. Por
ejemplo, si en una prueba bilateral y luego de transformar el valor
observado a puntaje <span class="math inline">\(z\)</span>, se obtiene <span class="math inline">\(z=2.3\)</span>, este resultado conducirá a que se rechace <span class="math inline">\(H_{0}\)</span> al 5% (porque <span class="math inline">\(2.3\)</span> es mayor que <span class="math inline">\(1.96\)</span>) pero que no se rechace al 1% (porque <span class="math inline">\(2.3\)</span> no es mayor que <span class="math inline">\(2.56\)</span>). En ese caso diremos que se obtienen resultados significativos al 5% pero no al 1%. Luego veremos que esta clasificación puede hacerse más precisa.</p>
</div>
<div id="otros-ejemplos-de-prueba-de-hipótesis-sobre-la-media" class="section level3 hasAnchor" number="11.2.4">
<h3><span class="header-section-number">11.2.4</span> Otros ejemplos de prueba de hipótesis sobre la media<a href="#otros-ejemplos-de-prueba-de-hip%C3%B3tesis-sobre-la-media" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La investigación con sujetos animales en Psicología se basa en que
distintas especies comparten mecanismos básicos, y los animales no
humanos presentan un nivel de complejidad menor, lo que facilita la
comprensión de fenómenos complejos en personas. De hecho, los <em>modelos
animales</em> han permitido avanzar en el conocimiento de mecanismos
neurofisiológicos, cognitivos y comportamentales de seres humanos,
siendo clave en el ámbito de la psicopatología y terapia psicológica.</p>
<p>En este contexto, alumnas de Psicología interesadas en la vulnerabilidad
adolescente hacia el uso y abuso de drogas, recurrieron a un modelo
animal para estudiar los efectos del alcohol <span class="citation">Dziula and Reyna (<a href="#ref-Dziula2005">2005</a>)</span>. Uno de los posibles
factores que determinan las primeras aproximaciones a las drogas es la
búsqueda de nuevas sensaciones, que se manifiesta en niveles elevados
tanto en adolescentes humanos como no humanos, particularmente en
roedores. En modelos animales, una manera de indagar el comportamiento
de búsqueda de novedad es a través del uso de un objeto novedoso. Debido
al escaso conocimiento sobre el comportamiento de los roedores ante
tales objetos, las alumnas desarrollaron un estudio piloto.
Concretamente, expusieron a 32 ratas Wistar<a href="#fn71" class="footnote-ref" id="fnref71"><sup>71</sup></a> adolescentes (28 a 42
días de edad) a un objeto novedoso durante 3 minutos en distintos
intervalos de tiempo.</p>
<p>A continuación, se retoman datos parciales del estudio piloto a los
fines de exponer la modalidad de trabajo cuando se realiza una prueba de
hipótesis sobre un valor determinado de la media. Primero ilustramos el
caso de una prueba bilateral y luego unilateral.</p>
<p>Ejemplo (datos modificados<a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a>): en algunos estudios se ha observado
que el tiempo que tardan los roedores (en general) en contactar un
objeto novedoso (llamado tiempo de latencia, o simplemente latencia) es
de 150 seg. En función de ello, se indaga si la latencia de contacto con
el objeto en ratas Wistar adolescentes es la misma o no en relación a la
reportada previamente en otros trabajos con roedores. Las hipótesis
formuladas son:</p>
<p><span class="math display">\[H_{0}:\mu = 150\]</span></p>
<p><span class="math display">\[H_{1}:\mu \neq 150\]</span></p>
<p>En la muestra utilizada, la latencia media de contacto con el objeto es
de 138.42 seg. y la desviación estándar 42.98. Se establece un nivel de
significación del 5%, por lo que los puntos críticos en puntajes <em>z</em> son <span class="math inline">\(z_{c}=\pm 1.96\)</span></p>
<p>Luego, se transforma el valor de <span class="math inline">\(\overline{x}\)</span> observado en puntaje <span class="math inline">\(z\)</span> a través de la siguiente fórmula:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\overline{x}}_{\text{obs}} - \mu}{\frac{s}{\sqrt{n}}} = \frac{138.42 - 150}{\frac{42.98}{\sqrt{32}}} = \frac{- 11.58}{7.59} = - 1.52\]</span></p>
<p>Vemos que al valor de <span class="math inline">\({\overline{x}}_{\text{obs}}\)</span> le corresponde un
valor <span class="math inline">\(z_{\text{obs}}\)</span> que se encuentra entre los puntos críticos <span class="math inline">\(z_{c}=\pm 1.96\)</span>, es decir que se halla en la zona de no rechazo de la <span class="math inline">\(H_{0}\)</span>, por lo que concluimos que no hay evidencia que indique que la latencia media de contacto con un objeto novedoso en ratas Wistar es distinta a la latencia que manifiestan los roedores en general.</p>
<p>Se obtiene la misma conclusión si se utilizan los valores críticos de
<span class="math inline">\(\overline{x}\)</span>. Revisemos el procedimiento: luego de haber establecido
el nivel de significación al 5%, se obtienen los puntos críticos en
puntajes originales (<span class="math inline">\({\overline{x}}_{c}\)</span>) a partir de los puntos
críticos en puntajes <span class="math inline">\(z\)</span> (los <span class="math inline">\(z_{c}\)</span>), a través de la siguiente
fórmula<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a>:</p>
<p><span class="math display">\[{\overline{x}}_{c} = \mu \pm z_{c}*\frac{s}{\sqrt{n}} = 150 \pm 1.96*\frac{42.98}{\sqrt{32}} = 150 \pm 14.89\]</span></p>
<p>Entonces, los <span class="math inline">\({\overline{x}}_{c}\)</span> que delimitan las zonas de rechazo y
no rechazo son 135.02 y 164.89, y el valor observado de
<span class="math inline">\(\overline{x} = 138.42\)</span> se encuentra comprendido entre ellos, por lo que no se rechaza la <span class="math inline">\(H_{0}\)</span>.</p>
<p>Ejemplo (datos reales<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a>): la literatura sobre comportamiento
exploratorio en roedores (en general) indica que cuando los organismos
son expuestos durante 180 seg a un objeto novedoso permanecen en
contacto con el mismo (duración) 14 seg en promedio. Debido a las
características del período adolescente, en este trabajo se formula una
hipótesis que indica que las ratas adolescentes estarán más tiempo en
contacto con el objeto. Las hipótesis formuladas son:</p>
<p><span class="math display">\[H_{0}:\mu = 14\]</span></p>
<p><span class="math display">\[H_{1}:\mu &gt; 14\]</span></p>
<p>En los animales que comprenden la muestra bajo análisis, se observa que
la duración de contacto con el objeto es de 17.43 seg y la desviación
estándar 4.25. El nivel de significación se establece en el 5% y, dado
que la prueba es unilateral derecha, el punto crítico en puntaje <span class="math inline">\(z\)</span> es
1.64.</p>
<p>Luego, transformamos el valor de <span class="math inline">\(\overline{x}\)</span> observado en puntaje
<span class="math inline">\(z\)</span>:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\overline{x}}_{\text{obs}} - \mu}{\frac{s}{\sqrt{n}}} = \frac{17.43 - 14}{\frac{4.25}{\sqrt{32}}} = \frac{3.43}{0.75} = 4.57\]</span></p>
<p>Al valor de <span class="math inline">\(\overline{x}\)</span> observado le corresponde un valor <span class="math inline">\(z=4.57\)</span>,
que resulta superior al <span class="math inline">\(z_c = 1.64\)</span>, por lo que se rechaza la <span class="math inline">\(H_0\)</span>, es
decir que las ratas adolescentes muestran una duración mayor de contacto
con un objeto novedoso que lo señalado por la literatura para roedores
en general.</p>
<p>Obtenemos la misma conclusión si usamos los valores críticos de
<span class="math inline">\(\overline{x}\)</span>. Una vez establecido el nivel de significación al 5%, se
obtienen los puntos críticos en puntajes originales
(<span class="math inline">\({\overline{x}}_{c}\)</span>) a partir de los puntos críticos en puntajes <span class="math inline">\(z\)</span>
(<span class="math inline">\(z_{c}\)</span>)<a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a>:</p>
<p><span class="math display">\[{\overline{x}}_{c} = \mu + z_{c}*\frac{s}{\sqrt{n}} = 14 + 1.64*\frac{4.25}{\sqrt{32}} = 14 + 1.23 = 15.23\]</span></p>
<p>El valor observado de <span class="math inline">\(\overline{x} = 17.43\)</span> resulta mayor a
<span class="math inline">\({\overline{x}}_{c} = 15.23\)</span>, por lo que se rechaza la <span class="math inline">\(H_{0}\)</span>, y
concluimos que la duración promedio de contacto con un objeto novedoso
en ratas adolescentes es significativamente mayor a 14.</p>
<p>Ejemplo (datos reales): luego de haber evaluado la latencia de contacto
con un objeto novedoso de los animales en repetidas ocasiones, se observa un valor promedio de 112.48 seg. Ahora, el equipo de investigación se interesa en indagar cuál será la latencia de contacto si las ratas
son nuevamente expuestas al objeto novedoso, suponiendo que será menor
debido a la disminución del carácter novedoso que hacía que los animales
tardaran en contactar el objeto en las exposiciones iniciales. Las
hipótesis formuladas son:</p>
<p><span class="math display">\[H_{0}:\mu = 112.48\]</span></p>
<p><span class="math display">\[H_{1}:\mu &lt; 112.48\]</span></p>
<p>En la nueva exposición, la latencia promedio de contacto con el objeto
es de 71.36 y la desviación estándar es de 45.77. El nivel de
significación se establece en el 5% y, dado que la prueba es unilateral
izquierda, el punto crítico en puntaje es <span class="math inline">\(z_{c}=-1.64\)</span>.</p>
<p>Luego, transformamos el valor de <span class="math inline">\({\overline{x}}_{c}\)</span> observado en
puntaje <span class="math inline">\(z\)</span> con el estadístico de prueba:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\overline{x}}_{\text{obs}} - \mu}{\frac{s}{\sqrt{n}}} = \frac{71.36 - 112.48}{\frac{45.77}{\sqrt{32}}} = \frac{- 41.12}{8.09} = - 5.08\]</span></p>
<p>Vemos entonces que al valor de <span class="math inline">\({\overline{x}}_{c}\)</span> observado le
corresponde un valor <span class="math inline">\(z=-5.08\)</span>, que resulta inferior al <span class="math inline">\(z_{c}=-1.64\)</span>, por lo que se rechaza la <span class="math inline">\(H_{0}\)</span>, es decir que se concluye que, a un nivel de significación del 5%, la latencia de contacto con el objeto novedoso en una nueva exposición es significativamente menor a 112.48 seg.</p>
<p>A la misma conclusión se arriba si se realizan los cálculos con los
valores críticos de <span class="math inline">\({\overline{x}}_{c}\)</span>, que se obtienen a partir de
los puntos críticos en puntajes <span class="math inline">\(z\)</span> /<span class="math inline">\(z_{c}\)</span>, a través de la siguiente
fórmula<a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a>:</p>
<p><span class="math display">\[{\overline{x}}_{c} = \mu - z_{c}*\frac{s}{\sqrt{n}} = 112.48 - 1.64*\frac{45.77}{\sqrt{32}} = 112.48 - 13.27 = 99.21\]</span></p>
<p>El valor observado de <span class="math inline">\(\overline{x} = 71.36\)</span> resulta menor a
<span class="math inline">\({\overline{x}}_{c} = 99.21\)</span>, por lo que se rechaza la <span class="math inline">\(H_{0}\)</span>, la latencia promedio de contacto con el objeto novedoso en la nueva exposición es, al 5% de significación, significativamente menor a 112.48 seg.</p>
<p>Debemos recordar que el carácter unilateral o bilateral de la prueba no
depende de la <span class="math inline">\(H_{0}\)</span> sino de la <span class="math inline">\(H_{1}\)</span>. En efecto, la <span class="math inline">\(H_{0}\)</span> siempre indica un valor determinado para el parámetro (hasta aquí la media), mientras que la <span class="math inline">\(H_{1}\)</span> puede indicar un valor diferente si la prueba es bilateral, o bien señalar la dirección de la diferencia hacia los mayores o menores y en esos casos, la prueba es unilateral. La decisión de hacer una prueba unilateral o bilateral depende de cada investigación concreta, de la pregunta que el investigador formula.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-503">Tabla 11.1: </span>Valores críticos usuales de la distribución normal
</caption>
<thead>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Significación
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Puntaje z para prueba:
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Bilateral
</th>
<th style="text-align:center;">
Unilateral derecha
</th>
<th style="text-align:center;">
Unilateral izquierda
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(0.10\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pm 1.64\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(+1.28\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(-1.28\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(0.05\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pm 1.96\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(+1.64\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(-1.64\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(0.01\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\pm 2.57\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(+2.33\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(-2.33\)</span>
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="prueba-sobre-la-proporción" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Prueba sobre la proporción<a href="#prueba-sobre-la-proporci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>De modo equivalente a los intervalos de confianza, comenzaremos con la
prueba de hipótesis sobre una proporción usando la distribución
binomial, para luego usar la aproximación normal, si los supuestos se
cumplen. El procedimiento conlleva los mismos pasos que cuando se trata
de la media: se plantean, en primer lugar, las hipótesis nula y
alternativa. La hipótesis nula afirma un valor para la proporción
poblacional, mientras que la hipótesis alternativa puede, o bien solo
indicar que el valor es diferente (prueba bilateral), o bien precisar si
la diferencia se espera hacia valores mayores o menores que los
indicados por la hipótesis nula (prueba unilateral). Una vez fijado el
nivel de significación (<span class="math inline">\(\alpha\)</span>) y la lateralidad de la prueba, deben
determinarse los valores de <span class="math inline">\(\widehat{p}\)</span> que dejan esa probabilidad por
encima (en el caso de una prueba unilateral derecha), por debajo
(unilateral izquierda), o bien repartida en ambas colas (si es una
prueba bilateral). La determinación de esos puntos se realiza con la
distribución binomial, por lo que es necesario transformar la variable
<em>proporción de éxitos</em> (<span class="math inline">\(p\)</span>) al <em>número de éxitos</em> (<span class="math inline">\(x\)</span>). Esta
transformación vale para la proporción hipotética (<span class="math inline">\(P\)</span>) y para la
observada (<span class="math inline">\(\widehat{p}\)</span>): <span class="math display">\[P = \frac{X}{n}\]</span> es decir <span class="math display">\[X = P*n\]</span>
Del mismo modo que:
<span class="math display">\[\widehat{p} = \frac{\widehat{x}}{n}\]</span> equivale a
<span class="math display">\[\widehat{x} = \widehat{p}*n\]</span></p>
<p>Ejemplo (datos ficticios): un partido político tenía, haces tres meses una intención de voto equivalente al 30% del padrón. De acuerdo con algunas acciones de campaña, se cree que esta proporción pudo haber aumentado, por lo que el planteo de las hipótesis es:</p>
<p><span class="math display">\[H_{0}:P = 0.30\]</span></p>
<p><span class="math display">\[H_{1}:P &gt; 0.30\]</span></p>
<p>Hipótesis que se pondrá a prueba sobre una muestra de 50 casos. Al igual que sucedió con la media, estos son valores que planteamos de manera hipotética acerca del parámetro, en este caso la proporción poblacional (<span class="math inline">\(P\)</span>). La <span class="math inline">\(H_{0}\)</span> indica que la proporción de votos sigue siendo la misma. Se trata de una prueba unilateral derecha, porque el interés está en encontrar un eventual aumento en la proporción de votantes que tiene el partido, por eso la <span class="math inline">\(H_{1}\)</span> indica una proporción mayor.</p>
<p>Se fija un nivel de significación de 5% y, para determinar los puntos
críticos bajo un modelo binomial, se transforma el valor hipotético de <span class="math inline">\(P\)</span> al correspondiente a X en la muestra dada:</p>
<p><span class="math display">\[X = P*n = 0.30*50 = 15\]</span></p>
<p>Con lo que el punto crítico es el valor de <span class="math inline">\(\widehat{x}\)</span> que deja por
encima (porque es una prueba unilateral derecha) al 5% de los valores
posibles. Buscamos el percentil 95 de la distribución binomial corespondiente a los parámetros:
<span class="math inline">\(n = 50\)</span>, <span class="math inline">\(P = 0.30\)</span> y <span class="math inline">\(P( X &gt; x) = 0.05\)</span></p>
<p>La probabilidad es la de la cola derecha de la distribución, por ser una prueba unilateral derecha, y corresponde a una probabilidad acumulada de 0.95, de modo que el percentil es 95, que equivale a <span class="math inline">\(P( X \leq x) = 0.95\)</span> es:</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="prueba-de-hipótesis-la-lógica.html#cb567-1" tabindex="-1"></a><span class="fu">qbinom</span>(.<span class="dv">95</span>, <span class="dv">50</span>, .<span class="dv">30</span>)</span></code></pre></div>
<pre><code>## [1] 20</code></pre>
<p>El número de éxitos es 20. Por lo que el valor de <span class="math inline">\(\widehat{x}\)</span> que
es superado por el 5% de los valores muestrales posibles es 20. La
representación gráfica es la siguiente:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-505-1.svg" width="672" /></p>
<p>Repasemos la interpretación de estas operaciones: si la proporción de
votos que el candidato tiene en la población total fuera del 30% (esa es
la hipótesis nula), entonces se esperaría que en una muestra de 50
casos, haya 15 que lo voten (15 es el 30% de 50, es la media de la distribución binomial; su esperanza). Como la muestra es
aleatoria, la cantidad de votos que se obtienen en ella es
aleatoria, puede ir desde cero hasta cincuenta, con diferentes
probabilidades, que muestra el gráfico anterior. El criterio del 5%,
establece al valor 20 votos como punto crítico. Eso quiere decir que, si
la proporción de votos que el candidato tiene en toda la población fuera
del 30%, la probabilidad de encontrar más de 20 votos en una muestra de
50 es menor al 5%. La regla de decisión será entonces: rechazar la
hipótesis nula si en la muestra se encuentran más de 20 votos.</p>
<p>Si en la encuesta realizada sobre la muestra de 50 casos se encuentran
16 personas que dicen que lo votarán (con lo que<a href="#fn77" class="footnote-ref" id="fnref77"><sup>77</sup></a>
<span class="math inline">\(\widehat{p} = 32\%\)</span>), la decisión será la de no rechazar <span class="math inline">\(H_{0}\)</span> y
considerar que no hay evidencia para creer que la proporción de votos
que el candidato tiene, haya aumentado de su 30% anterior.</p>
<p>El punto crítico situado en 20 éxitos equivale a
<span class="math inline">\({\widehat{p}}_{c} = 0.40\)</span>. La comparación de los 16 éxitos muestrales
con los 20 del punto crítico es la misma que la del 32% muestral frente
al 40% crítico.</p>
<p>Si se tratara de una muestra de mayor tamaño y tanto <span class="math inline">\(n*P\)</span> como
<span class="math inline">\(n*(1 - P)\)</span> fueran mayores a 5, podríamos usar la aproximación normal de
la distribución binomial. Para ello, establecemos un nivel de
significación de 5%, y el valor crítico de <span class="math inline">\(z\)</span> (en prueba unilateral) es <span class="math inline">\(1.64\)</span>. Ahora en términos de <span class="math inline">\(z\)</span>, la zona de rechazo queda así:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-506-1.svg" width="672" /></p>
<p>Una vez fijado el nivel de significación (<span class="math inline">\(\alpha\)</span>) y la lateralidad de la prueba (derecha), quedan determinados el o los puntos críticos en términos de <span class="math inline">\(z\)</span>.</p>
<p>La principal diferencia a tener en cuenta para la transformación a
puntaje <span class="math inline">\(z\)</span> de la proporción es el cálculo de su error estándar que, en
la aproximación normal de la distribución en el muestreo de las
<span class="math inline">\(\widehat{p}\)</span> es:</p>
<p><span class="math display">\[\sigma_{\widehat{p}} = \sqrt{\frac{P*(1 - P)}{n}}\]</span></p>
<p>En la construcción de intervalos de confianza es necesario aproximar
<span class="math inline">\(P*(1 - P)\)</span> a través de <span class="math inline">\(\widehat{p}*(1 - \widehat{p})\)</span>, porque se
ignora el valor de la proporción poblacional. Pero en la prueba de hipótesis, la situación es diferente, porque se cuenta con una <span class="math inline">\(P\)</span> (poblacional) hipotética, y es esa la que se utiliza para el cálculo de
<span class="math inline">\(\sigma_{\widehat{p}}\)</span>. Por lo tanto, la transformación del valor
observado en la muestra a puntajes <span class="math inline">\(z\)</span> se hará según:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\widehat{p}}_{\text{obs}} - P}{\sqrt{\frac{P*(1 - P)}{n}}}\]</span></p>
<p>Que es el estadístico de prueba para la prueba de proporciones que debe
usarse cuando sea válida la aproximación normal para la distribución
binomial. De acuerdo a que la posición de este <span class="math inline">\(z_{obs}\)</span> sea en la zona de rechazo o no rechazo de <span class="math inline">\(H_{0}\)</span>, se toma la decisión.</p>
<p>Nuevamente sobre el ejemplo con las mismas hipótesis, nula y alternativa</p>
<p><span class="math display">\[H_{0}:P = 0.30\]</span></p>
<p><span class="math display">\[H_{1}:P &gt; 0.30\]</span></p>
<p>Sea ahora que se trató de una muestra de 200 personas habilitadas para votar, en la que se
halla que 64 dicen que van a votar a ese candidato (de este modo la
proporción muestral sigue siendo de 32%). En la muestra entonces:</p>
<p><span class="math display">\[\widehat{p} = \frac{64}{200} = 0.32\]</span></p>
<p>Nos preguntamos si este valor puede considerarse como un verdadero
aumento respecto del 30% anterior o si solo se explica por razones de
azar. Repitiendo la operación que realizamos para la media,
transformamos este valor observado de la proporción muestral a puntaje
<span class="math inline">\(z\)</span> y hallamos el estadístico de prueba:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\widehat{p}}_{\text{obs}} - P}{\sqrt{\frac{P*(1 - P)}{n}}} = \frac{0.32 - 0.30}{\sqrt{\frac{0.30*(1 - 0.30)}{200}}} = 0.617\]</span></p>
<p>Este puntaje de <span class="math inline">\(z_{obs}\)</span> no supera al punto crítico (<span class="math inline">\(z=1.64\)</span>) por lo
que se sitúa en la zona de no rechazo de <span class="math inline">\(H_{0}\)</span>. Concluimos que la
proporción no ha aumentado respecto del valor anterior.</p>
<p>Para repetir la prueba sobre valores del estimador <span class="math inline">\(\widehat{p}\)</span>, vamos
a transformar el punto crítico de acuerdo a la expresión general:</p>
<p><span class="math display">\[\widehat{p} = P \pm z_{c}*\sqrt{\frac{P*(1 - P)}{n}}\]</span></p>
<p>de la que usaremos ambos signos cuando se trate de una prueba bilateral
o solo la suma si es unilateral derecha o solo la resta si es unilateral izquierda. Para nuestro problema, corresponde sumar, por lo que resulta:</p>
<p><span class="math display">\[\widehat{p} = P + z_{c}*\sqrt{\frac{P*(1 - P)}{n}} = 0.30 + 1.64*\sqrt{\frac{0.30*(1 - 0.30)}{200}} = 0.353\]</span></p>
<p>Representamos gráficamente la zona de rechazo como la cola derecha de la distribución de las <span class="math inline">\(\widehat{p}\)</span>:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-507-1.svg" width="672" /></p>
<p>El valor hallado en la muestra (<span class="math inline">\({\widehat{p}}_{\text{obs}} = 0.32\)</span>) es
menor que el punto crítico, por lo que no está en la zona de rechazo, en consecuencia, no rechazamos la <span class="math inline">\(H_{0}\)</span> y concluimos que no hay evidencia para creer que el
candidato haya aumentado su proporción de votos. Como había sucedido
antes, la conclusión es la misma si trabajamos sobre los puntajes
estandarizados o sobre valores del estimador. Sin embargo, el punto
crítico expresado en términos de <span class="math inline">\(\widehat{p}\)</span> es diferente, cuando se
usó la distribución binomial su valor fue 40% y ahora es 35%.</p>
<p>En los ejemplos siguientes trabajaremos con muestras grandes por lo que
las pruebas se realizan usando la aproximación normal.</p>
<p>Ejemplo (datos reales): en el estudio Latinobarómetro<a href="#fn78" class="footnote-ref" id="fnref78"><sup>78</sup></a> se menciona
la importancia de comprender la percepción de la gente sobre el cambio
generacional: cómo creen que vivían sus padres y madres, y cómo creen que vivirán sus hijos e hijas. En el año 2004, el
58.2% de las personas encuestadas en Argentina consideraba que los hijos e hijas vivirían mejor que ellos. En el año 2005, se indaga nuevamente la expectativa futura. Dado que se habían observado fluctuaciones en años previos, cabe preguntar si esa expectativa positiva habrá cambiado o no respecto del año anterior. Las hipótesis que se formulan son:</p>
<p><span class="math display">\[H_{0}:P = 0.582\]</span></p>
<p><span class="math display">\[H_{1}:P \neq 0.582\]</span></p>
<p>En el estudio del año 2005, observaron que 676 participantes de 1200
que componían la muestra consideraban que sus hijos e hijas vivirían mejor que la generación anterior, con lo que, la proporción en la muestra es:</p>
<p><span class="math display">\[\widehat{p} = \frac{676}{1200} = 0.563\]</span></p>
<p>El nivel de significación se establece al 5%, por lo que los puntos
críticos en puntajes <span class="math inline">\(z\)</span> son <span class="math inline">\(z_{c}=\pm1.96\)</span> (prueba bilateral).</p>
<p>Para responder a la hipótesis planteada, se transforma el valor de
proporción observado a puntaje <span class="math inline">\(z\)</span> haciendo:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\widehat{p}}_{\text{obs}} - P}{\sqrt{\frac{P*(1 - P)}{n}}} = \frac{0.563 - 0.582}{\sqrt{\frac{0.582*(1 - 0.582)}{1200}}} = - 1.36\]</span></p>
<p>El valor <span class="math inline">\(z_{obs}=-1.36\)</span> se encuentra entre los puntos críticos <span class="math inline">\(\pm1.96\)</span>, es decir que se halla en la zona de no rechazo de la <span class="math inline">\(H_{0}\)</span>, por lo cual
se concluye que no hay evidencia que indique que la proporción de
expectativas positivas haya cambiado; la proporción no es
significativamente distinta de 0.582.</p>
<p>Se alcanza la misma conclusión si se realizan los cálculos en función de
los valores del estimador. Establecido el nivel de significación en el 5%,
se obtienen los puntos críticos en puntajes originales (<span class="math inline">\(\widehat{p}\)</span>) a
partir de los puntos críticos en puntajes <span class="math inline">\(z\)</span> (<span class="math inline">\(z_{c}\)</span>):</p>
<p><span class="math display">\[\widehat{p}_{c} = P \pm z_{c}*\sqrt{\frac{P*(1 - P)}{n}} = 0.582 \pm 1.96*\sqrt{\frac{0.582*(1 - 0.582)}{1200}} = 0.582 \pm 0.027\]</span></p>
<p>De esta manera se obtienen los <span class="math inline">\({\widehat{p}}_{c}\)</span> que delimitan las
zonas de rechazo y no rechazo: 0.55 y 0.61. El valor
<span class="math inline">\({\widehat{p}}_{\text{obs}} = 0.563\)</span> se encuentra comprendido entre
ellos, por lo que no se rechaza la <span class="math inline">\(H_{0}\)</span>.</p>
<p>Ejemplo (datos reales): otro de los aspectos indagados en el estudio
Latinobarómetro se refiere a la opinión sobre progreso en la reducción de la corrupción
en las instituciones del Estado. En el año 2004, en Argentina, el 3.33% de quienes respondieron consideraba que se había progresado mucho en ese
aspecto. En el estudio del 2005, se espera que los resultados sean más
favorables debido a la aplicación de una serie de medidas tendientes a
controlar la corrupción institucional. Así, las hipótesis que se
formulan son:</p>
<p><span class="math display">\[H_{0}:P = 0.033\]</span></p>
<p><span class="math display">\[H_{1}:P &gt; 0.033\]</span></p>
<p>De las 1200 respuestas recogidas en el año 2005, 51 indican que se ha
progresado mucho en reducir la corrupción institucional, es decir que la proporción en la muestra es</p>
<p><span class="math display">\[\widehat{p}_{obs} = \frac{51}{1200} = 0.043\]</span></p>
<p>El nivel de significación se establece en el 5%, dado que la prueba es
unilateral derecha el único punto crítico en puntaje <span class="math inline">\(z\)</span> es <span class="math inline">\(1.64\)</span>.</p>
<p>Luego, se transforma el valor de proporción observado en puntaje <span class="math inline">\(z\)</span>,
usando el estadístico de prueba:</p>
<p><span class="math display">\[z_{obs} = \frac{{\widehat{p}}_{obs} - P}{\sqrt{\frac{P*(1 - P)}{n}}} = \frac{0.043 - 0.033}{\sqrt{\frac{0.033*(1 - 0.033)}{1200}}} = 1.94\]</span></p>
<p>El valor <span class="math inline">\(z_{obs}=1.94\)</span> resulta superior al <span class="math inline">\(z_{c}=1.64\)</span>, por lo que
se rechaza la <span class="math inline">\(H_0\)</span>. Por eso concluimos que la proporción de personas que
declara que se ha progresado en la reducción de la corrupción
institucional se incrementó de manera significativa.</p>
<p>Se obtiene la misma conclusión a partir de los valores del estimador.
Establecido el nivel de significación en el 5%, se obtiene el punto crítico
en puntaje original (<span class="math inline">\({\widehat{p}}_{c}\)</span>) a partir del punto crítico en
puntaje <span class="math inline">\(z\)</span> (<span class="math inline">\(z_{c}\)</span>):</p>
<p><span class="math display">\[\widehat{p}_{c} = P + z_{c}*\sqrt{\frac{P*(1 - P)}{n}} = \]</span>
<span class="math display">\[0.033 + 1.64*\sqrt{\frac{0.033*(1 - 0.033)}{1200}} = 0.033 + 0.008 = 0.041\]</span></p>
<p>El valor observado de <span class="math inline">\({\widehat{p}}_{\text{obs}} = 0.043\)</span> resulta mayor
a <span class="math inline">\({\widehat{p}}_{c} = 0.041\)</span>, por lo que se rechaza la <span class="math inline">\(H_{0}\)</span>, y se
concluye que la proporción de quienes creen que se ha progresado en la
reducción de la corrupción institucional se ha incrementado de manera
significativa de 2004 a 2005.</p>
<p>Ejemplo (datos reales): otro tema que aborda Latinobarómetro es el
interés por la política. En el estudio del año 2004, el 11% de las personas encuestadas en Argentina manifestó estar muy interesado en la política. Si bien no ha habido notables cambios en la última década con respecto al interés de la ciudadanía en la política, una serie de indicadores llevaron al equipo de investigación a considerar que el interés en esta cuestión podría haber disminuido. Las hipótesis planteadas son:</p>
<p><span class="math display">\[H_{0}:P = 0.11\]</span></p>
<p><span class="math display">\[H_{1}:P &lt; 0.11\]</span></p>
<p>De la muestra de Argentina de 1200 casos correspondiente el año 2005, 111 manifiestan un elevado interés en la política, la proporción en la
muestra es:</p>
<p><span class="math display">\[\widehat{p}_{obs} = \frac{111}{1200} = 0.093\]</span></p>
<p>El nivel de significación se establece en el 5%, dado que la prueba es
unilateral izquierda el punto crítico en puntaje <span class="math inline">\(z\)</span> es <span class="math inline">\(-1.64\)</span> . Con el
estadístico de prueba se transforma el valor de proporción observado en
puntaje <span class="math inline">\(z\)</span>:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{\widehat{p}}_{\text{obs}} - P}{\sqrt{\frac{P*(1 - P)}{n}}} = \frac{0.093 - 0.11}{\sqrt{\frac{0.11*(1 - 0.11)}{1200}}} = - 1.88\]</span></p>
<p>El valor <span class="math inline">\(z_{obs}=-1.88\)</span> resulta inferior al <span class="math inline">\(z_{c}=-1.64\)</span>, por lo que
se rechaza la <span class="math inline">\(H_{0}\)</span>. Concluimos que la proporción de personas que
manifiestan elevado interés en la política ha disminuido de manera
significativa de un año al siguiente.</p>
<p>Como antes, puede alcanzarse la misma conclusión realizando los cálculos
con el valor crítico del estimador:</p>
<p><span class="math display">\[{\widehat{p}}_{c} = P - z_{c}*\sqrt{\frac{P*(1 - P)}{n}} = 0.11 - 1.64*\sqrt{\frac{0.11*(1 - 0.11)}{1200}} = 0.11 - 0.015 = 0.095\]</span></p>
<p>El valor observado de <span class="math inline">\({\widehat{p}}_{\text{obs}} = 0.093\)</span> resulta menor
a <span class="math inline">\({\widehat{p}}_{c} = 0.095\)</span>, por lo que se rechaza la <span class="math inline">\(H_{0}\)</span>. Se
concluye entonces que, en Argentina, la proporción de personas con alto
interés en la política en el año 2005 es significativamente menor a
0.11.</p>
</div>
<div id="tipos-de-error-en-las-pruebas-de-hipótesis" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Tipos de error en las pruebas de hipótesis<a href="#tipos-de-error-en-las-pruebas-de-hip%C3%B3tesis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dado que la decisión de aceptar o rechazar la <span class="math inline">\(H_{0}\)</span> se toma de manera
probabilística, siempre existe la posibilidad de tomar una decisión
incorrecta. Esto sucede porque las muestras son tomadas al azar y puede
suceder que la que usamos para tomar la decisión sea una muestra
extrema. Aunque es un resultado poco probable, no es imposible.</p>
<p>Como hemos visto, el nivel de significación mide la probabilidad de
hallar un determinado resultado muestral si la <span class="math inline">\(H_{0}\)</span> fuera cierta, es una
probabilidad pequeña, que habitualmente fijamos en 0.05 ó 0.01. Si la
<span class="math inline">\(H_{0}\)</span> es cierta y la muestra sobre la que basamos la decisión es extrema,
es decir, tiene un valor ubicado en alguna de las colas de la
distribución, la decisión será la de rechazar <span class="math inline">\(H_{0}\)</span> y esa decisión será
errónea. La decisión de rechazar puede deberse o bien a que <span class="math inline">\(H_{0}\)</span> sea
efectivamente falsa, o bien a que <span class="math inline">\(H_{0}\)</span> sea verdadera y se haya obtenido
una de esas muestras muy poco probables. Por esta razón el nivel de
significación mide la probabilidad de errar en la decisión de esta
manera: rechazando una <span class="math inline">\(H_{0}\)</span> que es verdadera. Al igual que en los
intervalos de confianza, éste no es un error de cálculo ni una
equivocación, sino una imprecisión inherente a todos los procesos de
estimación. Éste error se conoce como <strong>Error de Tipo I</strong> (ETI).</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">El <strong>Error de Tipo I</strong> es tomar una decisión errónea que consiste en rechazar la <span class="math inline">\(H_{0}\)</span> cuando esta es verdadera. Su probabilidad está fijada de antemano y es <span class="math inline">\(\alpha\)</span>, el nivel de significación de la prueba.</td>
</tr>
</tbody>
</table>
<p>En consecuencia, establecer <span class="math inline">\(\alpha\)</span> es afirmar que se está dispuesto a correr
ese riesgo de cometer el ETI. En un experimento que consiste en decidir
si una droga produce efectos sobre un determinada patología, la <span class="math inline">\(H_{0}\)</span> dirá
que no hay efecto, por lo que cometer el ETI será creer que hay efecto
(rechazar <span class="math inline">\(H_{0}\)</span>) cuando en realidad no lo haya (<span class="math inline">\(H_{0}\)</span> verdadera). Como no
sabemos si <span class="math inline">\(H_{0}\)</span> es verdadera o falsa, cada vez que rechacemos <span class="math inline">\(H_{0}\)</span>
debemos recordar que hay una probabilidad <span class="math inline">\(\alpha\)</span> de haber tomado una decisión
incorrecta. Esta incertidumbre está siempre presente en evaluación humana en los campos psicológico y educativo, así como en la evaluación de efectos e impactos de programas de intervención social, o en la comparación de grupos para conocer diferencias entre varones y mujeres, medir los efectos del nivel de educación, etc. En general, está presente en la toma de decisión en contextos de incertidumbre, que son aquellos en que no se conocce a todos los elementos de una población, sino a una muestra de ellos.</p>
<p>Ejemplo ilustrativo: las preguntas de un examen oral son una muestra de
lo que quien está rindiendo sabe y, si se usa un bolillero, la elección del tema que debe desarrollarse es aleatoria. Supongamos que alguien va a un examen y ha estudiado muy poco, pero la unidad que le toca desarrollar es la única que sí estudió.<br />
En ese caso responderá correctamente y la decisión del o la docente será darle por aprobado el examen. Si supiéramos que ignora todos
los demás temas de la materia, la decisión correcta sería que no
apruebe. La formalización de este problema es la siguiente: la
hipótesis nula es la conservadora, esto es, que quien rinde no sabe; será necesario sumar evidencia para que se tome la decisión de rechazar esa hipótesis y dar el examen por aprobado. La muestra de información que tiene el o la docente a su disposición (las unidades que salieron por azar) es correctamente desarrollada, lo que conduce a la
decisión de rechazar la <span class="math inline">\(H_{0}\)</span> y dar el examen por aprobado. Para quien tiene toda la información (que quien rindió solo sabía esa unidad del programa), se ha cometido un Error de Tipo I, pero el o la docente nunca lo sabrá. Si el programa tenía 20 unidades, la probabilidad de extraer la única bolilla que sabe es <span class="math inline">\(\frac{1}{20} = 0.05\)</span>, si la saca, se trata de una de esas “muestras extremas” que llevan a tomar la decisión incorrecta a la que llamamos Error de Tipo I.</p>
<p>En investigación nunca tenemos “toda la información”, trabajamos con muestras, por lo que nunca sabemos si, cuando rechazamos <span class="math inline">\(H_{0}\)</span> y concluimos que algo cambió o que hay un efecto, estamos cometiendo este error o no. Esta es la razón por la que <span class="math inline">\(\alpha\)</span> se elige con valores pequeños, pero no se
puede reducir indefinidamente el valor de <span class="math inline">\(\alpha\)</span>, porque también existe el riesgo de no rechazar <span class="math inline">\(H_{0}\)</span> siendo falsa.</p>
<p>Éste es otro tipo de error, que se llama <strong>Error de Tipo II</strong> (ETII) que sucede cuando no se rechaza una <span class="math inline">\(H_{0}\)</span>, siendo ésta falsa. En el experimento anterior, cometer este error consiste en creer que la droga no es efectiva (no rechazar <span class="math inline">\(H_{0}\)</span>) cuando en realidad sí tiene efectos (<span class="math inline">\(H_{0}\)</span> es falsa). En el ejemplo del examen, se trata de aplazar a alguien que rindió (aceptar <span class="math inline">\(H_{0}\)</span>) cuándo sí sabía, porque le tocó -a la inversa que en el caso anterior- una de las únicas bolillas que no había estudiado.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Se llama <strong>Error de Tipo II</strong> a la decisión equivocada de no rechazar una hipótesis nula cuando ésta es falsa.</td>
</tr>
</tbody>
</table>
<p>Según la prueba de que se trate, el costo de cometer cada tipo de error
es diferente. Si se trata de evaluar el efecto de una intervención
terapéutica, la <span class="math inline">\(H_{0}\)</span> dirá que no produce efectos. Entonces, cometer un
ETI equivaldrá a recomendar la intervención y que no produzca efecto.
Mientras que el ETII consistirá en desestimar una intervención que sí
tenía efectos. Si se trata de una intervención muy riesgosa, el ETI es
muy grave, porque implicará poner en peligro al paciente, por nada. Por
su parte, el ETII conlleva la pérdida del beneficio que la intervención
habría dado. La decisión sobre qué error es más grave debe tomarse en
cada caso y no pertenece al terreno de la estadística.</p>
<p>Esto se vincula a los errores a que están expuestas las pruebas
diagnósticas.</p>
<p>Cuando la prueba da un resultado positivo al ser aplicada a una persona sana, se llama <em>falso positivo</em>. De modo más general, esa expresión
indica que el error consiste en creer que “sucedió algo” cuando no fue
así y corresponde, en las pruebas de hipótesis, al ETI.</p>
<p>De modo equivalente, el resultado negativo de una prueba diagnóstica
aplicada a una persona que sí está enferma se llama <em>falso negativo</em>. Se
trata del error opuesto, porque cuando se comete se cree que “no sucedió nada” cuando en realidad sí sucedió. Es el ETII.</p>
<p>Si insistimos sobre estos errores es para llamar la atención sobre dos
aspectos fundamentales de las pruebas de hipótesis:</p>
<ul>
<li><p>Las conclusiones son probabilísticas, no son verdaderas ni falsas.</p></li>
<li><p>Toda conclusión proveniente de estos procedimientos está sujeta a error.</p></li>
</ul>
<p>Y estos no son problemas del procedimiento de prueba de hipótesis, sino que es reflejo de las posibilidades humanas de contruir conocimiento: no hay certezas, solo hay aproximaciones.</p>
</div>
<div id="etii-mu-alpha-y-n" class="section level2 hasAnchor" number="11.5">
<h2><span class="header-section-number">11.5</span> <em>ETII:</em> <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(n\)</span><a href="prueba-de-hipótesis-la-lógica.html#etii-mu-alpha-y-n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A diferencia del ETI, la probabilidad de cometer un ETII no es fijada de
antemano, al contrario, el riesgo de creer que <span class="math inline">\(H_{0}\)</span> es verdadera cuando
no lo es, depende de cuál sea la verdadera. Intuitivamente: no es
igualmente probable creer que no hay diferencia entre dos valores cuando
en realidad éstos son muy cercanos, que cuando difieren mucho, es más
fácil confundir cosas que están cerca (creyendo que son iguales) que
cuando están lejos.</p>
<p>Llamaremos <span class="math inline">\(\beta\)</span> a la probabilidad de cometer el ETII y veremos cómo
calcularla según las diferentes posibilidades del verdadero valor del
parámetro sobre el cual se realiza la prueba.</p>
<p>El gráfico <a href="prueba-de-hipótesis-la-lógica.html#fig:etii5">11.11</a> corresponde a una prueba de hipótesis unilateral derecha
sobre la media poblacional<a href="#fn79" class="footnote-ref" id="fnref79"><sup>79</sup></a>, con la forma:</p>
<p><span class="math display">\[H_{0}:\mu = \mu_{0}\]</span></p>
<p><span class="math display">\[H_{1}:\mu &gt; \mu_{0}\]</span></p>
<p>Donde <span class="math inline">\(\mu_{0}\)</span> es un valor determinado e hipotético para la media de la
población. En el gráfico se ha ubicado ése valor hipotético y la zona de
rechazo de <span class="math inline">\(H_0\)</span>, estableciendo el nivel de significación (<span class="math inline">\(\alpha\)</span>) en 0.05.
Además, hemos dibujado otra curva, centrada en otra media poblacional
que podría ser verdadera<a href="#fn80" class="footnote-ref" id="fnref80"><sup>80</sup></a>. Así, la curva superior representa la
distribución de probabilidad de <span class="math inline">\(\overline{x}\)</span> si <span class="math inline">\(H_0\)</span> fuera verdadera
(<span class="math inline">\(\mu = \mu_{0}\)</span>). La curva inferior muestra la distribución de
probabilidades de <span class="math inline">\(\overline{x}\)</span> si <span class="math inline">\(H_{0}\)</span> fuera falsa (<span class="math inline">\(\mu &gt; \mu_{0}\)</span>) y
la verdadera media poblacional fuera <span class="math inline">\(\mu_{1}\)</span> (que es una de las
posibles entre las mayores que <span class="math inline">\(\mu_{0}\)</span>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:etii5"></span>
<img src="imagenes/etii5.png" alt="Comparación de la probabilidad de hallar a $\overline{x}$ en zona de rechazo o no rechazo, según sea $H_{0}$ verdadera o falsa $(\alpha = 0.05)$" width="396" />
<p class="caption">
Figura 11.11: Comparación de la probabilidad de hallar a <span class="math inline">\(\overline{x}\)</span> en zona de rechazo o no rechazo, según sea <span class="math inline">\(H_{0}\)</span> verdadera o falsa <span class="math inline">\((\alpha = 0.05)\)</span>
</p>
</div>
<p>La parte superior del gráfico muestra que, si <span class="math inline">\(H_{0}\)</span> es verdadera,
<span class="math inline">\(\overline{x}\)</span> tiene una probabilidad <span class="math inline">\(\alpha\)</span> de estar en la zona de rechazo,
por lo que, si <span class="math inline">\(H_{0}\)</span> es verdadera y <span class="math inline">\(\overline{x}\)</span> está en esa zona,
tomaremos la decisión errada de rechazarla. El complemento del nivel de
significación (<span class="math inline">\(1-\alpha\)</span>), es la probabilidad de tomar la decisión correcta de no rechazar <span class="math inline">\(H_{0}\)</span> cuando ésta es verdadera. Es la probabilidad de hallar a <span class="math inline">\(\overline{x}\)</span> en la zona de no rechazo de <span class="math inline">\(H_{0}\)</span>.</p>
<p>En la parte inferior del gráfico vemos que, si <span class="math inline">\(H_{0}\)</span> es falsa, <span class="math inline">\(\overline{x}\)</span> tiene
probabilidad <span class="math inline">\(1-\beta\)</span> de estar en la zona de rechazo, lo que llevará a tomar
la decisión correcta de rechazar una <span class="math inline">\(H_{0}\)</span> falsa. Bajo el mismo supuesto de <span class="math inline">\(H_{0}\)</span> falsa, <span class="math inline">\(\beta\)</span> es el área correspondiente a la zona de no rechazo de <span class="math inline">\(H_{0}\)</span>, por lo que mide la probabilidad de errar aceptando una <span class="math inline">\(H_{0}\)</span> falsa.</p>
<p>Debido a que no podemos tener certeza acerca de la verdad o falsedad de
<span class="math inline">\(H_{0}\)</span>, es que se nos plantean dos posibles escenarios: que <span class="math inline">\(H_{0}\)</span> sea
verdadera o que sea falsa. En base a los datos con que contamos en la
muestra podemos tomar dos decisiones: rechazar <span class="math inline">\(H_{0}\)</span> o no rechazarla, con lo que la decisión que tomemos puede ser correcta o incorrecta.</p>
<p>Esquema 1: Posibles combinaciones de estados de realidad y decisión que
se toma. (Entre paréntesis, la probabilidad de cada evento):</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="1">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Estado de realidad
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Decisión
</div>
</th>
</tr>
<tr>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
No rechazar <span class="math inline">\(H_0\)</span>
</th>
<th style="text-align:center;">
Rechazar <span class="math inline">\(H_0\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(H_0\)</span> Verdadera
</td>
<td style="text-align:center;">
Decisión correcta (<span class="math inline">\(1-\alpha\)</span>)
</td>
<td style="text-align:center;">
Error de tipo I (<span class="math inline">\(\alpha\)</span>)
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(H_0\)</span> Falsa
</td>
<td style="text-align:center;">
Error de tipo II (<span class="math inline">\(\beta\)</span>)
</td>
<td style="text-align:center;">
Decisión correcta (1-<span class="math inline">\(\beta\)</span>)
</td>
</tr>
</tbody>
</table>
<p>La última celda del esquema corresponde a la decisión correcta de
rechazar una <span class="math inline">\(H_{0}\)</span> que es falsa, y se la denomina <strong>potencia de la prueba</strong>. Es un indicador de la capacidad de la prueba para detectar
hipótesis nulas que son falsas y rechazarlas.</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Se llama <strong>potencia de una prueba</strong> a la probabilidad de rechazar una <span class="math inline">\(H_{0}\)</span> cuando ésta es falsa.</td>
</tr>
</tbody>
</table>
<p>Es una importante medida de la calidad de la prueba, luego volveremos
sobre su cálculo, y en el último capítulo ofrecemos más detalles.</p>
<p>Así entonces, <span class="math inline">\(\alpha\)</span> es elegido en el marco de la investigación, según criterios del equipo y mide el riesgo que está dispuesto a correr de rechazar una <span class="math inline">\(H_{0}\)</span> que es verdadera. Por el contrario, <span class="math inline">\(\beta\)</span> depende de varios elementos:</p>
<p>En primer lugar, depende de <span class="math inline">\(\alpha\)</span>: si se reduce el nivel de significación, aumenta el riesgo de cometer
ETII.</p>
<p>Si se cambia el gráfico <a href="prueba-de-hipótesis-la-lógica.html#fig:etii5">11.11</a>, reduciendo el nivel de significación, ahora la posición relativa de las áreas de rechazo y no rechazo queda:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:etii1"></span>
<img src="imagenes/etii1.png" alt="Comparación de la probabilidad de hallar a $\overline{x}$ en zona de rechazo o no rechazo, según sea $H_{0}$ verdadera o falsa $(\alpha = 0.01)$" width="396" />
<p class="caption">
Figura 11.12: Comparación de la probabilidad de hallar a <span class="math inline">\(\overline{x}\)</span> en zona de rechazo o no rechazo, según sea <span class="math inline">\(H_{0}\)</span> verdadera o falsa <span class="math inline">\((\alpha = 0.01)\)</span>
</p>
</div>
<p>Como vemos, la reducción del nivel de significación del 5% al 1% hace
que el punto crítico se desplace hacia la derecha y, en consecuencia,
que aumente el área bajo la otra curva, que corresponde a <span class="math inline">\(H_{0}\)</span> falsa.
Este cambio consiste en hacer a la prueba más exigente, al reducir las
chances de rechazar <span class="math inline">\(H_{0}\)</span> por error, del 5 al 1%. Su consecuencia es la de aumentar las chances de aceptar <span class="math inline">\(H_{0}\)</span> por error, aumentando el valor de <span class="math inline">\(\beta\)</span>.</p>
<p>El ETII depende también de cuál sea la verdadera media poblacional. En
los gráficos <a href="prueba-de-hipótesis-la-lógica.html#fig:etii5">11.11</a> y <a href="prueba-de-hipótesis-la-lógica.html#fig:etii1">11.12</a> planteamos como “otra posibilidad” que la verdadera media fuera <span class="math inline">\(\mu_{1}\)</span>, que es una de las formas en que puede ser <span class="math inline">\(H_{0}\)</span> falsa.
Siendo <span class="math inline">\(H_{0}\)</span> falsa, <span class="math inline">\(\mu\)</span> puede tener distintos valores y ellos incidirán en la probabilidad de cometer ETII. En el gráfico siguiente, además de <span class="math inline">\(\mu_{1}\)</span> agregamos otras dos medias poblacionales posibles <span class="math inline">\(\mu_{2}\)</span> y <span class="math inline">\(\mu_{3}\)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:compHallarX"></span>
<img src="imagenes/image188.png" alt="Comparación de la probabilidad de hallar a $\overline{x}$ en zona de rechazo o no rechazo, según sea $H_0$ verdadera o falsa, de tres modos diferentes" width="588" />
<p class="caption">
Figura 11.13: Comparación de la probabilidad de hallar a <span class="math inline">\(\overline{x}\)</span> en zona de rechazo o no rechazo, según sea <span class="math inline">\(H_0\)</span> verdadera o falsa, de tres modos diferentes
</p>
</div>
<p>El gráfico muestra que si la verdadera media poblacional difiere mucho
de la hipotética (como es el caso de <span class="math inline">\(\mu_{3}\)</span>), es menor la probabilidad <span class="math inline">\(\beta\)</span> de cometer ETII: <span class="math inline">\(\beta\)</span> va decreciendo a medida que se consideran medias más alejadas de la que sostiene la <span class="math inline">\(H_{0}\)</span>. Ésta es una manera de formalizar la idea intuitiva que mencionamos más arriba: es más fácil aceptar un valor equivocado de <span class="math inline">\(\mu\)</span> si el verdadero se le parece, que si es muy diferente.
Más concreto aún: es más fácil aceptar por error un billete falso si se
le parece mucho al verdadero que si es muy distinto, y cuanto más difiera, menor será la probabilidad de aceptarlo por error.</p>
<p>El gráfico <a href="prueba-de-hipótesis-la-lógica.html#fig:compHallarX">11.13</a> también muestra que, de manera complementaria, <span class="math inline">\(1-\beta\)</span> (la potencia de la prueba), va creciendo a medida que se consideran medias alternativas más alejadas de la hipotética.</p>
<p>Volvamos al ejemplo (ficticio) sobre el promedio al egreso de una carrera universitaria en la prueba unilateral derecha, cuyas
hipótesis son:</p>
<p><span class="math display">\[H_{0}:\mu = 6.50\]</span></p>
<p><span class="math display">\[H_{1}:\mu &gt; 6.50\]</span></p>
<p>Preguntamos: si la verdadera media de nota al egreso fuera de 6.55, ¿cuál habría sido la probabilidad de haber
aceptado <span class="math inline">\(H_{0}\)</span>? Dicho de otra forma ¿qué probabilidad hay de creer que la media sigue siendo 6.50 si en realidad ha aumentado a 6.55? Se trata de calcular la probabilidad de cometer ETII, que consiste en aceptar una <span class="math inline">\(H_{0}\)</span> que es falsa. A un nivel de significación del 5%, el punto crítico que habíamos encontrado es 6.60, por lo que:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:etii"></span>
<img src="imagenes/image189.png" alt="Ubicación de los tipos de error de la prueba si $H_{0}$ es verdadera o si es falsa" width="507" />
<p class="caption">
Figura 11.14: Ubicación de los tipos de error de la prueba si <span class="math inline">\(H_{0}\)</span> es verdadera o si es falsa
</p>
</div>
<p>La probabilidad de ETII en este caso es el área bajo la curva inferior
que está por debajo del punto crítico, 6.60. Para calcular <span class="math inline">\(\beta\)</span> es
necesario hallar esa área bajo la curva normal centrada en 6.55, lo que
requiere que se lo transforme a puntaje <span class="math inline">\(z\)</span>:</p>
<p><span class="math display">\[z = \frac{6.60 - 6.55}{\frac{0.60}{\sqrt{100}}} = \frac{0.05}{0.06} = 0.83\]</span></p>
<p>Cuya área izquierda asociada es:</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="prueba-de-hipótesis-la-lógica.html#cb569-1" tabindex="-1"></a><span class="fu">pnorm</span>(.<span class="dv">83</span>)</span></code></pre></div>
<pre><code>## [1] 0.7967306</code></pre>
<p><span class="math inline">\(P(z \leq 0.83)=0.7967\)</span></p>
<p>Éste es el valor de <span class="math inline">\(\beta\)</span> para esta prueba y esta media alternativa. Leemos
el resultado diciendo que: “si el verdadero promedio al egreso fuera de 6.55, habría una probabilidad de 0.7967 de creer que sigue siendo igual al histórico, de 6.60”.</p>
<p>Calculamos la potencia de esta prueba, como el complemento de <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math inline">\(Potencia = 1-\beta = 1-0.7967 = 0.2033\)</span></p>
<p>Esta potencia es la probabilidad de detectar una diferencia de 0.05
entre la media real y la hipotética (es la diferencia entre 6.50 y 6.55) a un nivel de significación del 5%, con una muestra de 100
observaciones. Estos cuatro elementos: magnitud de la diferencia, tamaño de la muestra, nivel de significación y potencia están vinculados entre sí y deben tenerse en cuenta al planificar un estudio que vaya a usar pruebas de hipótesis.</p>
<div id="curva-de-potencia" class="section level3 hasAnchor" number="11.5.1">
<h3><span class="header-section-number">11.5.1</span> Curva de potencia<a href="prueba-de-hipótesis-la-lógica.html#curva-de-potencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dado que no se conoce la verdadera media de la población, solo podemos
conjeturar acerca de ella y calcular el ETII (<span class="math inline">\(\beta\)</span>) y la potencia (<span class="math inline">\(1-\beta\)</span>) para diferentes valores posibles, como hemos hecho para tres valores en el gráfico <a href="prueba-de-hipótesis-la-lógica.html#fig:compHallarX">11.13</a>. En general, resulta más valioso calcular la potencia (<span class="math inline">\(1-\beta\)</span>) porque nos informa sobre la calidad de la prueba. El cálculo es largo
porque deben seguirse los mismos pasos que en el ejemplo anterior para
cada una de las medias posibles, pero podemos automatizarlo en una hoja
de cálculo. La tabla para calcular la potencia de la prueba anterior se
construye manteniendo el punto crítico fijo en 6.60 (y también la
desviación estándar y el tamaño de la muestra), y calculando el puntaje
<span class="math inline">\(z\)</span> correspondiente a ese valor “desde” diferentes medias poblacionales
alternativas, a las que hemos llamado <span class="math inline">\(\mu_{k}\)</span>. Así resulta:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Media alternativa <span class="math inline">\(\mu_{k}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(z = \frac{6.60 - \mu_{k}}{\frac{0.60}{\sqrt{100}}}\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(\beta\)</span>
</th>
<th style="text-align:center;">
<span class="math inline">\(1 - \beta\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
6.51
</td>
<td style="text-align:center;">
1.50
</td>
<td style="text-align:center;">
0.9332
</td>
<td style="text-align:center;">
0.0668
</td>
</tr>
<tr>
<td style="text-align:center;">
6.53
</td>
<td style="text-align:center;">
1.17
</td>
<td style="text-align:center;">
0.8783
</td>
<td style="text-align:center;">
0.1217
</td>
</tr>
<tr>
<td style="text-align:center;">
6.55
</td>
<td style="text-align:center;">
0.83
</td>
<td style="text-align:center;">
0.7977
</td>
<td style="text-align:center;">
0.2023
</td>
</tr>
<tr>
<td style="text-align:center;">
6.57
</td>
<td style="text-align:center;">
0.50
</td>
<td style="text-align:center;">
0.6915
</td>
<td style="text-align:center;">
0.3085
</td>
</tr>
<tr>
<td style="text-align:center;">
6.59
</td>
<td style="text-align:center;">
0.17
</td>
<td style="text-align:center;">
0.5662
</td>
<td style="text-align:center;">
0.4338
</td>
</tr>
<tr>
<td style="text-align:center;">
6.61
</td>
<td style="text-align:center;">
-0.17
</td>
<td style="text-align:center;">
0.4338
</td>
<td style="text-align:center;">
0.5662
</td>
</tr>
<tr>
<td style="text-align:center;">
6.63
</td>
<td style="text-align:center;">
-0.50
</td>
<td style="text-align:center;">
0.3085
</td>
<td style="text-align:center;">
0.6915
</td>
</tr>
<tr>
<td style="text-align:center;">
6.65
</td>
<td style="text-align:center;">
-0.83
</td>
<td style="text-align:center;">
0.2023
</td>
<td style="text-align:center;">
0.7977
</td>
</tr>
<tr>
<td style="text-align:center;">
6.67
</td>
<td style="text-align:center;">
-1.17
</td>
<td style="text-align:center;">
0.1217
</td>
<td style="text-align:center;">
0.8783
</td>
</tr>
<tr>
<td style="text-align:center;">
6.69
</td>
<td style="text-align:center;">
-1.50
</td>
<td style="text-align:center;">
0.0668
</td>
<td style="text-align:center;">
0.9332
</td>
</tr>
<tr>
<td style="text-align:center;">
6.71
</td>
<td style="text-align:center;">
-1.83
</td>
<td style="text-align:center;">
0.0334
</td>
<td style="text-align:center;">
0.9666
</td>
</tr>
<tr>
<td style="text-align:center;">
6.73
</td>
<td style="text-align:center;">
-2.17
</td>
<td style="text-align:center;">
0.0151
</td>
<td style="text-align:center;">
0.9849
</td>
</tr>
<tr>
<td style="text-align:center;">
6.75
</td>
<td style="text-align:center;">
-2.50
</td>
<td style="text-align:center;">
0.0062
</td>
<td style="text-align:center;">
0.9938
</td>
</tr>
<tr>
<td style="text-align:center;">
6.77
</td>
<td style="text-align:center;">
-2.83
</td>
<td style="text-align:center;">
0.0023
</td>
<td style="text-align:center;">
0.9977
</td>
</tr>
<tr>
<td style="text-align:center;">
6.79
</td>
<td style="text-align:center;">
-3.17
</td>
<td style="text-align:center;">
0.0008
</td>
<td style="text-align:center;">
0.9992
</td>
</tr>
<tr>
<td style="text-align:center;">
6.81
</td>
<td style="text-align:center;">
-3.50
</td>
<td style="text-align:center;">
0.0002
</td>
<td style="text-align:center;">
0.9998
</td>
</tr>
<tr>
<td style="text-align:center;">
6.83
</td>
<td style="text-align:center;">
-3.83
</td>
<td style="text-align:center;">
0.0001
</td>
<td style="text-align:center;">
0.9999
</td>
</tr>
<tr>
<td style="text-align:center;">
6.85
</td>
<td style="text-align:center;">
-4.17
</td>
<td style="text-align:center;">
0.0000
</td>
<td style="text-align:center;">
1.0000
</td>
</tr>
<tr>
<td style="text-align:center;">
6.87
</td>
<td style="text-align:center;">
-4.50
</td>
<td style="text-align:center;">
0.0000
</td>
<td style="text-align:center;">
1.0000
</td>
</tr>
</tbody>
</table>
<p>Resultan así diferentes valores para la potencia, uno para cada media
posible y vemos, ahora numéricamente, como disminuye el riesgo de
aceptar <span class="math inline">\(H_0\)</span> a medida que la verdadera media es más lejana. Al mismo
tiempo, aumenta la probabilidad de rechazar <span class="math inline">\(H_0\)</span> (aumenta la potencia).
Esos resultados se representan gráficamente en lo que se denomina
<strong>curva de potencia</strong>. Para el ejemplo anterior, la curva de potencia es
la de la figura <a href="prueba-de-hipótesis-la-lógica.html#fig:pot1">11.15</a>.</p>
<div class="figure"><span style="display:block;" id="fig:pot1"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/pot1-1.svg" alt="Curva de potencia con $\mu_{0} = 6.50$, $\alpha = 0.05$ y $n = 100$" width="672" />
<p class="caption">
Figura 11.15: Curva de potencia con <span class="math inline">\(\mu_{0} = 6.50\)</span>, <span class="math inline">\(\alpha = 0.05\)</span> y <span class="math inline">\(n = 100\)</span>
</p>
</div>
<p>En el eje horizontal se ubican las posibles medias poblacionales (las
distintas <span class="math inline">\(\mu_{k}\)</span>) y en el vertical, la potencia asociada a cada una
de ellas. Vemos que si la verdadera media es la hipotética
(<span class="math inline">\(\mu = 6.50\)</span>), la probabilidad de rechazarla es <span class="math inline">\(\alpha\)</span>, y esa probabilidad
aumenta a medida que se consideran medias más lejanas a <span class="math inline">\(\mu_{0}\)</span>. Si la
verdadera media poblacional fuera tan lejana como 6.90, la probabilidad
de rechazar <span class="math inline">\(H_{0}\)</span> es casi 1, lo que indica que es casi seguro que se
rechazará esa hipótesis.</p>
<p>Dijimos antes que la potencia es una medida de la calidad de la prueba,
en efecto, cuanto más rápidamente crezca esta curva, tanto más sensible
será la prueba, porque será más probable detectar hipótesis nulas que
son falsas y rechazarlas. Dicho de otro modo, será alta la probabilidad
de rechazar una hipótesis nula si la verdadera media difiere -aunque sea
poco-, de la hipotética.</p>
<p>La forma de la curva de potencia depende de varios factores, de los que
solo nos detendremos en el tamaño de la muestra. Con muestras más
grandes, si todo lo demás se mantiene sin cambios, la potencia de la
prueba aumenta. Inversamente, muestras pequeñas reducen la potencia.</p>
<p>Veamos esto gráficamente, si la muestra fuera de menor tamaño que la del ejemplo, como <em>n=50</em>, la curva de potencia es la de la figura <a href="prueba-de-hipótesis-la-lógica.html#fig:pot2">11.16</a>:</p>
<div class="figure"><span style="display:block;" id="fig:pot2"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/pot2-1.svg" alt="Curva de potencia con $\mu_{0} = 6.50$, $\alpha = 0.05$ y $n = 50$" width="672" />
<p class="caption">
Figura 11.16: Curva de potencia con <span class="math inline">\(\mu_{0} = 6.50\)</span>, <span class="math inline">\(\alpha = 0.05\)</span> y <span class="math inline">\(n = 50\)</span>
</p>
</div>
<p>Igual que antes, en 6.50, la probabilidad de rechazo es 0.05, que es <span class="math inline">\(\alpha\)</span>.
Pero cuando consideramos valores más lejanos de la media poblacional, la
curva sube con más lentitud que la anterior, podríamos decir que “tarda
más en reaccionar”, son necesarios alejamientos más grandes para que
crezca la probabilidad de rechazo.</p>
<p>Por el contrario, si se trata de una muestra de mayor tamaño, como 200
casos, la curva tiene la forma de la figura <a href="prueba-de-hipótesis-la-lógica.html#fig:pot3">11.17</a>:</p>
<div class="figure"><span style="display:block;" id="fig:pot3"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/pot3-1.svg" alt="Curva de potencia con $\mu_{0} = 6.50$, $\alpha = 0.05$ y $n = 200$" width="672" />
<p class="caption">
Figura 11.17: Curva de potencia con <span class="math inline">\(\mu_{0} = 6.50\)</span>, <span class="math inline">\(\alpha = 0.05\)</span> y <span class="math inline">\(n = 200\)</span>
</p>
</div>
<p>Que muestra un aumento más rápido de la probabilidad de rechazar una
<span class="math inline">\(H_0\)</span> cuando ésta es falsa.</p>
<p>Es importante destacar que la potencia no depende del resultado
observado en la muestra, por el contrario, es un indicador de la calidad
de la prueba como tal, independientemente de lo que se encuentre en la
muestra. Por esta razón, el análisis de la potencia se realiza al
momento de planificar un experimento. Tiene mucha importancia para
calcular el tamaño de muestra necesario para detectar una determinada
diferencia entre grupos.</p>
<p>Existen índices para estandarizar la distancia entre el verdadero valor
del parámetro y el hipotético. Esos índices permiten comparar entre
pruebas de diferente naturaleza (porque están estandarizados), se
denominan <em>medidas del tamaño del efecto.</em> Ellis (2010) provee un
tratamiento detallado de este tema, en el apéndice regresaremos sobre
ellas.</p>
</div>
<div id="significación-estadística-y-valor-p" class="section level3 hasAnchor" number="11.5.2">
<h3><span class="header-section-number">11.5.2</span> Significación estadística y valor <span class="math inline">\(p\)</span><a href="#significaci%C3%B3n-estad%C3%ADstica-y-valor-p" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hasta este punto se ha indicado que el equipo de investigación establece el nivel
de significación estadística al realizar una prueba de hipótesis, a
partir de lo cual se determinan zonas de rechazo y no rechazo de la
hipótesis nula y que esto puede hacerse sobre valores estandarizados o
del estimador. Luego, una vez obtenido el resultado de la muestra, se
indica en qué zona se ubica, y se decide si se acepta o rechaza la <span class="math inline">\(H_{0}\)</span>.
La forma en que se comunican los resultados es, por ejemplo: “se rechaza
la <span class="math inline">\(H_{0}\)</span> a un nivel del 5%”. De modo que, como hemos dicho, se establece
una regla de decisión y en base a ella se decide por sí o por no.</p>
<p>En una prueba unilateral derecha al 5%, el puntaje <span class="math inline">\(z\)</span> que determina el
punto de corte entre las zonas de rechazo y no rechazo es <span class="math inline">\(z_{c}=1.64\)</span>, por lo que, si se obtiene un <span class="math inline">\(z_{obs}= 2\)</span>, se rechaza
<span class="math inline">\(H_{0}\)</span> y también se rechaza si se obtiene <span class="math inline">\(z_{obs}= 3.20\)</span>, porque ambos son
superiores al punto crítico. Sin embargo, encontrar <span class="math inline">\(z_{obs}= 3.20\)</span> indica que
el valor observado se aleja en gran magnitud del hipotético, mientras
que si <span class="math inline">\(z_{obs}= 2\)</span>, se rechaza más cerca del límite. Entre dos situaciones,
que ambas llevan a rechazar <span class="math inline">\(H_{0}\)</span>, puede haber diferencias de
importancia; por eso es necesaria una medida de la magnitud de la
diferencia. Para ver esto gráficamente, se denomina <span class="math inline">\(z_{obs}^{(a)}\)</span> y <span class="math inline">\(z_{obs}^{(b)}\)</span> a dos puntajes <span class="math inline">\(z_{obs}\)</span> obtenidos de la estandarización de los resultados de dos observaciones diferentes:</p>
<div class="figure"><span style="display:block;" id="fig:dosz"></span>
<img src="EstadisticaParaCienciasSocialesConR_files/figure-html/dosz-1.svg" alt="Ejemplo de dos valores posibles de $z_{obs}$ que conducen a rechazar $H_0$" width="672" />
<p class="caption">
Figura 11.18: Ejemplo de dos valores posibles de <span class="math inline">\(z_{obs}\)</span> que conducen a rechazar <span class="math inline">\(H_0\)</span>
</p>
</div>
<p>Aunque los dos valores de <span class="math inline">\(z_{obs}\)</span> llevan a concluir que se debe rechazar la
<span class="math inline">\(H_{0}\)</span> (porque ambos están en la zona de rechazo), el valor <span class="math inline">\(3.20\)</span> es
sustancialmente menos probable que el <span class="math inline">\(2\)</span>, por lo que podríamos decir
que en ese caso (<span class="math inline">\(z_{obs}=3.20\)</span>) tenemos <em>más</em> evidencia para rechazar
<span class="math inline">\(H_{0}\)</span>, sin embargo, si solo informamos que “se rechaza <span class="math inline">\(H_{0}\)</span> a un nivel
del 5%”, quien lee no puede saber si se trató de una diferencia grande o
pequeña.</p>
<p>El modo en que se transmite esta información es ofreciendo el <strong>valor de probabilidad</strong> asociado al resultado muestral, que también se llama
<strong>valor <span class="math inline">\(p\)</span></strong>. Se trata de la probabilidad de observar en la experiencia
un resultado igual o más extremo que el obtenido a partir de los datos
muestrales, bajo el supuesto de que la hipótesis nula es cierta. Es
decir, la probabilidad de hallar un resultado como el que se encontró o
más extremo que él, solo por azar. Un valor <span class="math inline">\(p\)</span> pequeño indica que el
resultado observado (o resultados más extremos que él) son poco
probables bajo el supuesto de hipótesis nula cierta, por lo cual hay
evidencia en contra de la hipótesis nula.</p>
<p>El valor <span class="math inline">\(p\)</span> es una probabilidad condicional a la que escribimos
formalmente como:</p>
<p><span class="math display">\[p=P( |u| \geq u_{obs}/H_{0}  V )\]</span></p>
<p>Donde <span class="math inline">\(u\)</span> es el estimador del parámetro al que se refiere la <span class="math inline">\(H_{0}\)</span>. La
expresión <span class="math inline">\(|u| \geq u_{obs}\)</span> es la forma reducida de
decir que <span class="math inline">\(u\)</span> sea más extrema (por encima o por debajo) que el valor
observado.</p>
<p>Cuanto más pequeño es el valor <span class="math inline">\(p\)</span>, tanta más evidencia hay para
rechazar <span class="math inline">\(H_{0}\)</span>. Por el contrario, un valor <span class="math inline">\(p\)</span> grande indica que el
resultado observado es muy probable bajo el supuesto de hipótesis nula
cierta, lo que no aporta evidencia en contra de la hipótesis nula y
conduce a no rechazarla. El uso del valor <span class="math inline">\(p\)</span> es más cercano al enfoque original de Fisher, el cual, a diferencia del de Neyman y Pearson, no establece un punto de corte para tomar una decisión dicotómica, sino que <em>mide</em> la “fuerza de la evidencia” en contra de <span class="math inline">\(H_0\)</span> por medio de una probabilidad. Pero esa probabilidad no está asociada a <span class="math inline">\(H_0\)</span>, lo cual es un error de interpretación frecuente, sino a los valores muestrales.</p>
<p>Esta manera de indicar cuán esperable sería lo que hemos observado si <span class="math inline">\(H_{0}\)</span> fuera cierta, puede vincularse con el razonamiento anterior, comparando el valor <span class="math inline">\(p\)</span> con el nivel de significación fijado de antemano. Así resultan dos posibilidades:</p>
<ul>
<li><p>Si el valor <span class="math inline">\(p\)</span> es menor que el nivel de significación establecido
(<span class="math inline">\(p&lt;\alpha\)</span>): se rechaza la hipótesis nula y se describe como “un
resultado estadísticamente significativo”. Esto quiere decir que la
probabilidad de haber hallado este resultado por azar es pequeña, por lo
que se trata de un efecto o diferencia que muy difícilmente se puede
atribuir al azar.</p></li>
<li><p>Si el valor <span class="math inline">\(p\)</span> es mayor que el nivel de significación establecido
(<span class="math inline">\(p&gt;\alpha\)</span>): no se rechaza la hipótesis nula y se expresa como “un
resultado no estadísticamente significativo”. Lo que expresa que la
probabilidad de haber hallado este resultado por azar es mayor que el
máximo establecido, por lo que es razonable atribuirlo al azar, es decir a la variabilidad propia de los resultados muestrales.</p></li>
</ul>
<p>Es decir, se trata de dicotomizar el continuo del campo de variación de <span class="math inline">\(p\)</span>, que es <span class="math inline">\(0\geq p\geq1\)</span> a que sea mayor o menor que <span class="math inline">\(\alpha\)</span>.<br />
Pero aun cuando esta modalidad de presentar el resultado puede hacerse
equivalente a la toma de decisión por sí o por no, constituye un aporte importante de información, porque pasa de la conclusión
dicotómica (se rechaza o no se rechaza) a la probabilidad de hallar este resultado si la hipótesis nula fuera cierta.</p>
<p>A continuación calculamos estas probabilidades en los ejemplos vistos,
empezando por pruebas unilaterales:</p>
<p>En el ejemplo sobre el promedio al egreso de una carrera universitaria:</p>
<p><span class="math display">\[H_{0}:\mu = 6.50\]</span></p>
<p><span class="math display">\[H_{1}:\mu &gt; 6.50\]</span></p>
<p>En la muestra de 100 estudiantes habíamos hallado
<span class="math inline">\({\overline{x}}_{\text{obs}} = 6.65\)</span> y <span class="math inline">\(s = 0.60\)</span>, con esos datos
debe calcularse la probabilidad de hallar “un valor tan extremo como el
observado o más extremo que él, si <span class="math inline">\(H_{0}\)</span> es verdadera”. Se trata de una
probabilidad condicional, en la que la condición es que <span class="math inline">\(H_{0}\)</span> sea
verdadera, lo escribimos así:</p>
<p><span class="math display">\[P\left( \overline{x} \geq 6.65/\mu = 6.50 \right)\]</span></p>
<p>Que expresa la probabilidad de coincidir con 6.65 o superarlo (se trata
de una prueba unilateral derecha, por eso usamos el signo <span class="math inline">\(\geq\)</span>), si la
media poblacional fuera la hipotética (6.50). Para encontrar la
probabilidad, transformamos <span class="math inline">\(\overline{x}\)</span> a puntaje <span class="math inline">\(z\)</span>:</p>
<p><span class="math display">\[z = \frac{6.65 - 6.50}{\frac{0.60}{\sqrt{100}}} = \frac{0.15}{0.06} = 2.50\]</span></p>
<p>Entonces debemos hallar <span class="math inline">\(P( z \geq 2.50 )\)</span> y ya no hace falta
indicar la condición (si <span class="math inline">\(\mu = 6.50\)</span>), porque está incluida en el
cálculo de <span class="math inline">\(z\)</span>. Para eso complementamos la probabilidad acumulada hasta <span class="math inline">\(2.50\)</span>:</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="prueba-de-hipótesis-la-lógica.html#cb571-1" tabindex="-1"></a><span class="fu">round</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">2.5</span>), <span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.0062</code></pre>
<p><span class="math display">\[P( z \geq 2.50) = 0.0062\]</span></p>
<p>Ese es el valor <span class="math inline">\(p\)</span>, e indica cuál es la probabilidad de encontrar un
valor como el observado o uno más extremo que él, si la <span class="math inline">\(H_{0}\)</span> fuera
verdadera. Vemos que se trata de un valor pequeño, es menor a 0.05 y
también menor a 0.01, por lo que podemos decir que la <span class="math inline">\(H_{0}\)</span> se rechaza a
un nivel del 5% y también del 1%. Pero además de esto, comunicamos el
valor <span class="math inline">\(p\)</span> obtenido, porque eso da al lector una idea más completa de
nuestro resultado.</p>
<p>Para el caso de la proporción, consideremos la segunda parte del ejemplo
del candidato, cuando usamos una muestra grande:</p>
<p><span class="math display">\[H_{0}:P = 0.30\]</span></p>
<p><span class="math display">\[H_{1}:P &gt; 0.30\]</span></p>
<p>En la muestra de <span class="math inline">\(n = 200\)</span> casos habíamos hallado
<span class="math inline">\({\widehat{p}}_{\text{obs}} = 0.32\)</span>.</p>
<p>Por tratarse de una prueba unilateral derecha, necesitamos conocer la
probabilidad condicional de hallar un valor como el observado -o más
extremo que éste-, si fuera verdadera <span class="math inline">\(H_{0}\)</span></p>
<p><span class="math display">\[P( \widehat{p} \geq 0.32/P = 0.30)\]</span></p>
<p>Para calcular esta probabilidad transformamos el valor de <span class="math inline">\(\widehat{p}\)</span>
a puntaje <span class="math inline">\(z\)</span>:</p>
<p><span class="math display">\[z = \frac{\widehat{p} - P}{\sqrt{\frac{P*(1 - P)}{n}}} = \frac{0.32 - 0.30}{\sqrt{\frac{0.30*(1 - 0.30)}{200}}} = 0.617\]</span></p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="prueba-de-hipótesis-la-lógica.html#cb573-1" tabindex="-1"></a><span class="fu">round</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(.<span class="dv">617</span>), <span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.2686</code></pre>
<p><span class="math display">\[P( \widehat{p} \geq 0.32/P = 0.30)=0.2686\]</span>
Se trata de una probabilidad “grande”, si se compara con los niveles de
significación que usamos, es superior a 0.05 y también superior a 0.10,
por lo que la decisión será la de no rechazar <span class="math inline">\(H_{0}\)</span> y concluir que el
candidato no mejoró su proporción de votos.</p>
<p>En el mismo ejemplo, cuando se trabaja con la muestra pequeña, no es
válida la aproximación normal, por lo que debe usarse la binomial. El
cálculo del valor <span class="math inline">\(p\)</span> es equivalente, solo que se realiza en términos de
la variable <em>número de éxitos</em>. En el ejemplo, el número observado de
éxitos era de 16, la probabilidad condicional que corresponde al valor <span class="math inline">\(p\)</span> es entonces la probabilidad de hallar en la muestra de 50 casos, 16
personas o más que vayan a votar al candidato, si en la población la
proporción de quienes lo votarán fuera de 30% (<span class="math inline">\(H_0\)</span> verdadera). Se complementa la probabilildad acumulada hasta 15 (variable dicreta):</p>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="prueba-de-hipótesis-la-lógica.html#cb575-1" tabindex="-1"></a><span class="fu">round</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">pbinom</span>(<span class="dv">15</span>, <span class="dv">50</span>, .<span class="dv">3</span>), <span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.4308</code></pre>
<p><span class="math display">\[P(\widehat{x} \geq 16/n = 50,\ P = 0.30) = 0.4308\]</span></p>
<p>Nuevamente es un valor elevado para p, por lo que no se rechaza <span class="math inline">\(H_{0}\)</span>.</p>
<p>Los software de análisis de datos ofrecen, como resultado de las pruebas
de hipótesis este valor, a veces llamado <span class="math inline">\(p\)</span>, <span class="math inline">\(p-value\)</span>, <span class="math inline">\(valor \, p\)</span> o <span class="math inline">\(significacion\)</span>; y es en él que hay que basar la decisión.</p>
</div>
</div>
<div id="muestras-pequeñas-y-pruebas-t" class="section level2 hasAnchor" number="11.6">
<h2><span class="header-section-number">11.6</span> Muestras pequeñas y pruebas <span class="math inline">\(t\)</span><a href="#muestras-peque%C3%B1as-y-pruebas-t" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Se ha mencionado que la distribución <em>t de Student</em>, es un modelo de
probabilidades con una forma similar a la distribución normal, pero más
aplanada y dependiente de un dato al que se llama “grados de libertad”.
Estos grados de libertad dependen del número de casos que haya en la
muestra. También se indicó que a medida que los grados de libertad
aumentan, la curva <span class="math inline">\(t\)</span> tiende a asemejarse más a la normal. De modo que
si se trata de muestras grandes, la distribución <span class="math inline">\(t\)</span> es muy similar a la
normal. Esto se denomina convergencia de la distribución <span class="math inline">\(t\)</span> hacia la
normal.</p>
<p>Vamos a usar esa distribución en las pruebas de hipótesis cuando
trabajemos con muestras pequeñas, pero con una restricción. En aquellos
casos en que sea posible suponer que la variable de origen (en la
población) tiene distribución normal, entonces la distribución de las
medias muestrales es adecuadamente modelada por la distribución <span class="math inline">\(t\)</span>.
Dicho de otro modo: si la variable tiene -en la población-, distribución
normal, entonces las medias muestrales, cuando se trate de muestras
pequeñas, tienen <em>distribución t</em>. Nos encontramos así con distintas
situaciones, de acuerdo al tamaño de la muestra y a la normalidad o no
de la variable en la población.</p>
<p>Muestras grandes: Por el teorema central del límite, estamos autorizados
a usar distribución normal para la media muestral, sin importar cuál sea
la distribución de la variable en la población.</p>
<p>Muestras pequeñas: Si la variable tiene distribución paramétrica normal (es decir si tiene esa distribución en la población), usamos distribución <em>t de Student</em>, con <span class="math inline">\(n-1\)</span> grados de libertad para modelar la distribución de las <span class="math inline">\(\bar{x}\)</span>.</p>
<p>De estas dos condiciones (tamaño de muestra y normalidad de la variable
en la población) resultan cuatro combinaciones:</p>
<table>
<colgroup>
<col width="30%" />
<col width="37%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th>Tamaño de muestra</th>
<th>Distribución paramétrica</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>.</td>
<td><strong>Normal</strong></td>
<td><strong>No normal</strong></td>
</tr>
<tr class="even">
<td>grande (<span class="math inline">\(n \geq 30\)</span>)</td>
<td>distribución normal</td>
<td>Por TCL tiende a normal</td>
</tr>
<tr class="odd">
<td>pequeña (<span class="math inline">\(n &lt; 30\)</span>)</td>
<td>distribución <em>t de Student</em></td>
<td>Ninguna<a href="#fn81" class="footnote-ref" id="fnref81"><sup>81</sup></a></td>
</tr>
</tbody>
</table>
<p>De modo que hay una situación que no podemos abordar con estos
procedimientos: la de muestras pequeñas provenientes de poblaciones no
normales, para ellas disponemos de procedimientos llamados “no
paramétricos” de los que nos ocuparemos más adelante. Las demás
combinaciones pueden todas ellas resolverse con la distribución <span class="math inline">\(t\)</span> que
es específica en el caso de muestras pequeñas y es equivalente a la
normal cuando la muestra es grande (porque lo son los grados de
libertad).</p>
<p>Por esta razón, en la mayoría de los paquetes informáticos de análisis
de datos, se habla de <em>pruebas t</em> de manera genérica para las pruebas
sobre la media, y el estadístico de prueba constituye un valor <span class="math inline">\(t\)</span> en
lugar de <span class="math inline">\(z\)</span>. La lógica es exactamente la que hemos seguido en este
capítulo, solo que el programa hace las cuentas usando la distribución
<span class="math inline">\(t\)</span> que, cuando se trabaja con una muestra grande, da el mismo resultado
que la normal.</p>
<p>Además de operar internamente con la distribución <em>t de Student</em>, los
programas de análisis de datos ofrecen los resultados de las pruebas de
hipótesis siempre en términos del valor <span class="math inline">\(p\)</span>. Eso permite que quien lee
la salida pueda decidir si rechaza o no rechaza la <span class="math inline">\(H_{0}\)</span>, de acuerdo al
nivel de significación que haya fijado. Para facilitar la interpretación, los programas de análisis de datos indican la “fuerza de la evidencia”, que se espresa en cuán pequeño es el valor <span class="math inline">\(p\)</span>, con asteriscos <span class="math inline">\(*\)</span> simples, dobles, etc. La interpretación es la siguiente:</p>
<table>
<thead>
<tr class="header">
<th>Símbolo</th>
<th>Significado</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(ns\)</span></td>
<td><span class="math inline">\(p \geq 0.05\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(*\)</span></td>
<td><span class="math inline">\(p \leq 0.05\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(**\)</span></td>
<td><span class="math inline">\(p \leq 0.01\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(***\)</span></td>
<td><span class="math inline">\(p \leq 0.001\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(****\)</span></td>
<td><span class="math inline">\(p \leq 0.0001\)</span></td>
</tr>
</tbody>
</table>
<p>La recomendación de <span class="citation">APA (<a href="#ref-APA2010">2010</a>)</span> es hasta tres asteriscos, todos los valores <span class="math inline">\(p\)</span> menores a <span class="math inline">\(0.001\)</span> se codifican con <span class="math inline">\(***\)</span></p>
<div style="page-break-after: always;"></div>
</div>
<div id="hacerlo-en-r-9" class="section level2 hasAnchor" number="11.7">
<h2><span class="header-section-number">11.7</span> Hacerlo en R<a href="prueba-de-hipótesis-la-lógica.html#hacerlo-en-r-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="prueba-sobre-la-media-1" class="section level3 hasAnchor" number="11.7.1">
<h3><span class="header-section-number">11.7.1</span> Prueba sobre la media<a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-media-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea el caso de una prueba de hipótesis acerca del promedio del número de hijas e hijos por mujer en una comunidad dada. Se busca evidencia para decidir si, según los datos de una muestra de 150 casos, la población de la que esa muestra proviene tiene en promedio dos hijos e hijas por mujer o si ese promedio es mayor a 2. En la muestra de 150 observaciones se obtuvieron las siguientes medidas descriptivas (los datos son ficticios, por lo que se generan aleatoriamente a partir de una distribución normal, la variable se llama <span class="math inline">\(x\)</span>):</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="prueba-de-hipótesis-la-lógica.html#cb577-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">13</span>)</span>
<span id="cb577-2"><a href="prueba-de-hipótesis-la-lógica.html#cb577-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">150</span>, <span class="fl">2.15</span>, <span class="dv">1</span>)</span></code></pre></div>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="prueba-de-hipótesis-la-lógica.html#cb578-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">mean</span>(x), <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 2.09</code></pre>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="prueba-de-hipótesis-la-lógica.html#cb580-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">sd</span>(x), <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.95</code></pre>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="prueba-de-hipótesis-la-lógica.html#cb582-1" tabindex="-1"></a><span class="fu">length</span>(x)</span></code></pre></div>
<pre><code>## [1] 150</code></pre>
<p>Con el valor muestral de 2.09, la pregunta es si se trata de evidencia suficiente como para afirmar que la media poblacional supera al valor de dos hijos e hijas por mujer.
Las hipótesis entonces son:</p>
<p><span class="math display">\[H_{0}:\ \mu = 2\]</span></p>
<p><span class="math display">\[H_{0}:\ \mu &gt; 2\]</span></p>
<p>El comando para solicitar la prueba es t.test al que hay que informar, la variable (proveniente de una matriz de datos), el valor de la media bajo la hipótesis nula y la lateralidad de la prueba. Para esto último,las opciones son:</p>
<ul>
<li>Bilateral: alternative = “two.sided”</li>
<li>Unilateral derecha: alternative = “greater”</li>
<li>Unilateral izquierda: alternative = “less”</li>
</ul>
<p>Así, la prueba se pide:</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb584-1"><a href="prueba-de-hipótesis-la-lógica.html#cb584-1" tabindex="-1"></a><span class="fu">t.test</span>(x, <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>, <span class="at">mu =</span> <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 1.1554, df = 149, p-value = 0.1249
## alternative hypothesis: true mean is greater than 2
## 95 percent confidence interval:
##  1.961243      Inf
## sample estimates:
## mean of x 
##  2.089606</code></pre>
<p>El resultado muestra el valor <span class="math inline">\(t=1.15\)</span>, la cantidad de desviaciones estándar a que se encuentra el resultado muestral alejado de la media hipotética. No es un número grande, según los criterios vistos y eso se confirma con el valor <span class="math inline">\(p\)</span>, que es <span class="math inline">\(0.12\)</span>. Esta es una probabilidad mayor a todos los niveles de significación usuales, es decir que lo observado es esperable bajo la hipótesis nula, lo que conduce a no rechazar <span class="math inline">\(H_{0}\)</span>. Así, la conclusión es que no hay evidencia para creer que la población de la cual esta muestra proviene, tenga un promedio de más de dos hijas e hijos por mujer.</p>
<p>Luego, la salida ofrece un intervalo que tiene un solo límite; el inferior. Es un intervalo unilateral derecho, porque así es como fue formulada la <span class="math inline">\(H_{1}\)</span>, que indica que, con una confianza de 95%, el número medio de descendientes por mujer supera el valor <span class="math inline">\(1.96\)</span>. Como este intervalo, que comienza en <span class="math inline">\(1.96\)</span> y sigue hacia la derecha, contiene al valor hipotético (<span class="math inline">\(2\)</span>), es compatible con la decisión de no rechazar <span class="math inline">\(H_0\)</span>.</p>
</div>
<div id="prueba-sobre-la-proporción-1" class="section level3 hasAnchor" number="11.7.2">
<h3><span class="header-section-number">11.7.2</span> Prueba sobre la proporción<a href="#prueba-sobre-la-proporci%C3%B3n-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea que interesa comparar la proporción de población adulta de Argentina que sufre de obesidad con los valores mundiales de obesidad de personas adultas. Se define como obesas a las personas cuyo índice de masa corporal (peso en Kg dividido talla en metros al cuadrado) es mayor o igual a 30. Según la Organización Mundial de la Salud <span class="citation">(<a href="#ref-WHO">World Health Organization 2016</a>)</span>, en 2016, un 13% de la población mundial sufría de obesidad.</p>
<p>Para el problema de interés, la hipótesis se plantea en dirección a que la población adulta de Argentina probablemente tengan una prevalencia de obesidad superior a la media de todo el mundo. La hipótesis nula afirmará que la proporción de personas con sobrepeso en Argentina no es diferente del promedio mundial. Es decir:</p>
<p><span class="math display">\[H_{0}:P = 0.13\]</span></p>
<p><span class="math display">\[H_{1}:P &gt; 0.13\]</span></p>
<p>La base de la Encuesta Nacional de Factores de Riego 2013 contiene la variable “IMC_agrupado”, con categorías:</p>
<ul>
<li>1 Peso normal</li>
<li>2 Sobrepeso</li>
<li>3 Obesidad</li>
<li>9 Ns/Nc peso y/o talla</li>
</ul>
<p>Para obtener la distribución, primero se lee la base (que tiene separador de campos el signo “<span class="math inline">\(|\)</span>”), se solicita la tabla con el total y luego la tabla de de frecuencias relativas se redondea a 3 decimales:</p>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="prueba-de-hipótesis-la-lógica.html#cb586-1" tabindex="-1"></a>ENFR2013 <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(</span>
<span id="cb586-2"><a href="prueba-de-hipótesis-la-lógica.html#cb586-2" tabindex="-1"></a>  <span class="st">&quot;bases/archivostxt/ENFR2013_baseusuario.txt&quot;</span>,</span>
<span id="cb586-3"><a href="prueba-de-hipótesis-la-lógica.html#cb586-3" tabindex="-1"></a>                     <span class="at">sep =</span> <span class="st">&quot;|&quot;</span>)</span>
<span id="cb586-4"><a href="prueba-de-hipótesis-la-lógica.html#cb586-4" tabindex="-1"></a></span>
<span id="cb586-5"><a href="prueba-de-hipótesis-la-lógica.html#cb586-5" tabindex="-1"></a><span class="fu">addmargins</span>(<span class="fu">table</span>(ENFR2013<span class="sc">$</span>IMC_AGRUPADO))</span></code></pre></div>
<pre><code>## 
##     1     2     3     9   Sum 
## 12442 11343  6505  2075 32365</code></pre>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="prueba-de-hipótesis-la-lógica.html#cb588-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">addmargins</span>(<span class="fu">prop.table</span>(<span class="fu">table</span>(ENFR2013<span class="sc">$</span>IMC_AGRUPADO))), <span class="dv">3</span>) <span class="sc">*</span> <span class="dv">100</span></span></code></pre></div>
<pre><code>## 
##     1     2     3     9   Sum 
##  38.4  35.0  20.1   6.4 100.0</code></pre>
<p>Esta tabla está construida sobre los datos muestrales, una comparación correcta exige que se usen los factores de ponderación de la encuesta, que están calculados teniendo en cuenta el diseño de la muestra. Para tenerlos en cuenta, hace falta la función “wtd.table” (tabla ponderada), del paquete <code>questionr</code>, y cuyos argumentos son: la o las variables que se van a tabular y la variable que define las ponderaciones.<br />
Se instala el paquete correspondiente:</p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb590-1"><a href="prueba-de-hipótesis-la-lógica.html#cb590-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;questionr&quot;</span>)</span></code></pre></div>
<p>Y carga en sesión</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="prueba-de-hipótesis-la-lógica.html#cb591-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;questionr&quot;</span>)</span></code></pre></div>
<p>Tomando en cuenta los ponderadores de la ENFR2013, la tabla tiene esta forma:</p>
<div class="sourceCode" id="cb592"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb592-1"><a href="prueba-de-hipótesis-la-lógica.html#cb592-1" tabindex="-1"></a><span class="fu">addmargins</span>(<span class="fu">wtd.table</span>(ENFR2013<span class="sc">$</span>IMC_AGRUPADO, <span class="at">weights =</span> ENFR2013<span class="sc">$</span>PONDERACION))</span></code></pre></div>
<pre><code>##        1        2        3        9      Sum 
## 10180480  8953836  5027227  1616044 25777587</code></pre>
<div class="sourceCode" id="cb594"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb594-1"><a href="prueba-de-hipótesis-la-lógica.html#cb594-1" tabindex="-1"></a><span class="fu">round</span>(</span>
<span id="cb594-2"><a href="prueba-de-hipótesis-la-lógica.html#cb594-2" tabindex="-1"></a>  <span class="fu">addmargins</span>(</span>
<span id="cb594-3"><a href="prueba-de-hipótesis-la-lógica.html#cb594-3" tabindex="-1"></a>    <span class="fu">prop.table</span>(</span>
<span id="cb594-4"><a href="prueba-de-hipótesis-la-lógica.html#cb594-4" tabindex="-1"></a>      <span class="fu">wtd.table</span>(</span>
<span id="cb594-5"><a href="prueba-de-hipótesis-la-lógica.html#cb594-5" tabindex="-1"></a>        ENFR2013<span class="sc">$</span>IMC_AGRUPADO,</span>
<span id="cb594-6"><a href="prueba-de-hipótesis-la-lógica.html#cb594-6" tabindex="-1"></a>        <span class="at">weights =</span>ENFR2013<span class="sc">$</span>PONDERACION))), <span class="dv">3</span>) <span class="sc">*</span> <span class="dv">100</span></span></code></pre></div>
<pre><code>##     1     2     3     9   Sum 
##  39.5  34.7  19.5   6.3 100.0</code></pre>
<p>Que expande los aproximadamente 35 mil casos relevados a casi 26 millones de la población a la que la ENFR2013 representa. Las frecuencias relativas de las dos tablas son similares. Aplicar los ponderadores es útil para observar medidas descriptivas, pero no puede usarse para hacer inferencias, ya que se incrementaría de manera artificial el tamaño de la muestra. Esto debe cuidarse en algunos programas de análisis de datos, que permiten fijar poderadores y dejarlos activos para cualquier procedimiento. Una prueba de hipótesis o un intervalo de confianza realizado con los factores de ponderación están mal calculados, porque el tamaño de muestra es falso. Salvo en el caso que los ponderadores estén reescalados a <span class="math inline">\(1\)</span>, porque así no se altera el tamaño de la muestra, solo se ajusta su composición.</p>
<p>Para realizar la prueba sobre la proporción, se debe construir la categoría de referencia, que en este caso es la 3 de las tablas anteriores (obesidad). Se genera una nueva variable, que se llamará “obesidad” en la matriz de datos, de tal modo que: cuando “IMC_agrupado” valga 3 tengamos lo que llamamos “éxito”; cuando sea 9, sea un caso perdido (NA): y si vale 1 ó 2, vale cero.<br />
Luego se verifica que las nuevas categorías coincidan con las previstas, por medio de una tabla bivariada entre la variable original y la nueva. Una tabla univariada da los absolutos de “obesidad” y finalmente los relativos, donde se ve que en la muestra, la proporción de personas con obesidad es del <span class="math inline">\(21\%\)</span>.</p>
<div class="sourceCode" id="cb596"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb596-1"><a href="prueba-de-hipótesis-la-lógica.html#cb596-1" tabindex="-1"></a>ENFR2013<span class="sc">$</span>obesidad <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(ENFR2013<span class="sc">$</span>IMC_AGRUPADO <span class="sc">==</span> <span class="dv">3</span>, <span class="dv">1</span>, <span class="fu">ifelse</span>(ENFR2013<span class="sc">$</span>IMC_AGRUPADO <span class="sc">==</span> <span class="dv">9</span>, <span class="cn">NA</span>, <span class="dv">0</span>))</span>
<span id="cb596-2"><a href="prueba-de-hipótesis-la-lógica.html#cb596-2" tabindex="-1"></a></span>
<span id="cb596-3"><a href="prueba-de-hipótesis-la-lógica.html#cb596-3" tabindex="-1"></a><span class="fu">table</span>(ENFR2013<span class="sc">$</span>IMC_AGRUPADO, ENFR2013<span class="sc">$</span>obesidad)</span></code></pre></div>
<pre><code>##    
##         0     1
##   1 12442     0
##   2 11343     0
##   3     0  6505
##   9     0     0</code></pre>
<div class="sourceCode" id="cb598"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb598-1"><a href="prueba-de-hipótesis-la-lógica.html#cb598-1" tabindex="-1"></a><span class="fu">addmargins</span>(<span class="fu">table</span>(ENFR2013<span class="sc">$</span>obesidad))</span></code></pre></div>
<pre><code>## 
##     0     1   Sum 
## 23785  6505 30290</code></pre>
<div class="sourceCode" id="cb600"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb600-1"><a href="prueba-de-hipótesis-la-lógica.html#cb600-1" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">addmargins</span>(<span class="fu">prop.table</span>(<span class="fu">table</span>(ENFR2013<span class="sc">$</span>obesidad))), <span class="dv">3</span>) <span class="sc">*</span> <span class="dv">100</span></span></code></pre></div>
<pre><code>## 
##     0     1   Sum 
##  78.5  21.5 100.0</code></pre>
<p>El resultado muestral es una prevalencia de obesidad de <span class="math inline">\(21.5\%\)</span> en los 30290 casos válidos de la muestra, <span class="math inline">\(\widehat{p}=0.215\)</span>. La diferencia con el <span class="math inline">\(20.1\%\)</span> de la primera tabla es porque ahora no se están contando los casos perdidos.<br />
Ahora puede realizarse una prueba <span class="math inline">\(t\)</span> idéntica a la de la media, porque se cuenta con una variable dicotómica con categorías 0 - 1:</p>
<div class="sourceCode" id="cb602"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb602-1"><a href="prueba-de-hipótesis-la-lógica.html#cb602-1" tabindex="-1"></a><span class="fu">t.test</span>(ENFR2013<span class="sc">$</span>obesidad, <span class="at">mu =</span> .<span class="dv">13</span>, <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  ENFR2013$obesidad
## t = 35.921, df = 30289, p-value &lt; 2.2e-16
## alternative hypothesis: true mean is greater than 0.13
## 95 percent confidence interval:
##  0.2108761       Inf
## sample estimates:
## mean of x 
## 0.2147573</code></pre>
<p>El primer resultado es <span class="math inline">\(t=35.9\)</span> que indica un alejamiento de la media hipotética (que en este caso mide la proporción de 1s) de casi 36 desviaciones estándar. Es una valor muy grande y se corresponde con el de <span class="math inline">\(p\)</span> muy pequeño. Esto indica que si <span class="math inline">\(H_{0}\)</span> fuera verdadera (si la prevalencia de obesidad en Argentina fuera la misma que el promedio de todo el mundo), entonces habríamos encontrado un resultado tan poco probable como si, jugando a la ruleta, el número que elegimos hubiese salido nueve veces seguidas(dos en diez mil billones). Por lo cual decidimos (con mucha evidencia a favor) que la proporción de personas con obesidad en Argentina supera a la media mundial.
Luego tenemos un intervalo que es unilateral, como lo es la prueba que planteamos, que indica que, con una confianza del 95%, el intervalo que comienza en 21.09 contiene a la prevalencia de obesidad en Argentina. El hecho que este intervalo excluya al valor hipotético (<span class="math inline">\(13\%\)</span>) coincide con el rechazo de <span class="math inline">\(H_0\)</span>.<br />
El último renglón de la salida es el valor muestral, que conocíamos de la tabla anterior.</p>
</div>
</div>
<div id="resumen-de-pruebas-sobre-una-muestra" class="section level2 hasAnchor" number="11.8">
<h2><span class="header-section-number">11.8</span> Resumen de pruebas sobre una muestra<a href="prueba-de-hipótesis-la-lógica.html#resumen-de-pruebas-sobre-una-muestra" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Parámetro
</th>
<th style="text-align:center;">
Estimador
</th>
<th style="text-align:center;">
Estadístico de prueba
</th>
<th style="text-align:center;">
Puntos críticos en términos del estimador
</th>
<th style="text-align:center;">
Supuestos
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\overline{x}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(t = \frac{\overline{x} - \mu}{\frac{s}{\sqrt{n}}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\({\overline{x}}_{c} = \mu \pm z*\frac{s}{\sqrt{n}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n \geq 30\)</span> ó distribución normal de <em>x</em> en la población
</td>
</tr>
<tr>
<td style="text-align:center;">
P
</td>
<td style="text-align:center;">
<span class="math inline">\(\widehat{p}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(z = \frac{\widehat{p} - P}{\sqrt{\frac{P*(1 - P)}{n}}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\({\widehat{p}}_{c} = P \pm z*\sqrt{\frac{P*(1 - P)}{n}}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(n*P \geq 5\)</span> ó <span class="math inline">\(n*(1 - P) \geq 5\)</span>
</td>
</tr>
</tbody>
</table>
<p>Usando el valor <span class="math inline">\(p\)</span>, la lectura del resultado de la prueba de hipótesis
se expresa:</p>
<p>Si la hipótesis nula fuera verdadera, habría una probabilidad <span class="math inline">\(p\)</span> de
hallar un valor como el observado o uno más extremo.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-APA2010" class="csl-entry">
APA. 2010. <em><span class="nocase">Publication manual of the American Psychological Association</span></em>. Edited by American Psychological Association. 6th ed. Washington, DC.
</div>
<div id="ref-cumming2012" class="csl-entry">
Cumming, Geoff. 2012. <em>Understanding the New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis</em>. Multivariate Applications Book Series. Routledge. <a href="https://books.google.com.ar/books?id=AVBDYgEACAAJ">https://books.google.com.ar/books?id=AVBDYgEACAAJ</a>.
</div>
<div id="ref-Dziula2005" class="csl-entry">
Dziula, Cecilia Erica, and Cecilia Erica Reyna. 2005. <span>“<span class="nocase">Tolerancia r<span class="nocase">á</span>pida a los efectos del etanol en ratas periadolescentes : efectos diferenciales sobre patrones t<span class="nocase">é</span>rmicos y de conducta exploratoria</span>.”</span> Universidad Nacional de C<span>ó</span>rdoba. <a href="http://ffyh.biblio.unc.edu.ar/cgi-bin/koha/opac-detail.pl?biblionumber=71157">http://ffyh.biblio.unc.edu.ar/cgi-bin/koha/opac-detail.pl?biblionumber=71157</a>.
</div>
<div id="ref-Fisher" class="csl-entry">
Fisher, Ronald Aylmer. 1925. <em><span class="nocase">Statistical methods for research workers</span></em>. London: Oliver <span>&amp;</span> Boyd.
</div>
<div id="ref-Goedhart2018" class="csl-entry">
Goedhart, Joachim. 2018. <span>“<span class="nocase">Make a difference: the alternative for p-values</span>.”</span>
</div>
<div id="ref-greenland2019" class="csl-entry">
Greenland, Sander. 2019. <span>“Valid p-Values Behave Exactly as They Should: Some Misleading Criticisms of p-Values and Their Resolution with s-Values.”</span> <em>The American Statistician</em> 73 (sup1): 106–14. <a href="https://doi.org/10.1080/00031305.2018.1529625">https://doi.org/10.1080/00031305.2018.1529625</a>.
</div>
<div id="ref-Halsey2019" class="csl-entry">
Halsey, Lewis G. 2019. <span>“<span class="nocase">The reign of the p-value is over: What alternative analyses could we employ to fill the power vacuum?</span>”</span> <em>Biology Letters</em> 15 (5). <a href="https://doi.org/10.1098/rsbl.2019.0174">https://doi.org/10.1098/rsbl.2019.0174</a>.
</div>
<div id="ref-neyman1928" class="csl-entry">
Neyman, Jerzy, and Eagon Pearson. 1928. <span>“On the Use and Interpretation of Certain Test Criteria for Purposes of Statistical Inference: Part i.”</span> <em>Biometrika</em> 20A (1/2): 175–240. <a href="http://www.jstor.org/stable/2331945">http://www.jstor.org/stable/2331945</a>.
</div>
<div id="ref-WHO" class="csl-entry">
World Health Organization. 2016. <span>“<span class="nocase">Obesity and overweight</span>.”</span> <a href="https://www.who.int/news-room/fact-sheets/detail/obesity-and-overweight">https://www.who.int/news-room/fact-sheets/detail/obesity-and-overweight</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="69">
<li id="fn69"><p>En 1965, en <em>Statistical methods and scientific inference</em>, Fisher señaló: “Ningún investigador tiene un nivel de significación fijo, al cual año tras año y en toda circunstancia rechaza hipótesis; más bien entrega su mente a cada caso particular a la luz de la evidencia y de sus ideas”.<a href="prueba-de-hipótesis-la-lógica.html#fnref69" class="footnote-back">↩︎</a></p></li>
<li id="fn70"><p>Este número es el mismo que usamos al nivel del 10% en pruebas bilaterales. Esto se debe a que en ese caso el 10% extremo se reparte en 5% en cada cola; ahora nos interesa una sola cola, del 5%.<a href="prueba-de-hipótesis-la-lógica.html#fnref70" class="footnote-back">↩︎</a></p></li>
<li id="fn71"><p>Se trata de una línea albina de la rata parda. Fue desarrollada en el Wistar Institute en 1906 para fines de investigación biomédica, se trata de la primera rata empleada como organismo modelo (anteriormente se trabajaba con el ratón).<a href="prueba-de-hipótesis-la-lógica.html#fnref71" class="footnote-back">↩︎</a></p></li>
<li id="fn72"><p>Algunos de los datos son ficticios debido a la falta de disponibilidad y a la necesidad de adaptar el ejemplo a nuestros fines. Se mantiene la temática del estudio de referencia, aunque los resultados mostrados no corresponden exactamente a él.<a href="prueba-de-hipótesis-la-lógica.html#fnref72" class="footnote-back">↩︎</a></p></li>
<li id="fn73"><p>Sumamos y restamos para obtener dos puntos críticos, porque se trata de una prueba bilateral.<a href="prueba-de-hipótesis-la-lógica.html#fnref73" class="footnote-back">↩︎</a></p></li>
<li id="fn74"><p>Ver nota anterior<a href="prueba-de-hipótesis-la-lógica.html#fnref74" class="footnote-back">↩︎</a></p></li>
<li id="fn75"><p>Solo se suma para obtener el punto crítico de la derecha, porque se trata de una prueba unilateral derecha.<a href="prueba-de-hipótesis-la-lógica.html#fnref75" class="footnote-back">↩︎</a></p></li>
<li id="fn76"><p>Solo se resta para obtener el punto crítico izquierdo, porque es una prueba unilateral izquierda.<a href="prueba-de-hipótesis-la-lógica.html#fnref76" class="footnote-back">↩︎</a></p></li>
<li id="fn77"><p><span class="math inline">\(\widehat{p} = \frac{16}{50} = 0.32\)</span><a href="prueba-de-hipótesis-la-lógica.html#fnref77" class="footnote-back">↩︎</a></p></li>
<li id="fn78"><p>Latinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 19.000 entrevistas en 18 países de América Latina representando a más de 400 millones de habitantes. Corporación Latinobarómetro es una ONG sin fines de lucro con sede en Santiago de Chile, única responsable de la producción y publicación de los datos. <a href="http://www.latinobarometro.org/">http://www.latinobarometro.org/</a>.<a href="prueba-de-hipótesis-la-lógica.html#fnref78" class="footnote-back">↩︎</a></p></li>
<li id="fn79"><p>Aunque ejemplificaremos solo para el caso de la media y para una prueba unilateral derecha, el concepto de errores de tipo I y II es general y vale del mismo modo para la proporción y para pruebas de hipótesis sobre otros parámetros, en pruebas unilaterales o bilaterales.<a href="prueba-de-hipótesis-la-lógica.html#fnref79" class="footnote-back">↩︎</a></p></li>
<li id="fn80"><p>Lo que sigue tiene objetivos orientativos, si se necesita un tratamiento más detallado del tema -que requiere considerar que si <span class="math inline">\(H_0\)</span> es falsa entonces la distribución del estimador no es necesariamente simétrica-, puede consultarse <span class="citation">Cumming (<a href="#ref-cumming2012">2012</a>)</span>.<a href="prueba-de-hipótesis-la-lógica.html#fnref80" class="footnote-back">↩︎</a></p></li>
<li id="fn81"><p>Existe un procedimiento basado en un resultado importante de la estadística que se conoce como “desigualdad de Tchebycheff”, que establece que la probabilidad de encontrar a una variable a una distancia de su media superior a <span class="math inline">\(k\)</span> desviaciones estándar es menor a <span class="math inline">\(\frac{1}{k^{2}}\)</span>. Se expresa como <span class="math inline">\(P\left( \left| x - E(x) \right| &gt; k\sigma \right) &lt; \frac{1}{k^{2}}\)</span>. También es posible recurrir a la distribución empírica, obtenida por remuestreo. Más adelante se verán pruebas que permiten resolver situaciones en las que no se cumplen los supuestos, como pequeñas muestras, distribución no normal y/o nivel de medición no métrico.<a href="prueba-de-hipótesis-la-lógica.html#fnref81" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimación-por-intervalo.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="prueba-de-hipótesis-las-aplicaciones.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/jcrodriguez1989/EstadisticaParaCienciasSocialesConR/edit/master/12-capitulo11.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["EstadisticaParaCienciasSocialesConR.pdf", "EstadisticaParaCienciasSocialesConR.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

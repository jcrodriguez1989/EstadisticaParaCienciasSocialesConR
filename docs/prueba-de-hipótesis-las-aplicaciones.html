<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 12 Prueba de hipótesis: las aplicaciones | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R</title>
  <meta name="description" content="Capítulo 12 Prueba de hipótesis: las aplicaciones | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 12 Prueba de hipótesis: las aplicaciones | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/imagenes/cover.jpg" />
  
  <meta name="github-repo" content="jcrodriguez1989/EstadisticaParaCienciasSocialesConR" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 12 Prueba de hipótesis: las aplicaciones | Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R" />
  
  
  <meta name="twitter:image" content="/imagenes/cover.jpg" />

<meta name="author" content="Eduardo Bologna" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="prueba-de-hipótesis-la-lógica.html"/>
<link rel="next" href="cuando-los-supuestos-no-se-cumplen.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística para Ciencias Sociales con R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Colaboradores</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#comit%C3%A9-editorial"><i class="fa fa-check"></i>Comité Editorial</a></li>
<li class="chapter" data-level="" data-path=""><a href="#edici%C3%B3n-en-bookdown"><i class="fa fa-check"></i>Edición en bookdown</a></li>
<li class="chapter" data-level="" data-path=""><a href="#revisi%C3%B3n-de-lenguaje-incluyente"><i class="fa fa-check"></i>Revisión de lenguaje incluyente</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#presentaci%C3%B3n"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="presentación.html"><a href="presentación.html"><i class="fa fa-check"></i>Recorridos posibles</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#introducci%C3%B3n"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html"><i class="fa fa-check"></i>Antes de empezar</a>
<ul>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#materiales"><i class="fa fa-check"></i>Materiales</a>
<ul>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-permanente-de-hogares"><i class="fa fa-check"></i>Encuesta Permanente de Hogares</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-nacional-de-factores-de-riesgo"><i class="fa fa-check"></i>Encuesta Nacional de Factores de Riesgo</a></li>
<li class="chapter" data-level="" data-path=""><a href="#latinobar%C3%B3metro"><i class="fa fa-check"></i>Latinobarómetro</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#encuesta-nacional-sobre-prevalencias-de-consumo-de-sustancias-psicoactivas"><i class="fa fa-check"></i>Encuesta Nacional sobre Prevalencias de Consumo de Sustancias Psicoactivas</a></li>
<li class="chapter" data-level="" data-path=""><a href="#aplicaci%C3%B3n-de-la-escala-de-bayley"><i class="fa fa-check"></i>Aplicación de la escala de Bayley</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#tercera-edad"><i class="fa fa-check"></i>Tercera edad</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#herramientas"><i class="fa fa-check"></i>Herramientas</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#la-elecci%C3%B3n-de-r"><i class="fa fa-check"></i>La elección de R</a></li>
<li class="chapter" data-level="" data-path=""><a href="#instalaci%C3%B3n-de-r-y-rstudio"><i class="fa fa-check"></i>Instalación de R y RStudio</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#los-componentes-de-rstudio"><i class="fa fa-check"></i>Los componentes de RStudio</a></li>
<li class="chapter" data-level="" data-path="antes-de-empezar.html"><a href="antes-de-empezar.html#operaciones-en-el-script"><i class="fa fa-check"></i>Operaciones en el script</a></li>
<li class="chapter" data-level="" data-path=""><a href="#instalaci%C3%B3n-de-paquetes"><i class="fa fa-check"></i>Instalación de paquetes</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>I Estadística Descriptiva</b></span></li>
<li class="chapter" data-level="1" data-path="13-capitulo12.html"><a href="#los-datos-estad%C3%ADsticos"><i class="fa fa-check"></i><b>1</b> Los datos estadísticos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="13-capitulo12.html"><a href="#la-selecci%C3%B3n-de-la-informaci%C3%B3n-pertinente"><i class="fa fa-check"></i><b>1.1</b> La selección de la información pertinente</a></li>
<li class="chapter" data-level="1.2" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html"><i class="fa fa-check"></i><b>1.2</b> Las entidades</a></li>
<li class="chapter" data-level="1.3" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-variables"><i class="fa fa-check"></i><b>1.3</b> Las variables</a></li>
<li class="chapter" data-level="1.4" data-path="13-capitulo12.html"><a href="#las-categor%C3%ADas"><i class="fa fa-check"></i><b>1.4</b> Las categorías</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="13-capitulo12.html"><a href="#requisitos-de-las-categor%C3%ADas"><i class="fa fa-check"></i><b>1.4.1</b> Requisitos de las categorías</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="13-capitulo12.html"><a href="#los-s%C3%ADmbolos-num%C3%A9ricos"><i class="fa fa-check"></i><b>1.5</b> Los símbolos numéricos</a></li>
<li class="chapter" data-level="1.6" data-path="13-capitulo12.html"><a href="#la-medici%C3%B3n"><i class="fa fa-check"></i><b>1.6</b> La medición</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="13-capitulo12.html"><a href="#niveles-de-medici%C3%B3n"><i class="fa fa-check"></i><b>1.6.1</b> Niveles de medición</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="13-capitulo12.html"><a href="#resumen-de-los-niveles-de-medici%C3%B3n"><i class="fa fa-check"></i><b>1.7</b> Resumen de los niveles de medición</a></li>
<li class="chapter" data-level="1.8" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#hacerlo-en-r"><i class="fa fa-check"></i><b>1.8</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#lectura-de-la-base"><i class="fa fa-check"></i><b>1.8.1</b> Lectura de la base</a></li>
<li class="chapter" data-level="1.8.2" data-path="los-datos-estadísticos.html"><a href="los-datos-estadísticos.html#las-variables-1"><i class="fa fa-check"></i><b>1.8.2</b> Las variables</a></li>
<li class="chapter" data-level="1.8.3" data-path="13-capitulo12.html"><a href="#los-niveles-de-medici%C3%B3n-en-r"><i class="fa fa-check"></i><b>1.8.3</b> Los niveles de medición en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html"><i class="fa fa-check"></i><b>2</b> Distribuciones de frecuencia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="13-capitulo12.html"><a href="#tablas-de-distribuci%C3%B3n-de-frecuencia"><i class="fa fa-check"></i><b>2.1</b> Tablas de distribución de frecuencia</a></li>
<li class="chapter" data-level="2.2" data-path="13-capitulo12.html"><a href="#recategorizaci%C3%B3n"><i class="fa fa-check"></i><b>2.2</b> Recategorización</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="13-capitulo12.html"><a href="#variable-discreta-con-muchas-categor%C3%ADas"><i class="fa fa-check"></i><b>2.2.1</b> Variable discreta con muchas categorías</a></li>
<li class="chapter" data-level="2.2.2" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#variable-continua"><i class="fa fa-check"></i><b>2.2.2</b> Variable continua</a></li>
<li class="chapter" data-level="2.2.3" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#formas-de-recategorizar"><i class="fa fa-check"></i><b>2.2.3</b> Formas de recategorizar</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="13-capitulo12.html"><a href="#la-presentaci%C3%B3n-gr%C3%A1fica-de-los-resultados"><i class="fa fa-check"></i><b>2.3</b> La presentación gráfica de los resultados</a></li>
<li class="chapter" data-level="2.4" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#hacerlo-en-r-1"><i class="fa fa-check"></i><b>2.4</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="distribuciones-de-frecuencia.html"><a href="distribuciones-de-frecuencia.html#tablas-univariadas"><i class="fa fa-check"></i><b>2.4.1</b> Tablas univariadas</a></li>
<li class="chapter" data-level="2.4.2" data-path="13-capitulo12.html"><a href="#recategorizaci%C3%B3n-1"><i class="fa fa-check"></i><b>2.4.2</b> Recategorización</a></li>
<li class="chapter" data-level="2.4.3" data-path="13-capitulo12.html"><a href="#representaciones-gr%C3%A1ficas"><i class="fa fa-check"></i><b>2.4.3</b> Representaciones gráficas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="13-capitulo12.html"><a href="#la-expresi%C3%B3n-resumida-de-la-informaci%C3%B3n"><i class="fa fa-check"></i><b>3</b> La expresión resumida de la información</a>
<ul>
<li class="chapter" data-level="3.1" data-path="13-capitulo12.html"><a href="#medidas-de-posici%C3%B3n"><i class="fa fa-check"></i><b>3.1</b> Medidas de posición</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html"><i class="fa fa-check"></i><b>3.1.1</b> Variables nominales: proporciones</a></li>
<li class="chapter" data-level="3.1.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-tasas"><i class="fa fa-check"></i><b>3.1.2</b> Variables nominales: tasas</a></li>
<li class="chapter" data-level="3.1.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-razones"><i class="fa fa-check"></i><b>3.1.3</b> Variables nominales: razones</a></li>
<li class="chapter" data-level="3.1.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-nominales-el-modo"><i class="fa fa-check"></i><b>3.1.4</b> Variables nominales: el modo</a></li>
<li class="chapter" data-level="3.1.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#variables-ordinales-cuantiles"><i class="fa fa-check"></i><b>3.1.5</b> Variables ordinales: cuantiles</a></li>
<li class="chapter" data-level="3.1.6" data-path="13-capitulo12.html"><a href="#variables-m%C3%A9tricas-la-media-o-promedio"><i class="fa fa-check"></i><b>3.1.6</b> Variables métricas: la media o promedio</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="13-capitulo12.html"><a href="#la-forma-de-la-distribuci%C3%B3n"><i class="fa fa-check"></i><b>3.2</b> La forma de la distribución</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="13-capitulo12.html"><a href="#asimetr%C3%ADa"><i class="fa fa-check"></i><b>3.2.1</b> Asimetría</a></li>
<li class="chapter" data-level="3.2.2" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#curtosis"><i class="fa fa-check"></i><b>3.2.2</b> Curtosis</a></li>
<li class="chapter" data-level="3.2.3" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#box-plots"><i class="fa fa-check"></i><b>3.2.3</b> Box-plots</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="13-capitulo12.html"><a href="#medidas-de-dispersi%C3%B3n"><i class="fa fa-check"></i><b>3.3</b> Medidas de dispersión</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#recorrido"><i class="fa fa-check"></i><b>3.3.1</b> Recorrido</a></li>
<li class="chapter" data-level="3.3.2" data-path="13-capitulo12.html"><a href="#amplitud-intercuart%C3%ADlica"><i class="fa fa-check"></i><b>3.3.2</b> Amplitud intercuartílica</a></li>
<li class="chapter" data-level="3.3.3" data-path="13-capitulo12.html"><a href="#medidas-de-dispersi%C3%B3n-basadas-en-la-media"><i class="fa fa-check"></i><b>3.3.3</b> Medidas de dispersión basadas en la media</a></li>
<li class="chapter" data-level="3.3.4" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#varianza"><i class="fa fa-check"></i><b>3.3.4</b> Varianza</a></li>
<li class="chapter" data-level="3.3.5" data-path="13-capitulo12.html"><a href="#desviaci%C3%B3n-est%C3%A1ndar"><i class="fa fa-check"></i><b>3.3.5</b> Desviación estándar</a></li>
<li class="chapter" data-level="3.3.6" data-path="13-capitulo12.html"><a href="#coeficiente-de-variaci%C3%B3n"><i class="fa fa-check"></i><b>3.3.6</b> Coeficiente de variación</a></li>
<li class="chapter" data-level="3.3.7" data-path="13-capitulo12.html"><a href="#box-plots-y-dispersi%C3%B3n"><i class="fa fa-check"></i><b>3.3.7</b> Box-plots y dispersión</a></li>
<li class="chapter" data-level="3.3.8" data-path="13-capitulo12.html"><a href="#medida-de-la-dispersi%C3%B3n-cuando-no-hay-distancias"><i class="fa fa-check"></i><b>3.3.8</b> Medida de la dispersión cuando no hay distancias</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="13-capitulo12.html"><a href="#el-individuo-en-relaci%C3%B3n-a-su-grupo"><i class="fa fa-check"></i><b>3.4</b> El individuo en relación a su grupo</a></li>
<li class="chapter" data-level="3.5" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#resumen-de-medidas-descriptivas"><i class="fa fa-check"></i><b>3.5</b> Resumen de medidas descriptivas</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="13-capitulo12.html"><a href="#medidas-de-posici%C3%B3n-1"><i class="fa fa-check"></i><b>3.5.1</b> Medidas de posición</a></li>
<li class="chapter" data-level="3.5.2" data-path="13-capitulo12.html"><a href="#medidas-de-dispersi%C3%B3n-1"><i class="fa fa-check"></i><b>3.5.2</b> Medidas de dispersión</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="la-expresión-resumida-de-la-información.html"><a href="la-expresión-resumida-de-la-información.html#hacerlo-en-r-2"><i class="fa fa-check"></i><b>3.6</b> Hacerlo en R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="13-capitulo12.html"><a href="#relaci%C3%B3n-entre-variables-los-fundamentos"><i class="fa fa-check"></i><b>4</b> Relación entre variables: los fundamentos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html"><i class="fa fa-check"></i><b>4.1</b> Tablas de contingencia</a></li>
<li class="chapter" data-level="4.2" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#frecuencias-relativas"><i class="fa fa-check"></i><b>4.2</b> Frecuencias relativas</a></li>
<li class="chapter" data-level="4.3" data-path="13-capitulo12.html"><a href="#una-clasificaci%C3%B3n-en-referencia-al-tiempo"><i class="fa fa-check"></i><b>4.3</b> Una clasificación en referencia al tiempo</a></li>
<li class="chapter" data-level="4.4" data-path="13-capitulo12.html"><a href="#la-direcci%C3%B3n-de-la-relaci%C3%B3n"><i class="fa fa-check"></i><b>4.4</b> La dirección de la relación</a></li>
<li class="chapter" data-level="4.5" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#concepto-de-riesgo-relativo"><i class="fa fa-check"></i><b>4.5</b> Concepto de riesgo relativo</a></li>
<li class="chapter" data-level="4.6" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#la-intensidad"><i class="fa fa-check"></i><b>4.6</b> La intensidad</a></li>
<li class="chapter" data-level="4.7" data-path="13-capitulo12.html"><a href="#el-concepto-de-independencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>4.7</b> El concepto de independencia estadística</a></li>
<li class="chapter" data-level="4.8" data-path="relación-entre-variables-los-fundamentos.html"><a href="relación-entre-variables-los-fundamentos.html#hacerlo-en-r-3"><i class="fa fa-check"></i><b>4.8</b> Hacerlo en R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="13-capitulo12.html"><a href="#relaci%C3%B3n-entre-variables-el-an%C3%A1lisis"><i class="fa fa-check"></i><b>5</b> Relación entre variables: el análisis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="13-capitulo12.html"><a href="#relaciones-entre-variables-vs.-comparaci%C3%B3n-de-grupos"><i class="fa fa-check"></i><b>5.1</b> Relaciones entre variables vs. comparación de grupos</a></li>
<li class="chapter" data-level="5.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html"><i class="fa fa-check"></i><b>5.2</b> Variables nominales</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="13-capitulo12.html"><a href="#coeficientes-de-asociaci%C3%B3n-para-variables-nominales"><i class="fa fa-check"></i><b>5.2.1</b> Coeficientes de asociación para variables nominales</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#variables-de-nivel-ordinal"><i class="fa fa-check"></i><b>5.3</b> Variables de nivel ordinal</a></li>
<li class="chapter" data-level="5.4" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#nivel-intervalar-o-proporcional"><i class="fa fa-check"></i><b>5.4</b> Nivel intervalar o proporcional</a></li>
<li class="chapter" data-level="5.5" data-path="13-capitulo12.html"><a href="#dicotom%C3%ADas-reales-y-artificiales"><i class="fa fa-check"></i><b>5.5</b> Dicotomías reales y artificiales</a></li>
<li class="chapter" data-level="5.6" data-path="13-capitulo12.html"><a href="#niveles-de-medici%C3%B3n-combinados"><i class="fa fa-check"></i><b>5.6</b> Niveles de medición combinados</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="13-capitulo12.html"><a href="#una-variable-dicot%C3%B3mica-real-y-una-proporcional"><i class="fa fa-check"></i><b>5.6.1</b> Una variable dicotómica real y una proporcional</a></li>
<li class="chapter" data-level="5.6.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#una-variable-continua-dicotomizada-y-una-proporcional"><i class="fa fa-check"></i><b>5.6.2</b> Una variable continua dicotomizada y una proporcional</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="13-capitulo12.html"><a href="#resumen-de-coeficientes-de-asociaci%C3%B3n"><i class="fa fa-check"></i><b>5.7</b> Resumen de coeficientes de asociación</a></li>
<li class="chapter" data-level="5.8" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>5.8</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="5.9" data-path="13-capitulo12.html"><a href="#la-forma-de-la-relaci%C3%B3n"><i class="fa fa-check"></i><b>5.9</b> La forma de la relación</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#ordenada-al-origen"><i class="fa fa-check"></i><b>5.9.1</b> Ordenada al origen</a></li>
<li class="chapter" data-level="5.9.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#pendiente"><i class="fa fa-check"></i><b>5.9.2</b> Pendiente</a></li>
<li class="chapter" data-level="5.9.3" data-path="13-capitulo12.html"><a href="#obtenci%C3%B3n-de-la-recta-de-regresi%C3%B3n"><i class="fa fa-check"></i><b>5.9.3</b> Obtención de la recta de regresión</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="13-capitulo12.html"><a href="#la-visualizaci%C3%B3n-de-los-datos"><i class="fa fa-check"></i><b>5.10</b> La visualización de los datos</a></li>
<li class="chapter" data-level="5.11" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#hacerlo-en-r-4"><i class="fa fa-check"></i><b>5.11</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#distancia-chi2"><i class="fa fa-check"></i><b>5.11.1</b> Distancia <span class="math inline">\(\chi^{2}\)</span></a></li>
<li class="chapter" data-level="5.11.2" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#coeficientes"><i class="fa fa-check"></i><b>5.11.2</b> Coeficientes</a></li>
<li class="chapter" data-level="5.11.3" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#modelo-lineal"><i class="fa fa-check"></i><b>5.11.3</b> Modelo lineal</a></li>
<li class="chapter" data-level="5.11.4" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#cuarteto-de-anscombe"><i class="fa fa-check"></i><b>5.11.4</b> Cuarteto de Anscombe</a></li>
<li class="chapter" data-level="5.11.5" data-path="relación-entre-variables-el-análisis.html"><a href="relación-entre-variables-el-análisis.html#datasaurus"><i class="fa fa-check"></i><b>5.11.5</b> Datasaurus</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II De la descripción a la inferencia</b></span></li>
<li class="chapter" data-level="6" data-path="13-capitulo12.html"><a href="#obtenci%C3%B3n-de-la-muestra"><i class="fa fa-check"></i><b>6</b> Obtención de la muestra</a>
<ul>
<li class="chapter" data-level="6.1" data-path="13-capitulo12.html"><a href="#poblaci%C3%B3n"><i class="fa fa-check"></i><b>6.1</b> Población</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html"><i class="fa fa-check"></i><b>6.1.1</b> Muestra</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="13-capitulo12.html"><a href="#muestreos-probabil%C3%ADsticos"><i class="fa fa-check"></i><b>6.2</b> Muestreos probabilísticos</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-irrestricto-aleatorio-o-aleatorio-simple"><i class="fa fa-check"></i><b>6.2.1</b> Muestreo irrestricto aleatorio o aleatorio simple</a></li>
<li class="chapter" data-level="6.2.2" data-path="13-capitulo12.html"><a href="#muestreo-sistem%C3%A1tico"><i class="fa fa-check"></i><b>6.2.2</b> Muestreo sistemático</a></li>
<li class="chapter" data-level="6.2.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-estratificado"><i class="fa fa-check"></i><b>6.2.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="6.2.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-por-conglomerados"><i class="fa fa-check"></i><b>6.2.4</b> Muestreo por conglomerados</a></li>
<li class="chapter" data-level="6.2.5" data-path="13-capitulo12.html"><a href="#m%C3%A9todo-de-kish"><i class="fa fa-check"></i><b>6.2.5</b> Método de Kish</a></li>
<li class="chapter" data-level="6.2.6" data-path="13-capitulo12.html"><a href="#uso-combinado-de-t%C3%A9cnicas-de-muestreo"><i class="fa fa-check"></i><b>6.2.6</b> Uso combinado de técnicas de muestreo</a></li>
<li class="chapter" data-level="6.2.7" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-de-panel"><i class="fa fa-check"></i><b>6.2.7</b> Muestreo de panel</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="13-capitulo12.html"><a href="#muestreos-no-probabil%C3%ADsticos"><i class="fa fa-check"></i><b>6.3</b> Muestreos no probabilísticos</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-por-cuotas"><i class="fa fa-check"></i><b>6.3.1</b> Muestreo por cuotas</a></li>
<li class="chapter" data-level="6.3.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-de-juicio-o-intencional"><i class="fa fa-check"></i><b>6.3.2</b> Muestreo de juicio o intencional</a></li>
<li class="chapter" data-level="6.3.3" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-autoelegido"><i class="fa fa-check"></i><b>6.3.3</b> Muestreo autoelegido</a></li>
<li class="chapter" data-level="6.3.4" data-path="13-capitulo12.html"><a href="#muestreo-accidental-o-seg%C3%BAn-disponibilidad"><i class="fa fa-check"></i><b>6.3.4</b> Muestreo accidental o según disponibilidad</a></li>
<li class="chapter" data-level="6.3.5" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#muestreo-bola-de-nieve"><i class="fa fa-check"></i><b>6.3.5</b> Muestreo bola de nieve</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#hacerlo-en-r-5"><i class="fa fa-check"></i><b>6.4</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#aleatorio-simple"><i class="fa fa-check"></i><b>6.4.1</b> Aleatorio simple</a></li>
<li class="chapter" data-level="6.4.2" data-path="obtención-de-la-muestra.html"><a href="obtención-de-la-muestra.html#estratificado"><i class="fa fa-check"></i><b>6.4.2</b> Estratificado</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html"><i class="fa fa-check"></i><b>7</b> Probabilidad: los fundamentos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#formas-para-asignar-probabilidades"><i class="fa fa-check"></i><b>7.1</b> Formas para asignar probabilidades</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="13-capitulo12.html"><a href="#asignaci%C3%B3n-a-priori"><i class="fa fa-check"></i><b>7.1.1</b> Asignación a priori</a></li>
<li class="chapter" data-level="7.1.2" data-path="13-capitulo12.html"><a href="#asignaci%C3%B3n-a-posteriori"><i class="fa fa-check"></i><b>7.1.2</b> Asignación a posteriori</a></li>
<li class="chapter" data-level="7.1.3" data-path="13-capitulo12.html"><a href="#la-relaci%C3%B3n-entre-asignaci%C3%B3n-a-priori-y-a-posteriori"><i class="fa fa-check"></i><b>7.1.3</b> La relación entre asignación a priori y a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#operando-con-probabilidades"><i class="fa fa-check"></i><b>7.2</b> Operando con probabilidades</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#con-probabilidades-frecuenciales"><i class="fa fa-check"></i><b>7.2.1</b> Con probabilidades frecuenciales</a></li>
<li class="chapter" data-level="7.2.2" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#con-probabilidades-a-priori"><i class="fa fa-check"></i><b>7.2.2</b> Con probabilidades a priori</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#el-teorema-de-bayes"><i class="fa fa-check"></i><b>7.3</b> El teorema de Bayes</a></li>
<li class="chapter" data-level="7.4" data-path="probabilidad-los-fundamentos.html"><a href="probabilidad-los-fundamentos.html#variables-aleatorias"><i class="fa fa-check"></i><b>7.4</b> Variables aleatorias</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html"><i class="fa fa-check"></i><b>8</b> Probabilidad: los modelos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="13-capitulo12.html"><a href="#concepto-de-modelizaci%C3%B3n"><i class="fa fa-check"></i><b>8.1</b> Concepto de modelización</a></li>
<li class="chapter" data-level="8.2" data-path="13-capitulo12.html"><a href="#distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>8.2</b> Distribución binomial</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#esperanza-y-varianza"><i class="fa fa-check"></i><b>8.2.1</b> Esperanza y varianza</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="13-capitulo12.html"><a href="#distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.3</b> Distribución normal</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#cuantiles"><i class="fa fa-check"></i><b>8.3.1</b> Cuantiles</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#la-idea-de-grados-de-libertad"><i class="fa fa-check"></i><b>8.4</b> La idea de grados de libertad</a></li>
<li class="chapter" data-level="8.5" data-path="13-capitulo12.html"><a href="#la-distribuci%C3%B3n-ji-cuadrado-chi2"><i class="fa fa-check"></i><b>8.5</b> La distribución ji cuadrado (<span class="math inline">\(\chi^{2}\)</span>)</a></li>
<li class="chapter" data-level="8.6" data-path="13-capitulo12.html"><a href="#la-distribuci%C3%B3n-t-de-student"><i class="fa fa-check"></i><b>8.6</b> La distribución t de Student</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="13-capitulo12.html"><a href="#la-distribuci%C3%B3n-f"><i class="fa fa-check"></i><b>8.6.1</b> La distribución F</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#hacerlo-en-r-6"><i class="fa fa-check"></i><b>8.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#probabilidades-exactas"><i class="fa fa-check"></i><b>8.7.1</b> Probabilidades exactas</a></li>
<li class="chapter" data-level="8.7.2" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#probabilidades-acumuladas"><i class="fa fa-check"></i><b>8.7.2</b> Probabilidades acumuladas</a></li>
<li class="chapter" data-level="8.7.3" data-path="probabilidad-los-modelos.html"><a href="probabilidad-los-modelos.html#cuantiles-1"><i class="fa fa-check"></i><b>8.7.3</b> Cuantiles</a></li>
<li class="chapter" data-level="8.7.4" data-path="13-capitulo12.html"><a href="#%C3%A1reas-centrales"><i class="fa fa-check"></i><b>8.7.4</b> Áreas centrales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html"><i class="fa fa-check"></i><b>9</b> Distribuciones en el muestreo</a>
<ul>
<li class="chapter" data-level="9.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#variabilidad-muestral"><i class="fa fa-check"></i><b>9.1</b> Variabilidad muestral</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#dos-aspectos-importantes-para-recordar-cuando-se-usan-muestras"><i class="fa fa-check"></i><b>9.1.1</b> Dos aspectos importantes para recordar cuando se usan muestras:</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="13-capitulo12.html"><a href="#caracter%C3%ADsticas-de-los-estimadores"><i class="fa fa-check"></i><b>9.2</b> Características de los estimadores</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#insesgabilidad"><i class="fa fa-check"></i><b>9.2.1</b> Insesgabilidad</a></li>
<li class="chapter" data-level="9.2.2" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#consistencia"><i class="fa fa-check"></i><b>9.2.2</b> Consistencia</a></li>
<li class="chapter" data-level="9.2.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#eficiencia"><i class="fa fa-check"></i><b>9.2.3</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#distribuciones-de-probabilidad-de-los-estimadores"><i class="fa fa-check"></i><b>9.3</b> Distribuciones de probabilidad de los estimadores</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="13-capitulo12.html"><a href="#primera-aproximaci%C3%B3n"><i class="fa fa-check"></i><b>9.3.1</b> Primera aproximación</a></li>
<li class="chapter" data-level="9.3.2" data-path="13-capitulo12.html"><a href="#distribuci%C3%B3n-de-la-media-muestral"><i class="fa fa-check"></i><b>9.3.2</b> Distribución de la media muestral</a></li>
<li class="chapter" data-level="9.3.3" data-path="13-capitulo12.html"><a href="#distribuci%C3%B3n-de-la-proporci%C3%B3n-muestral"><i class="fa fa-check"></i><b>9.3.3</b> Distribución de la proporción muestral</a></li>
<li class="chapter" data-level="9.3.4" data-path="13-capitulo12.html"><a href="#muestras-peque%C3%B1as"><i class="fa fa-check"></i><b>9.3.4</b> Muestras pequeñas</a></li>
<li class="chapter" data-level="9.3.5" data-path="13-capitulo12.html"><a href="#distribuci%C3%B3n-de-la-varianza"><i class="fa fa-check"></i><b>9.3.5</b> Distribución de la varianza</a></li>
<li class="chapter" data-level="9.3.6" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#muestreo-desde-dos-poblaciones"><i class="fa fa-check"></i><b>9.3.6</b> Muestreo desde dos poblaciones</a></li>
<li class="chapter" data-level="9.3.7" data-path="13-capitulo12.html"><a href="#distribuci%C3%B3n-del-cociente-de-varianzas"><i class="fa fa-check"></i><b>9.3.7</b> Distribución del cociente de varianzas</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="13-capitulo12.html"><a href="#resumen-de-la-relaci%C3%B3n-entre-estimadores-y-par%C3%A1metros"><i class="fa fa-check"></i><b>9.4</b> Resumen de la relación entre estimadores y parámetros</a></li>
<li class="chapter" data-level="9.5" data-path="distribuciones-en-el-muestreo.html"><a href="distribuciones-en-el-muestreo.html#hacerlo-en-r-7"><i class="fa fa-check"></i><b>9.5</b> Hacerlo en R</a></li>
</ul></li>
<li class="part"><span><b>III Estadística inferencial</b></span></li>
<li class="chapter" data-level="10" data-path="13-capitulo12.html"><a href="#estimaci%C3%B3n-por-intervalo"><i class="fa fa-check"></i><b>10</b> Estimación por intervalo</a>
<ul>
<li class="chapter" data-level="10.1" data-path="13-capitulo12.html"><a href="#estimaci%C3%B3n-puntual"><i class="fa fa-check"></i><b>10.1</b> Estimación puntual</a></li>
<li class="chapter" data-level="10.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html"><i class="fa fa-check"></i><b>10.2</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="10.3" data-path="13-capitulo12.html"><a href="#estimaci%C3%B3n-de-la-media"><i class="fa fa-check"></i><b>10.3</b> Estimación de la media</a></li>
<li class="chapter" data-level="10.4" data-path="13-capitulo12.html"><a href="#estimaci%C3%B3n-de-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.4</b> Estimación de la proporción</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-clopper-pearson"><i class="fa fa-check"></i><b>10.4.1</b> Intervalo de Clopper-Pearson</a></li>
<li class="chapter" data-level="10.4.2" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-wald"><i class="fa fa-check"></i><b>10.4.2</b> Intervalo de Wald</a></li>
<li class="chapter" data-level="10.4.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-de-wilson"><i class="fa fa-check"></i><b>10.4.3</b> Intervalo de Wilson</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#la-calidad-de-las-estimaciones-por-intervalo"><i class="fa fa-check"></i><b>10.5</b> La calidad de las estimaciones por intervalo</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="13-capitulo12.html"><a href="#el-error-de-estimaci%C3%B3n-en-la-media"><i class="fa fa-check"></i><b>10.5.1</b> El error de estimación en la media</a></li>
<li class="chapter" data-level="10.5.2" data-path="13-capitulo12.html"><a href="#el-error-de-estimaci%C3%B3n-en-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.5.2</b> El error de estimación en la proporción</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#probabilidad-de-cobertura"><i class="fa fa-check"></i><b>10.6</b> Probabilidad de cobertura</a></li>
<li class="chapter" data-level="10.7" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#hacerlo-en-r-8"><i class="fa fa-check"></i><b>10.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#intervalo-para-la-media"><i class="fa fa-check"></i><b>10.7.1</b> Intervalo para la media</a></li>
<li class="chapter" data-level="10.7.2" data-path="13-capitulo12.html"><a href="#intervalo-para-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.7.2</b> Intervalo para la proporción</a></li>
<li class="chapter" data-level="10.7.3" data-path="estimación-por-intervalo.html"><a href="estimación-por-intervalo.html#cobertura"><i class="fa fa-check"></i><b>10.7.3</b> Cobertura</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="13-capitulo12.html"><a href="#prueba-de-hip%C3%B3tesis-la-l%C3%B3gica"><i class="fa fa-check"></i><b>11</b> Prueba de hipótesis: la lógica</a>
<ul>
<li class="chapter" data-level="11.1" data-path="13-capitulo12.html"><a href="#el-razonamiento-de-la-prueba-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>11.1</b> El razonamiento de la prueba de hipótesis</a></li>
<li class="chapter" data-level="11.2" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html"><i class="fa fa-check"></i><b>11.2</b> Prueba sobre la media</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="13-capitulo12.html"><a href="#la-toma-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>11.2.1</b> La toma de decisión</a></li>
<li class="chapter" data-level="11.2.2" data-path="13-capitulo12.html"><a href="#los-puntos-cr%C3%ADticos-en-t%C3%A9rminos-del-estimador"><i class="fa fa-check"></i><b>11.2.2</b> Los puntos críticos en términos del estimador</a></li>
<li class="chapter" data-level="11.2.3" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#pruebas-unilaterales"><i class="fa fa-check"></i><b>11.2.3</b> Pruebas unilaterales</a></li>
<li class="chapter" data-level="11.2.4" data-path="13-capitulo12.html"><a href="#otros-ejemplos-de-prueba-de-hip%C3%B3tesis-sobre-la-media"><i class="fa fa-check"></i><b>11.2.4</b> Otros ejemplos de prueba de hipótesis sobre la media</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="13-capitulo12.html"><a href="#prueba-sobre-la-proporci%C3%B3n"><i class="fa fa-check"></i><b>11.3</b> Prueba sobre la proporción</a></li>
<li class="chapter" data-level="11.4" data-path="13-capitulo12.html"><a href="#tipos-de-error-en-las-pruebas-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>11.4</b> Tipos de error en las pruebas de hipótesis</a></li>
<li class="chapter" data-level="11.5" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#etii-mu-alpha-y-n"><i class="fa fa-check"></i><b>11.5</b> <em>ETII:</em> <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(n\)</span></a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#curva-de-potencia"><i class="fa fa-check"></i><b>11.5.1</b> Curva de potencia</a></li>
<li class="chapter" data-level="11.5.2" data-path="13-capitulo12.html"><a href="#significaci%C3%B3n-estad%C3%ADstica-y-valor-p"><i class="fa fa-check"></i><b>11.5.2</b> Significación estadística y valor <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="13-capitulo12.html"><a href="#muestras-peque%C3%B1as-y-pruebas-t"><i class="fa fa-check"></i><b>11.6</b> Muestras pequeñas y pruebas <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="11.7" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#hacerlo-en-r-9"><i class="fa fa-check"></i><b>11.7</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#prueba-sobre-la-media-1"><i class="fa fa-check"></i><b>11.7.1</b> Prueba sobre la media</a></li>
<li class="chapter" data-level="11.7.2" data-path="13-capitulo12.html"><a href="#prueba-sobre-la-proporci%C3%B3n-1"><i class="fa fa-check"></i><b>11.7.2</b> Prueba sobre la proporción</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="prueba-de-hipótesis-la-lógica.html"><a href="prueba-de-hipótesis-la-lógica.html#resumen-de-pruebas-sobre-una-muestra"><i class="fa fa-check"></i><b>11.8</b> Resumen de pruebas sobre una muestra</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="13-capitulo12.html"><a href="#prueba-de-hip%C3%B3tesis-las-aplicaciones"><i class="fa fa-check"></i><b>12</b> Prueba de hipótesis: las aplicaciones</a>
<ul>
<li class="chapter" data-level="12.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html"><i class="fa fa-check"></i><b>12.1</b> Muestras independientes</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-de-diferencia-de-medias"><i class="fa fa-check"></i><b>12.1.1</b> Prueba de diferencia de medias</a></li>
<li class="chapter" data-level="12.1.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#muestras-apareadas"><i class="fa fa-check"></i><b>12.1.2</b> Muestras apareadas</a></li>
<li class="chapter" data-level="12.1.3" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#coeficiente-r-de-pearson"><i class="fa fa-check"></i><b>12.1.3</b> Coeficiente r de Pearson</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#hacerlo-en-r-10"><i class="fa fa-check"></i><b>12.2</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-1."><i class="fa fa-check"></i><b>12.2.1</b> Ejemplo 1.</a></li>
<li class="chapter" data-level="12.2.2" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-2."><i class="fa fa-check"></i><b>12.2.2</b> Ejemplo 2.</a></li>
<li class="chapter" data-level="12.2.3" data-path="13-capitulo12.html"><a href="#aplicaci%C3%B3n-a-los-datos-de-poblaci%C3%B3n-adulta-mayor"><i class="fa fa-check"></i><b>12.2.3</b> Aplicación a los datos de Población Adulta Mayor</a></li>
<li class="chapter" data-level="12.2.4" data-path="prueba-de-hipótesis-las-aplicaciones.html"><a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-apareada"><i class="fa fa-check"></i><b>12.2.4</b> Prueba apareada</a></li>
<li class="chapter" data-level="12.2.5" data-path="13-capitulo12.html"><a href="#coeficiente-de-correlaci%C3%B3n"><i class="fa fa-check"></i><b>12.2.5</b> Coeficiente de correlación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html"><i class="fa fa-check"></i><b>13</b> Cuando los supuestos no se cumplen</a>
<ul>
<li class="chapter" data-level="13.0.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#las-pruebas-ji-cuadrado-o-chi-cuadrado"><i class="fa fa-check"></i><b>13.0.1</b> Las pruebas ji cuadrado (o chi cuadrado)</a></li>
<li class="chapter" data-level="13.0.2" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#coeficiente-r_s-de-spearman"><i class="fa fa-check"></i><b>13.0.2</b> Coeficiente <span class="math inline">\(r_s\)</span> de Spearman</a></li>
<li class="chapter" data-level="13.0.3" data-path="13-capitulo12.html"><a href="#alternativas-no-param%C3%A9tricas-a-las-pruebas-t"><i class="fa fa-check"></i><b>13.0.3</b> Alternativas no paramétricas a las pruebas t</a></li>
<li class="chapter" data-level="13.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#hacerlo-en-r-11"><i class="fa fa-check"></i><b>13.1</b> Hacerlo en R</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#ejemplo-1"><i class="fa fa-check"></i><b>13.1.1</b> Ejemplo 1</a></li>
<li class="chapter" data-level="13.1.2" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#ejemplo-2"><i class="fa fa-check"></i><b>13.1.2</b> Ejemplo 2</a></li>
<li class="chapter" data-level="13.1.3" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#prueba-de-la-mediana-1"><i class="fa fa-check"></i><b>13.1.3</b> Prueba de la mediana</a></li>
<li class="chapter" data-level="13.1.4" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#prueba-de-wilcoxon"><i class="fa fa-check"></i><b>13.1.4</b> Prueba de Wilcoxon</a></li>
<li class="chapter" data-level="13.1.5" data-path="cuando-los-supuestos-no-se-cumplen.html"><a href="cuando-los-supuestos-no-se-cumplen.html#muestras-apareadas-1"><i class="fa fa-check"></i><b>13.1.5</b> Muestras apareadas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="13-capitulo12.html"><a href="#tama%C3%B1o-del-efecto"><i class="fa fa-check"></i><b>14</b> Tamaño del efecto</a>
<ul>
<li class="chapter" data-level="14.1" data-path="13-capitulo12.html"><a href="#significaci%C3%B3n-estad%C3%ADstica-y-significaci%C3%B3n-pr%C3%A1ctica"><i class="fa fa-check"></i><b>14.1</b> Significación estadística y significación práctica</a></li>
<li class="chapter" data-level="14.2" data-path="13-capitulo12.html"><a href="#medidas-de-tama%C3%B1o-del-efecto"><i class="fa fa-check"></i><b>14.2</b> Medidas de tamaño del efecto</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html"><i class="fa fa-check"></i><b>14.2.1</b> Prueba t para diferencia de medias</a></li>
<li class="chapter" data-level="14.2.2" data-path="13-capitulo12.html"><a href="#an%C3%A1lisis-de-la-varianza"><i class="fa fa-check"></i><b>14.2.2</b> Análisis de la varianza</a></li>
<li class="chapter" data-level="14.2.3" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#correlaciones"><i class="fa fa-check"></i><b>14.2.3</b> Correlaciones</a></li>
<li class="chapter" data-level="14.2.4" data-path="13-capitulo12.html"><a href="#regresi%C3%B3n-lineal"><i class="fa fa-check"></i><b>14.2.4</b> Regresión lineal</a></li>
<li class="chapter" data-level="14.2.5" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#pruebas-ji-cuadrado"><i class="fa fa-check"></i><b>14.2.5</b> Pruebas ji cuadrado</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="13-capitulo12.html"><a href="#an%C3%A1lisis-de-la-potencia"><i class="fa fa-check"></i><b>14.3</b> Análisis de la potencia</a></li>
<li class="chapter" data-level="14.4" data-path="tamaño-del-efecto.html"><a href="tamaño-del-efecto.html#hacerlo-en-r-12"><i class="fa fa-check"></i><b>14.4</b> Hacerlo en R</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Generado con bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Un Recorrido por los Métodos Cuantitativos en Ciencias Sociales a bordo de R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prueba-de-hipótesis-las-aplicaciones" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Capítulo 12</span> Prueba de hipótesis: las aplicaciones<a href="#prueba-de-hip%C3%B3tesis-las-aplicaciones" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Hasta aquí, la prueba de hipótesis es un procedimiento para evaluar si
un valor observado en la muestra es compatible con el valor poblacional
que plantea la hipótesis nula, para la media o la proporción. Se trabajó
sobre una única población y se puso a prueba un valor determinado para
un parámetro (media o proporción). Ahora ampliamos el análisis, porque
vamos a poner a prueba la eventual diferencia entre dos grupos y la
correlación entre dos variables. Probaremos por ejemplo, si puede
aceptarse que dos poblaciones tengan la misma media en una variable
cuantitativa o también la misma proporción de casos en una categoría de
una variable cualitativa. Como antes, la hipótesis nula será la de no
diferencia, es decir que formularemos como <span class="math inline">\(H_{0}\)</span> que las dos poblaciones
tienen la misma media o bien la misma proporción. Para la correlación,
la <span class="math inline">\(H_{0}\)</span> indica que, a nivel poblacional, el coeficiente vale cero.</p>
<p>En este capítulo se abordan los procedimientos que permiten comparar las
medias o proporciones de dos grupos y determinar si las diferencias que
se encuentran son significativamente mayores de lo que pudiera esperarse
por puro azar. Es decir, recorreremos los pasos necesarios para tomar
una decisión en términos estadísticos, a favor o en contra de la
hipótesis que sostiene que dos grupos son iguales respecto del parámetro
bajo análisis. Un modo alternativo de expresar el problema es considerar
que lo que se pone a prueba es si las dos muestras provienen de la misma
población o de dos poblaciones diferentes.</p>
<p>En el diseño experimental, a menudo interesa conocer, si un grupo sometido a
cierto tratamiento muestra cambios diferentes a los que experimenta otro
grupo que no fue sometido a ese tratamiento. Los procedimientos que
veremos se utilizan para determinar si las ganancias obtenidas en una
muestra de sujetos tras un tratamiento -por ejemplo de entrenamiento
cognitivo-, son lo suficientemente amplias como para representar
diferencias en la población. En este tipo de casos, se realiza una
primera evaluación del grupo (pre-test), se obtiene la media de ciertas
variables (aciertos en una prueba de atención, palabras recordadas,
aciertos en la correspondencia entre nombres y caras, etc.). Luego se
somete a los sujetos a un período de entrenamiento y a continuación son
nuevamente evaluados (post-test). Necesitamos determinar si los cambios,
medidos a través de la diferencia de los promedios, son de una magnitud
tal que podamos atribuirlos al entrenamiento o bien si pueden explicarse
por azar. La misma lógica, en condiciones menos controladas se usa en evaluación de impacto de intervenciones, para comparar a un grupo que se benefició de un programa con otro que no lo hizo, o también para comparar un grupo consigo mismo antes y después de una intervención <span class="citation">(<a href="#ref-Gertler2017">Gertler et al. 2017</a>)</span>.</p>
<p>Los procedimientos destinados a comparar grupos tienen gran difusión en
investigación. Muchos de los problemas que interesa resolver usándolos
se encuentran vinculados a distintos campos de las Ciencias Sociales, ya que se comparan grupos que han recibido una droga con
quienes no la han recibido, que han pasado por un período de
entrenamiento o no, que han participado en grupos terapéuticos o han
desarrollado otra actividad; estudiantes que usan una u otra estrategia de estudio; comunidades, familias o personas que han sido o no beneficiadas por una política pública; países con diferentes regímenes políticos; personas con diferente ideología política, etc. En todos los casos se realiza una comparación en algún resultado,
que puede ser el puntaje en un test, la valoración de la democracia, el rendimiento escolar o cualquier otra variable sobre la
que se busca intervenir. Por ejemplo, en una tesis de Maestría en
Psicología Clínica, el autor separa a un grupo de personas menores de edad deficientes
mentales en dos grupos. Uno de ellos participa de un taller con
actividades de protección ambiental (se lo llama “grupo experimental”), mientras que
el otro grupo no lo hace (es el denominado “grupo control”). A través de
pruebas estandarizadas se mide la sociabilidad, esperando que las
actividades en las que participaron pudieran estimularla. Se comparan
los niveles de sociabilidad de quienes participaron del taller con
los de quienes no lo hicieron, esta evaluación se hace antes y después
de la realización de estas actividades, que se prolongaron por un mes.
En este ejemplo hay dos comparaciones: la socialización de quienes
participaron con la de quienes no lo hicieron, y la de la sociabilidad
de quienes participaron, antes del taller y luego de él. En ambos casos
se utilizan las pruebas sobre las que trata este capítulo.</p>
<p>Siempre la hipótesis nula sostendrá que no hay diferencias entre las
puntuaciones obtenidas antes y después del tratamiento, o por un grupo y
el otro; o lo que es lo mismo, que las diferencias son cero (nulas). En
la hipótesis alternativa se planteará la situación opuesta, sea
bilateral (que las medias difieren) o unilateral (que una media es mayor que la otra).</p>
<p>Estos procedimientos no sólo se utilizan en experimentos -que contruyen los grupos con criterios preestablecidos-, sino también en estudios que analizan datos de observación, que pueden provenir de encuestas o de observación directa. Así una variable independiente puede constituirse por
grupos o muestras de sujetos que conforman categorías diferentes.
Varones versus mujeres, población rural versus población urbana, estudiantes de escuela primaria
que repiten o no repiten un grado. Pueden interesar entonces, ciertas
diferencias en los promedios de alguna variable entre estos grupos.
¿Tienen los mismos ingresos promedio los varones jefes de hogar que las
mujeres que son jefas de hogar? ¿La proporción de analfabetos es la
misma entre provincias del NOA o del Centro del país? La edad promedio
de las madres primerizas que se atienden en hospitales públicos, ¿es la
misma que la de quienes van a privados? Podemos comparar varones y
mujeres y evaluar si hay diferencia entre el promedio de un grupo y otro en relación a la introversión, el neuroticismo o su afabilidad. También podríamos comparar personas mayores y jóvenes en relación a los
promedios que obtuvieran en pruebas de inteligencia fluida o
cristalizada.<br />
En estos ejemplos, jefes y jefas de hogar,
NOA y Centro del país, personas jóvenes y adultas mayores, mujeres y varones, etc. son
grupos independientes, que se diferencian por los valores de una
variable (región, edad, género) y nos interesa investigar si estos
agrupamientos evidencian diferencias en otras variables de interés: como los ingresos, el analfabetismo, la inteligencia, la
introversión.</p>
<p>Cuando apreciamos que las medias de dos grupos son diferentes, no
podemos saber a priori si las muestras provienen de poblaciones cuyas
medias son diferentes o no, porque las diferencias observadas entre los
resultados muestrales pueden provenir de azar. Por eso, encontrar que
<span class="math inline">\({\overline{x}}_{1} \neq {\overline{x}}_{2}\)</span> (en las muestras) no
conduce inmediatamente a que <span class="math inline">\(\mu_{1} \neq \mu_{2}\)</span> (en las
poblaciones).</p>
<p>El procedimiento para comparar los parámetros (medias o proporciones) de
dos poblaciones consiste en extraer una muestra de cada población:
llamaremos a los tamaños de esas muestras <span class="math inline">\(n_{1}\)</span> y <span class="math inline">\(n_{2}\)</span>. En
cada muestra se calculan -como antes-, los estimadores correspondientes.
Si se estima una diferencia de medias calcularemos las medias
(<span class="math inline">\({\overline{x}}_{1}\)</span> y <span class="math inline">\({\overline{x}}_{2}\)</span>), así como las desviaciones
estándar (<span class="math inline">\(s_{1}\)</span> y <span class="math inline">\(s_{2}\)</span>) de cada una.<br />
Si lo que se estima es una
diferencia de proporciones, en cada muestra se calculará la proporción
de casos en la categoría de interés: <span class="math inline">\({\widehat{p}}_{1}\)</span> y
<span class="math inline">\({\widehat{p}}_{2}\)</span> que son los estimadores de los parámetros <span class="math inline">\(P_{1}\)</span> y <span class="math inline">\(P_{2}\)</span>.</p>
<p>Aquellas situaciones en que no se puedan calcular medias y varianzas
porque las variables son ordinales o bien no se sostengan los supuestos
sobre normalidad de las distribuciones poblacionales, se aplican otro
tipo de prueba de hipótesis, que serán tratados en el próximo capítulo.</p>
<p>Veamos en primer lugar el caso en que la variable bajo análisis es
cuantitativa y entonces nos interesa comparar las medias poblacionales.
El parámetro que se estima es la diferencia entre las medias
poblacionales: <span class="math inline">\(\mu_{1} - \mu_{2}\)</span>, y la estimación se hace a través de
la diferencia entre las medias muestrales:
<span class="math inline">\({\overline{x}}_{1} - {\overline{x}}_{2}\)</span>. El error estándar de ese
estimador (que será necesario para estandarizar el valor observado) va a depender del tipo de prueba de que se trate. En este capítulo trataremos
dos situaciones, cuando sean muestras independientes, y muestras
apareadas o dependientes.</p>
<div id="muestras-independientes" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Muestras independientes<a href="prueba-de-hipótesis-las-aplicaciones.html#muestras-independientes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="prueba-de-diferencia-de-medias" class="section level3 hasAnchor" number="12.1.1">
<h3><span class="header-section-number">12.1.1</span> Prueba de diferencia de medias<a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-de-diferencia-de-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La comparación de las medias de dos poblaciones independientes se
realiza comparando los correspondientes estimadores de las medias
poblacionales. De modo equivalente a la relación media muestral - media poblacional, ahora parámetro a estimar es la diferencia de medias poblacionales: <span class="math inline">\(\mu_1-\mu_2\)</span>, y el estimador es la diferencia de medias muestrales: <span class="math inline">\(\bar{x}_1-\bar{x}_2)\)</span>. Esta última es la variable aleatoria que, bajo los supuestos mencionados antes, tiene distribución normal centrada en el parámetro. El siguiente esquema recuerda la notación:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-525-1.svg" width="672" /></p>
<p>Una vez que se dispone de los datos muestrales, el estadístico de prueba toma la forma;</p>
<p><span class="math display">\[\frac{{(\overline{x}}_{1} - {\overline{x}}_{2}) - {(\mu}_{1} - \mu_{2})}{s_{{\overline{x}}_{1} - {\overline{x}}_{2}}}\]</span></p>
<p>Es decir, se trata de la diferencia entre la diferencia de las medias
muestrales y la diferencia de las medias poblacionales, dividida por el
error estándar de la diferencia (el error estándar del estimador). La
expresión mantiene la estructura que mencionamos en el capítulo
anterior: estimador menos parámetro sobre el error estándar del
estimador. En este caso el estimador es la diferencia de las medias
muestrales y el parámetro es la diferencia de las medias poblacionales.</p>
<p>Este estadístico de prueba tiene distribución normal si los tamaños de las muestras son suficientemente grandes (mayores a 30 casos) y tiene distribución <em>t de Student</em> si se trata de muestras pequeñas y puede además suponerse que las variables que se analizan tienen distribución normal en la población. Debido a que la distribución <span class="math inline">\(t\)</span> tiende a la normal a medida que aumenta el tamaño de la muestra, y como lo hicimos antes para una sola muestra, escribiremos de manera general:</p>
<p><span class="math display">\[t = \frac{{(\overline{x}}_{1} - {\overline{x}}_{2}) - {(\mu}_{1} - \mu_{2})}{s_{{\overline{x}}_{1} - {\overline{x}}_{2}}}\]</span></p>
<p>Como sabemos, cuando las muestras sean
grandes, las probabilidades asociadas al valor de <span class="math inline">\(t\)</span> coincidirán con
las de la distribución normal.</p>
<p>El denominador del estadístico de prueba puede
ser calculado de dos maneras diferentes y eso va a depender de que
podamos suponer que las varianzas de las dos poblaciones de las que
provienen las muestras son iguales o que no sea así.</p>
<div id="caso-1-varianzas-poblacionales-iguales" class="section level4 hasAnchor" number="12.1.1.1">
<h4><span class="header-section-number">12.1.1.1</span> Caso 1: Varianzas poblacionales iguales<a href="prueba-de-hipótesis-las-aplicaciones.html#caso-1-varianzas-poblacionales-iguales" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math inline">\(\sigma_{1}^{2} = \sigma_{2}^{2}\)</span></p>
<p>Si puede suponerse que las varianzas poblacionales son iguales, entonces las dos varianzas que se calculan desde las muestras, constituyen dos estimadores (diferentes por azar) del mismo parámetro. Cada muestra ofrece una estimación de la varianza, que es la misma en las dos poblaciones de origen. En ese caso, calcularemos primero un promedio<a href="#fn82" class="footnote-ref" id="fnref82"><sup>82</sup></a> de las dos estimaciones dadas por las varianzas muestrales, a la que llamaremos varianza combinada:</p>
<p><span class="math display">\[s_{\text{comb}}^{2} = \frac{\left( n_{1} - 1 \right)*s_{1}^{2} + \left( n_{2} - 1 \right)*s_{2}^{2}}{n_{1} + n_{2} - 2}\]</span></p>
<p>Usando este estimador de la (supuestamente única) varianza poblacional,
el estadístico de prueba asume la forma:</p>
<p><span class="math display">\[t = \frac{{(\overline{x}}_{1} - {\overline{x}}_{2}) - {(\mu}_{1} - \mu_{2})}{s_{\text{comb}}*\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}\]</span></p>
<p>Cuyos grados de libertad se calculan, en función de los tamaños de las muestras como: <span class="math inline">\(gl = n_{1} + n_{2} - 2\)</span>.</p>
</div>
<div id="caso-2-varianzas-poblacionales-diferentes" class="section level4 hasAnchor" number="12.1.1.2">
<h4><span class="header-section-number">12.1.1.2</span> Caso 2: Varianzas poblacionales diferentes<a href="prueba-de-hipótesis-las-aplicaciones.html#caso-2-varianzas-poblacionales-diferentes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math inline">\(\sigma_{1}^{2} \neq \sigma_{2}^{2}\)</span></p>
<p>Si no es posible suponer que las varianzas de
las poblaciones de donde provienen las muestras son iguales, entonces
debemos usar las varianzas muestrales de manera separada. Cuando éste es
el caso, el estadístico de prueba es:</p>
<p><span class="math display">\[t = \frac{{(\overline{x}}_{1} - {\overline{x}}_{2}) - {(\mu}_{1} - \mu_{2})}{\sqrt{\frac{s_{1}^{2}}{n_{1}} + \frac{s_{2}^{2}}{n_{2}}}}\]</span></p>
<p>Esta expresión es más sencilla, porque mantiene las varianzas originales en lugar de combinarlas, pero el
cálculo de los grados de libertad de la distribución <em>t de Student</em> se
vuelve más complejo. La fórmula para hacerlo es<a href="#fn83" class="footnote-ref" id="fnref83"><sup>83</sup></a></p>
<p><span class="math display">\[gl = \frac{\left( \frac{s_{1}^{2}}{n_{1}} + \frac{s_{2}^{2}}{n_{2}} \right)^{2}}{\frac{\left( \frac{s_{1}^{2}}{n_{1}} \right)^{2}}{n_{1} - 1} + \frac{\left( \frac{s_{2}^{2}}{n_{2}} \right)^{2}}{n_{2} - 1}}\]</span></p>
<p>No vamos a usar esta expresión para calcular los grados de libertad,
pero es la que usan los programas de análisis de datos cuando detectan
que las varianzas poblacionales no son iguales.</p>
</div>
<div id="comparación-de-las-varianzas" class="section level4 hasAnchor" number="12.1.1.3">
<h4><span class="header-section-number">12.1.1.3</span> Comparación de las varianzas<a href="#comparaci%C3%B3n-de-las-varianzas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>De acuerdo a esto, cuando vamos a hacer una prueba <span class="math inline">\(t\)</span> para comparar las medias de dos grupos debemos antes saber si estamos ante el caso 1 ó el caso 2; lo que significa que deberemos antes decidir si las varianzas de las dos poblaciones pueden considerarse iguales o no. Dado que no conocemos estas varianzas poblacionales, la decisión se toma a partir de los datos muestrales, es decir, a partir de las varianzas halladas en las muestras (<span class="math inline">\(s_{1}^{2}\)</span> y <span class="math inline">\(s_{2}^{2}\)</span>). Se realiza una prueba, cuya hipótesis nula afirma que las varianzas poblacionales son iguales y su resultado permitirá decidir, a un determinado nivel de significación, si puede tratarse a las varianzas poblacionales como iguales o si debe considerárselas diferentes, la prueba se llama prueba de homogeneidad de varianzas<a href="#fn84" class="footnote-ref" id="fnref84"><sup>84</sup></a> y tiene las siguientes hipótesis.</p>
<p><span class="math display">\[H_{0}:\ \frac{\sigma_{1}^{2}}{\sigma_{2}^{2}} = 1\]</span></p>
<p><span class="math display">\[H_{1}:\ \frac{\sigma_{1}^{2}}{\sigma_{2}^{2}} \neq 1\]</span></p>
<p>El estadístico de prueba es el cociente de las varianzas muestrales:</p>
<p><span class="math display">\[\frac{s_{1}^{2}}{s_{2}^{2}}\]</span></p>
<p>Y tiene una distribución F con <span class="math inline">\(n_{1} - 1\)</span> grados de libertad en el
numerador y <span class="math inline">\(n_{2} - 1\)</span> grados de libertad en el denominador.</p>
<p>Ejemplo 1. (datos ficticios): nos preguntamos si, para una carrera
universitaria dada, el tiempo que tardan en completar sus estudios quienes trabajan es el mismo que el que les requiere a quines no lo hacen, o si difiere.
Para ello tomamos una muestra de 100 estudiantes que trabajan y obtenemos una media de duración de la carrera de 6.7 años y una desviación estándar de 1.2 años. Extraemos otra muestra, de 150 casos que no trabajan, en la que obtenemos un promedio de los años de duración de 6.3 con una desviación estándar de 1.5 años. Todos estos datos provienen de la información descriptiva que proveen las muestras, son los que vamos a usar para hacer la inferencia acerca de las
poblaciones, constituidas por el total de quienes trabajan y no
trabajan.</p>
<p>Como antes, la hipótesis nula es la del “no cambio”, la que afirma que
no hay diferencia, por lo que:</p>
<p><span class="math display">\[H_{0}:\mu_{1} - \mu_{2} = 0\]</span></p>
<p>Que dice que la diferencia entre las medias poblacionales es cero (es
nula). Hemos dicho que nuestro interés está en saber si las medias
poblacionales son iguales o si difieren, por lo que se trata de una
prueba bilateral, entonces la hipótesis alternativa indicará que:</p>
<p><span class="math display">\[H_{1}:\mu_{1} - \mu_{2} \neq 0\]</span></p>
<p>Para la presentación continuaremos usando la distribución normal, ya que resulta más familiar, pero los paquetes de análisis de datos usan
directamente distribuciones <span class="math inline">\(t\)</span>, que en este ejemplo, con 100 y 150 casos, coincide, a los fines prácticos, con la normal.</p>
<p>Bajo la hipótesis nula, la distribución del estimador será:</p>
<!--acá también el eje x se debe llamar media dos menos media 1 -->
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-526-1.svg" width="672" /></p>
<p>Para decirlo nuevamente, la variable aleatoria es la diferencia de
medias muestrales, el centro de la distribución es el parámetro, que
según la hipótesis nula es cero.</p>
<p>Fijamos el nivel de significación de la prueba en el 5% y los puntos
críticos resultan, sobre la distribución normal estándar ±1.96,
gráficamente:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-527-1.svg" width="672" /></p>
<p>Ahora transformamos a puntaje <span class="math inline">\(z\)</span> los valores observados en las
muestras. Recordemos para ello que el puntaje <span class="math inline">\(z\)</span> se define como la
diferencia entre el estimador (observado) y el parámetro (hipotético), dividida por el error
estándar del estimador. Para esta prueba, el parámetro es la diferencia
de medias poblacionales, su estimador es la diferencia de medias
muestrales, con lo que:</p>
<p><span class="math display">\[z_{\text{obs}} = \frac{{(\overline{x}}_{1} - {\overline{x}}_{2}) - {(\mu}_{1} - \mu_{2})}{s_{({\overline{x}}_{1} - {\overline{x}}_{2})}}\]</span></p>
<p>Y queda por decidir cómo calcular el denominador, lo que va a depender
de que puedan o no suponerse iguales las varianzas poblacionales. Para
decidirlo, se realiza la prueba de homogeneidad de varianzas:</p>
<p><span class="math display">\[H_{0}:\ \frac{\sigma_{1}^{2}}{\sigma_{2}^{2}} = 1\]</span></p>
<p><span class="math display">\[H_{1}:\ \frac{\sigma_{1}^{2}}{\sigma_{2}^{2}} \neq 1\]</span></p>
<p>El estadístico de prueba es</p>
<p><span class="math display">\[\frac{s_{1}^{2}}{s_{2}^{2}} = \frac{{1.2}^{2}}{{1.5}^{2}} = 0.64\]</span></p>
<p>Se busca la probabilidad asociada a un valor como el
observado o mayor, bajo un modelo F con grados de libertad determinados por el tamaño de las muestras (de 100 y 150 observaciones)
<span class="math inline">\(P(F_{n_{1} - 1,\ n_{2} - 1}) = P(F_{99,\ 149})&gt;0.64\)</span><br />
Que equivale a:<br />
<span class="math inline">\(1-(P(F_{99,\ 149})&lt;0.64)\)</span></p>
<p>Y resulta:</p>
<pre><code>## [1] 0.9911</code></pre>
<p>Gráficamente, la distribución <span class="math inline">\(F\)</span> tiene poca asimetría, porque los grados de libertad son elevados, y el área que queda a la derecha del valor <span class="math inline">\(F_{obs}\)</span> es casi 1:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-529-1.svg" width="672" /></p>
<p>Esa área es el valor <span class="math inline">\(p\)</span>, por lo que debe interpretarse como la probabilidad de hallar un cociente entre las varianzas muestrales como el observado o más extremo, si las varianzas poblacionales fueran iguales. Dado que es un número muy alto, no se rechaza la hipótesis nula, y se concluye que las varianzas pueden suponerse iguales. Se trata entonces de lo que se ha llamado “caso 1” y, para el denominador del estadístico de prueba, se calcula la varianza combinada<a href="#fn85" class="footnote-ref" id="fnref85"><sup>85</sup></a>:</p>
<p><span class="math display">\[s_{\text{comb}}^{2} = \frac{\left( n_{1} - 1 \right)*s_{1}^{2} + \left( n_{2} - 1 \right)*s_{2}^{2}}{n_{1} + n_{2} - 2}\]</span></p>
<p>Con los datos del ejemplo, la varianza combinada es:</p>
<p><span class="math display">\[s_{\text{comb}}^{2} = \frac{\left( 100 - 1 \right)*{1.2}^{2} + \left( 150 - 1 \right)*{1.5}^{2}}{100 + 150 - 2} = \frac{477.81}{249} = 1.92\]</span></p>
<p>por lo que la desviación estándar combinada resulta:</p>
<p><span class="math display">\[s_{\text{comb}} = \sqrt{1.92} = 1.38\]</span></p>
<p>Como la hipótesis nula establece que la diferencia de medias
poblacionales es cero <span class="math inline">\(\mu_{1} - \mu_{2} = 0\)</span>, entonces, el estadístico
de prueba queda:</p>
<p><span class="math display">\[z = \frac{\left( 6.7 - 6.3 \right) - 0}{1.38*\sqrt{\frac{1}{100} + \frac{1}{150}}} = \frac{0.4}{0.18} = 2.22\]</span></p>
<p>Este es el estadístico de prueba correspondiente a la diferencia de
medias para muestras independientes cuando las varianzas poblacionales
pueden suponerse iguales. Este valor de <span class="math inline">\(z\)</span> (2.22) se encuentra en la zona de rechazo de <span class="math inline">\(H_{0}\)</span>, por lo que la decisión será la de rechazar <span class="math inline">\(H_{0}\)</span> y concluir que el tiempo que tardan en terminar la carrera quienes trabajan difiere significativamente del que tardan quienes no trabajan. Dicho de otro modo: la diferencia observada en las medias de las muestras es significativa a un nivel del 5%.</p>
<p>Ejemplo 2. Si los mismos resultados se hubiesen hallado en muestras más pequeñas, por ejemplo de 20 casos que trabajan y 25 que no, y además hubiésemos podido suponer que las dos poblaciones son normales en la variable <em>duración de la carrera</em>; entonces habría correspondido usar una prueba <span class="math inline">\(t\)</span> <a href="#fn86" class="footnote-ref" id="fnref86"><sup>86</sup></a>. La prueba de homogeneidad de varianzas da, con esos nuevos tamaños de muestra, <span class="math inline">\(p = 0.16\)</span>. Un valor que también es elevado, por lo que se puede tratar a las varianzas como iguales.</p>
<p>Los grados de libertad de la distribución <span class="math inline">\(t\)</span> se calculan sumando los
tamaños de muestra y restando dos:</p>
<p><span class="math display">\[gl = n_{1} + n_{2} - 2 = 20 + 25 - 2 = 43\]</span></p>
<p>Con 43 grados de libertad, los valores <span class="math inline">\(t_{c}\)</span> que delimitan un 5% extremo en la distribución de probabilidades son ±2.02, que gráficamente se representan así:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-530-1.svg" width="672" /></p>
<p>Para tomar la decisión calculamos el estadístico de prueba con el mismo
procedimiento anterior, para lo que es necesario contar primero con la
desviación estándar combinada. Calculamos primero la varianza combinada:</p>
<p><span class="math display">\[s_{\text{comb}}^{2} = \frac{\left( 20 - 1 \right)*{1.2}^{2} + \left( 25 - 1 \right)*{1.5}^{2}}{20 + 25 - 2} = \frac{81.36}{43} = 1.89\]</span></p>
<p>Y la desviación estándar combinada es:</p>
<p><span class="math display">\[s_{\text{comb}} = \sqrt{1.89} = 1.37\]</span></p>
<p>por lo que el estadístico de prueba resulta:</p>
<p><span class="math display">\[t = \frac{\left( 6.7 - 6.3 \right) - 0}{1.37*\sqrt{\frac{1}{20} + \frac{1}{25}}} = \frac{0.4}{0.41} = 0.97\]</span></p>
<p>Este valor no se ubica en la zona de rechazo de <span class="math inline">\(H_{0}\)</span>, como se ve en el gráfico:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-531-1.svg" width="672" /></p>
<p>La conclusión será en este caso que no hay evidencia para creer que el
tiempo promedio que tardan en terminar la carrera quienes
trabajan sea diferente que el de quienes no trabajan.</p>
<p>La comparación de las conclusiones de estos dos ejemplos muestra algo
muy importante: una misma diferencia absoluta de 0.4 años en los
promedios muestrales de los grupos, es significativa cuando proviene de
muestras grandes (100 y 150 casos) y deja de serlo cuando se obtiene en
muestras pequeñas (20 y 25 casos). El tamaño de las muestras incide en
la potencia de la prueba, que es su capacidad para detectar diferencias.</p>
<p>Por las razones que ya hemos mencionado, en el cálculo informatizado del estadístico de prueba no se distingue entre utilizar distribución normal (<span class="math inline">\(z\)</span>) para muestras grandes y <span class="math inline">\(t\)</span> para muestras chicas, como
acabamos de hacer en los ejemplos anteriores. Por el contrario, se usa
siempre distribución <span class="math inline">\(t\)</span> <a href="#fn87" class="footnote-ref" id="fnref87"><sup>87</sup></a>. Así, esta prueba se conoce como <em>prueba t de diferencia de medias</em>.</p>
<p>Ejemplo 3 (datos reales): la salida que mostramos a continuación es una
comparación de la edad promedio de docentes varones y mujeres del
nivel medio. Los datos provienen de una muestra aleatoria de 246
docentes de la ciudad de Córdoba. La hipótesis nula de esa comparación
es que no hay diferencia en la edad promedio de mujeres y varones
docentes del nivel medio, que se confronta con una hipótesis alternativa
que afirma que sí hay diferencia. Se trata de una prueba bilateral que
se expresa así:</p>
<p><span class="math display">\[H_{0}:\mu_{1} - \mu_{2} = 0\]</span></p>
<p><span class="math display">\[H_{1}:\mu_{1} - \mu_{2} \neq 0\]</span></p>
<p>Donde los subíndices 1 y 2 se refieren a los grupos formados por
docentes mujeres y varones respectivamente. Al final del capítulo se verá como pedir a R la realización de esta prueba, la salida es:</p>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  edad by sexo
## t = -1.9924, df = 116.54, p-value = 0.04867
## alternative hypothesis: true difference in means between group mujeres and group varones is not equal to 0
## 95 percent confidence interval:
##  -2.279948 -0.006789
## sample estimates:
## mean in group mujeres mean in group varones 
##              40.07696              41.22033</code></pre>
<p>El título es el de prueba t de dos muestras de Welch, que se refiere a la corrección de Welch-Satterthwaite. Se indican los datos, que es edad según sexo (la comparación de las edades según sexo).<br />
Lugo se ofrece el valor <span class="math inline">\(t_{obs}\)</span>, de -1.99, los grados de libertad y el valor <span class="math inline">\(p\)</span>, de 0.048. Se indica cuál fue la hipotesis alternativa (que las medias difieres, es decir bilateral).<br />
Luego se lee un intervalo de confianza para estimar la diferencia de las media, construido, por defecto al 95% y, finalmente las medias muestrales.</p>
<p>La lectura de esta salida es que, a un nivel de significación del 5%, hay evidencia para rechazar la hipótesis de igualdad de las medias poblacionales, dado que el valor <span class="math inline">\(p\)</span> hallado es menor a ese criterio. Pero si se reduce el riesgo de cometer error de tipo I y se baja el nivel de sigificación al 1%, entonces el resultado ya no es significativo a este nivel. La lectura del resultado debe incluir esta interpretación, para que quede constancia que la <span class="math inline">\(H_{0}\)</span> ha sido rechazada con poca evidencia en su contra.<br />
Un dato adicional que obtenemos en la salida es el intervalo de confianza que estima la diferencia poblacional. Leemos que, con una confianza del 95%, el intervalo que va de 0.007 a 2.280, contiene a la diferencia de edades que hay en la población. Para la lectura del intervalo no se tiene en cuenta el signo negativo, que proviene de haber restado <span class="math inline">\(edad.mujeres - edad.varones\)</span> y que habría sido positivo de haber elegido restar en otro orden. Sí importa, por el contrario, que los signos de los límites sean iguales (ambos positivos o ambos negativos) porque eso quiere decir que, al nivel de confianza establecido, se excluye al cero del intervalo. Por eso este resultado es siempre compatible con la decisión de aceptar o rechazar <span class="math inline">\(H_{0}\)</span>, al mismo nivel de significación.</p>
<p>Cuando una prueba de hipótesis sobre diferencia de medias se rechaza a un nivel de significación <span class="math inline">\(\alpha\)</span>, entones, un intervalo construido con una confianza del <span class="math inline">\(1-\alpha\)</span>, excluye al cero entre sus límites. Dicho de otra manera, el límite inferior y el límite superior tienen el mismo signo.</p>
<p>Cuando una prueba de hipótesis sobre diferencia de medias no se rechaza a un nivel de significación <span class="math inline">\(\alpha\)</span>, entones, un intervalo construido con una confianza del <span class="math inline">\(1-\alpha\)</span>, incluye al cero entre sus límites. Dicho de otra manera, el límite inferior es negativo y el límite superior es positivo.</p>
<p>La lateralidad de la prueba que analizamos en el capítulo anterior,
sigue del mismo modo cuando trabajamos con diferencias de medias.</p>
<p>Ejemplo 4. Se espera que una droga que se está experimentando produzca efectos sobre la depresión, en dirección a reducir el puntaje que alcanzan las personas diagnosticadas, en un test que la evalúa.
Para poner a prueba la droga será necesario diseñar un experimento, no
avanzaremos en ese tema pero de manera muy simple, podemos pensar en dos grupos de personas que padecen depresión, a uno de los cuales se administra la
droga (grupo 1) y al otro no (grupo 2)<a href="#fn88" class="footnote-ref" id="fnref88"><sup>88</sup></a>. Concluiremos que la droga
tiene efectos si luego de un tiempo de su administración, el grupo de
pacientes que la recibió experimentó cambios positivos en mayor
magnitud que el otro. Dicho de otro modo, habrá efectos si la media de
puntaje en el test que evalúa depresión es significativamente menor en
el grupo que se sometió al tratamiento.<br />
Como siempre, la hipótesis nula afirmará que no hay diferencia:</p>
<p><span class="math display">\[H_{0}:\mu_{1} - \mu_{2} = 0\]</span></p>
<p>Como ahora interesa que el grupo 1 haya <em>reducido</em> su puntaje en el
test de depresión, esperamos que la media del grupo 1 sea menor que la
del grupo 2, lo cual se escribe:</p>
<p><span class="math display">\[H_{1}:\mu_{1} - \mu_{2} &lt; 0\]</span></p>
<p>Por la lateralidad de la prueba, solo hay una zona extrema de rechazo,
la izquierda. Fijando un 5% de nivel de significación, si se tratara de
muestras grandes, en las que podemos usar distribución normal, esta zona se representa del modo habitual:</p>
<p><img src="EstadisticaParaCienciasSocialesConR_files/figure-html/unnamed-chunk-533-1.svg" width="672" /></p>
<p>Por el contrario, si se trata de muestras pequeñas, corresponde usar
distribución <em>t</em>, y el punto crítico dependerá de los grados de
libertad.</p>
<p>Un grupo de 15 sujetos que recibió un medicamento arroja un puntaje promedio en la prueba que evalúa la depresión de 5.7 puntos, con desviación estándar de 1.1 puntos. Otro grupo, de 10 pacientes, que no recibieron el medicamento alcanza un puntaje promedio
de 7.2 puntos, con desviación estándar de 1.6 (datos ficticios). La prueba previa sobre la homogeneidad de las varianzas indica que no puede suponérselas iguales, por lo que estamos en el caso 2. Debe utilizarse la distribución t con grados de libertad que deben calcularse con la expresión de Welch-Satterthwaite, el resultado<a href="#fn89" class="footnote-ref" id="fnref89"><sup>89</sup></a> es 15. El punto crítico <span class="math inline">\(t_{15, .05}\)</span>, es -1.75.</p>
<p>El estadístico de prueba vale:</p>
<p><span class="math display">\[t = \frac{\left( 5.7 - 7.2 \right) - 0}{\sqrt{\frac{1.1}{15} + \frac{1.6}{10}}} = \frac{-1.5}{0.48} = -3.10\]</span></p>
<p>Es un valor que se sitúa a la izquierda del punto crítico, por lo que se
rechaza la <span class="math inline">\(H_0\)</span> y se concluye que el grupo que recibió la droga alcanzó
un puntaje significativamente menor que el otro grupo.</p>
<p>Ejemplo (datos reales): en un estudio realizado en el Centro de
Promoción del Adulto Mayor, se seleccionaron aleatoriamente entre todos
los asistentes, a 503 personas mayores de 50 años. Entre otras
preguntas, se computó el número de hijas e hijos de cada persona.</p>
<p>Se conformaron dos grupos con los sujetos estudiados, quienes tenían
hasta 65 años en el momento del estudio y quienes tenían 66 o más años.
En este ejemplo, estos dos grupos, si bien no fueron asignados de manera
aleatoria, se comportarían como muestras independientes.</p>
<p>Podríamos suponer que las personas de mayor edad tendrían más descendencia,
dadas ciertas razones históricas, religiosas y culturales que
habitualmente inciden en el control de la natalidad. Esta hipótesis está
basada también en el conocimiento demográfico; sabemos que las tasas de
fecundidad en nuestro país han venido descendiendo desde hace varias
décadas. Sostenemos así que quienes conforman el grupo de 66 años y más
tendrán más hijos e hijas que los de 65 años o menos, con lo que se trata de una
prueba unilateral. Si llamamos 1 al grupo de hasta 65 años y 2 al
de quienes tienen 66 ó más, las hipótesis se expresan de la siguiente
manera:</p>
<p><span class="math display">\[H_{0}:\mu_{1} - \mu_{2} = 0\]</span></p>
<p><span class="math display">\[H_{1}:\mu_{1} - \mu_{2} &lt; 0\]</span></p>
<p>Los resultados descriptivos de los dos grupos son:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
grupo_edad
</th>
<th style="text-align:center;">
hijes.length
</th>
<th style="text-align:center;">
hijes.mean
</th>
<th style="text-align:center;">
hijes.median
</th>
<th style="text-align:center;">
hijes.sd
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
243
</td>
<td style="text-align:center;">
2.489712
</td>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
1.441310
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
260
</td>
<td style="text-align:center;">
2.607692
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
1.383835
</td>
</tr>
</tbody>
</table>
<p>El nombre de la variable <code>grupo_edad</code>, corresponde a los grupos 1, hasta 65 años y 2, de 66 ó más. Los grupos tienen 243 y 260 personas
respectivamente. La descripción muestra la media, mediana y desviación estándar.</p>
<p>Vemos que hay diferencia en la descendencia promedio de los dos
grupos. Las personas del segundo grupo (66 o más) tienen en promedio 0.12 hijos o hijas más que las del otro grupo. Ahora bien, dadas estas diferencias entre
las medias muestrales encontradas, nos interesa determinar si se deben al azar o
bien si tienen una magnitud tal que representen una diferencia que pueda
atribuirse a la diferencia de edad de quienes están en cada uno de los dos grupos.</p>
<p>Para realizar una prueba de diferencia de medias entre muestras independientes, se puede usar la distribución normal como buena aproximación, debido a que las muestras son grandes. La prueba es unilateral izquierda, porque interesa saber si el grupo 1 tiene menos hijas e hijos que el grupo 2. El punto crítico de esa prueba es <span class="math inline">\(z_{.05}=-1.64\)</span>. La región de rechazo está conformada por todos los valores de <em>z</em> que sean inferiores a <span class="math inline">\(-1.64\)</span>. Para hacer la prueba manualmente, ahora se calcula el <span class="math inline">\(z_{obs}\)</span> y según sea menor o mayor que ese punto crítico, se rechaza o no se rechaza <span class="math inline">\(H_0\)</span>.</p>
<p>La salida R para esta prueba es:</p>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  hijes by grupo_edad
## t = -0.93523, df = 495.19, p-value = 0.1751
## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0
## 95 percent confidence interval:
##        -Inf 0.08990955
## sample estimates:
## mean in group 1 mean in group 2 
##        2.489712        2.607692</code></pre>
<p>Por cuestiones de economía de recursos, los software usan siempre distribución <span class="math inline">\(t\)</span>. La salida muestra: la variable que se analiza (<code>hijes</code>, por hijas o hijos), según (<code>by</code>) la que clasifica los grupos (<code>grupo_edad</code>), el valor del estadístico de prueba (<span class="math inline">\(t=-0.94\)</span>), los grados de libertad (<span class="math inline">\(495\)</span>), el valor de probabilidad asociado a la
prueba (<span class="math inline">\(0.17\)</span>), el tipo de prueba, que es unilateral izquierda en este caso, un intervalo de confianza unilateral, como fue pedida la prueba y finalmente, las medias (<span class="math inline">\(2.49\)</span> y <span class="math inline">\(2.61\)</span>) de cantidades de hijos e hijas de cada grupo</p>
<p>El <span class="math inline">\(t_{obs}\)</span> de la prueba es <span class="math inline">\(-0.94\)</span>, que se ubica en la zona de no rechazo. Con ese resultado ya estamos en condiciones de concluir sobre la prueba: no se rechaza <span class="math inline">\(H_0\)</span>, las medias no difieren de manera significativa, no hay diferencia en el tamaño de la descendencia entre los grupos conformados.</p>
<p>Si no hubiésemos calculado previamente el punto crítico, podemos llegar
a esta conclusión a partir del valor <em>p</em>, que en este caso es <span class="math inline">\(0.1751\)</span> y
representa la probabilidad de haber hallado esa diferencia o una mayor,
por puro azar. Este es el valor que, como sabemos, se juzga en
comparación con el nivel de significación, por ser mayor a <span class="math inline">\(0.05\)</span> que
habíamos establecido, decidimos no rechazar la <span class="math inline">\(H_0\)</span>. Cuanto más pequeña
sea esta probabilidad, tanta más evidencia habrá para rechazar <span class="math inline">\(H_0\)</span>, en
este caso la consideramos grande y no rechazamos. La lectura del valor
<em>p</em> es, en este caso “si el número promedio de hijos e hijas de los dos grupos fuera el mismo, la probabilidad de haber encontrado entre dos muestras de tamaños <span class="math inline">\(243\)</span> y <span class="math inline">\(260\)</span>, una diferencia de <span class="math inline">\(0.12\)</span> ó superior, es de <span class="math inline">\(0.1751\)</span>”.
Brevemente:</p>
<p><span class="math display">\[P({(\overline{x}}_{1} - {\overline{x}}_{2} &lt; - 0.12)/{(\mu}_{1} - \mu_{2} = 0)) = 0.1751\]</span></p>
</div>
<div id="prueba-de-diferencia-de-proporciones" class="section level4 hasAnchor" number="12.1.1.4">
<h4><span class="header-section-number">12.1.1.4</span> Prueba de diferencia de proporciones<a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-de-diferencia-de-proporciones" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Compararemos ahora dos muestras en cuanto a la proporción de casos que
hay en una categoría de una variable que puede ser nominal o también de
un nivel superior<a href="#fn90" class="footnote-ref" id="fnref90"><sup>90</sup></a>. Aunque en los programas de análisis de datos
este procedimiento se realiza también solicitando <em>prueba t</em>, esto sólo
está autorizado si se trabaja con muestras grandes.</p>
<p>De manera muy similar a la prueba de diferencia de medias, la <span class="math inline">\(H_0\)</span>
afirma que no hay diferencia entre las proporciones de las dos
poblaciones, por lo que tiene la forma:</p>
<p><span class="math display">\[H_{0}:\ P_{1} - P_{2} = 0\]</span></p>
<p>Mientras que la <span class="math inline">\(H_1\)</span> puede indicar que las proporciones solo difieren:</p>
<p><span class="math display">\[H_{1}:\ P_{1} - P_{2} \neq 0\]</span></p>
<p>Cuando la prueba es bilateral o bien, si es unilateral derecha:</p>
<p><span class="math display">\[H_{1}:\ P_{1} - P_{2} &gt; 0\]</span></p>
<p>O izquierda:</p>
<p><span class="math display">\[H_{1}:\ P_{1} - P_{2} &lt; 0\]</span></p>
<p>Dado que solo trabajaremos con muestras grandes al analizar la
diferencia de proporciones, solo usaremos la distribución normal. El
estadístico de prueba tiene forma similar al que usamos en la prueba de
la proporción para una sola muestra, solo que ahora hay que hacer
participar los datos que provienen de dos muestras. Así resulta:</p>
<p><span class="math display">\[z = \frac{{(\widehat{p}}_{1} - {\widehat{p}}_{1}) - (P_{1} - P_{2})}{\sqrt{\frac{{\widehat{p}}_{1}*(1 - {\widehat{p}}_{1})}{n_{1}} + \frac{{\widehat{p}}_{2}*(1 - {\widehat{p}}_{2})}{n_{2}}}}\]</span></p>
<p>Donde <span class="math inline">\({\widehat{p}}_{1}\)</span> y <span class="math inline">\({\widehat{p}}_{2}\)</span> son los estimadores de
<span class="math inline">\(P_1\)</span> y <span class="math inline">\(P_2\)</span> respectivamente. A diferencia de la prueba sobre una sola
proporción, ahora no se cuenta con valores poblacionales de <span class="math inline">\(P_1\)</span> ni de <span class="math inline">\(P_2\)</span>, ya que la <span class="math inline">\(H_0\)</span> solo enuncia que son iguales. Por eso ahora, el error estándar del estimador (el denominador del estadístico de prueba) se calcula en base a las proporciones muestrales.</p>
<p>Ejemplo (datos ficticios): se dispone de datos de la proporción de
aplazos sobre el total de materias rendidas que tienen varones y mujeres
estudiantes de una carrera universitaria. En una muestra de 200 mujeres
hay un 15% de aplazos, mientras que entre los 150 varones que componen
la otra parte de la muestra, el porcentaje es del 17%. Nos preguntamos
si se trata de una diferencia significativa o si puede explicarse por la
variabilidad propia de los datos. Así, las hipótesis de la prueba serán:</p>
<p><span class="math display">\[H_{0}:P_{1} - P_{2} = 0\]</span></p>
<p><span class="math display">\[H_{1}:P_{1} - P_{2} \neq 0\]</span></p>
<p>Es decir que la hipótesis nula afirma que la diferencia en la proporción
de aplazos entre varones y mujeres es cero en la población, y la
hipótesis alternativa, dice que esa diferencia es distinta de cero.</p>
<p>Fijamos el nivel de significación en el 5% y, por tratarse de una prueba bilateral, los puntos críticos son <span class="math inline">\(\pm 1.96\)</span>.</p>
<p>A continuación calculamos el estadístico de prueba, que resulta:</p>
<p><span class="math display">\[z = \frac{{(\widehat{p}}_{1} - {\widehat{p}}_{1}) - (P_{1} - P_{2})}{\sqrt{\frac{{\widehat{p}}_{1}*(1 - {\widehat{p}}_{1})}{n_{1}} + \frac{{\widehat{p}}_{2}*(1 - {\widehat{p}}_{2})}{n_{2}}}} = \frac{\left( 0.15 - 0.17 \right) - 0}{\sqrt{\frac{0.15*(1 - 0.15)}{200} + \frac{0.17*(1 - 0.17)}{150}}} = - 0.50\]</span></p>
<p>Es un valor que no se ubica en la zona de rechazo, por lo que la
decisión es la de aceptar <span class="math inline">\(H_0\)</span> y concluir que no hay evidencia para
creer que la proporción de aplazos entre mujeres y varones sea
diferente.</p>
</div>
</div>
<div id="muestras-apareadas" class="section level3 hasAnchor" number="12.1.2">
<h3><span class="header-section-number">12.1.2</span> Muestras apareadas<a href="prueba-de-hipótesis-las-aplicaciones.html#muestras-apareadas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Esta prueba es útil cuando se buscan diferencias que puedan haber
aparecido en sujetos individuales. La prueba se llama así porque las
diferencias se consideran en pares o en parejas. En lugar de comparar
muestras provenientes de dos poblaciones independientes, compararemos
unidades de análisis consigo mismas, en dos momentos distintos. Ejemplo
típico de este uso lo constituyen las pruebas en las que se compara una
situación “antes y después”. Así, cuando cierta característica de las personas que integran el grupo experimental se evalúa antes de un tratamiento y se vuelve a
medir luego del tratamiento, interesa conocer en qué medida se han
producido cambios <em>individuales</em>. Observamos a cada individuo en dos
momentos y comparamos las dos observaciones (mediciones). En el contexto
del diseño experimental, la medición en el momento inicial se llama
<em>pretest</em> y la posterior <em>postest</em>.</p>
<p>Pero no es el único ámbito en que se usa, cuando se comparan los logros
que alcanzan quienes recorren una determinada experiencia
pedagógica, es valioso poder comparar el “estado inicial” (anterior a la experiencia) con el “estado final” (posterior) de cada participante, sea en términos de cuánto aprendieron o de los cambios que hubo en determinada conducta. Esta prueba
pone el acento en los cambios sucedidos en cada participante y no en las
diferencias entre ellos. Cuando interesa conocer la diferencia de
presión arterial a la mañana y al atardecer, corresponde medir la
presión arterial de cada persona en los dos horarios y comparar uno a
uno. Por cierto, luego los resultados se agregan, pero las diferencias
se miden caso por caso.</p>
<p>No hay cambio conceptual en el planteo de las hipótesis: la <span class="math inline">\(H_0\)</span> afirma que no hay diferencia entre las dos mediciones (o entre las mediciones hechas en momentos distintos) y la <span class="math inline">\(H_1\)</span> podrá ser unilateral o bilateral. Sin embargo cambiamos levemente la notación, porque vamos a resumir la diferencia en la letra <span class="math inline">\(\overline{D}\)</span> (por media de diferencias) y equivale a <span class="math inline">\(\mu_{1} - \mu_{2}\)</span>. El objetivo de este cambio es poner el acento en que no tratamos con dos poblaciones
independientes (una representada por <span class="math inline">\(\mu_{1}\)</span> y la otra por <span class="math inline">\(\mu_{2}\)</span>)
sino con las diferencias entre dos mediciones. <span class="math inline">\(\overline{D}\)</span> es un
parámetro y es sobre <span class="math inline">\(\overline{D}\)</span> que formulamos ahora las hipótesis:</p>
<p><span class="math display">\[H_{0}:\ \overline{D} = 0\]</span></p>
<p>La hipótesis alternativa puede ser bilateral</p>
<p><span class="math display">\[H_{1}:\ \overline{D} \neq 0\]</span></p>
<p>Unilateral derecha</p>
<p><span class="math display">\[H_{1}:\ \overline{D} &gt; 0\]</span></p>
<p>O bien unilateral izquierda</p>
<p><span class="math display">\[H_{1}:\ \overline{D} &lt; 0\]</span></p>
<p>El estimador de <span class="math inline">\(\overline{D}\)</span> se llamará <span class="math inline">\(\overline{d}\)</span> y es la media
de las diferencias individuales, que tiene distribución <em>t de Student</em>
con <em>n-1</em> grados de libertad. Como se trata de una sola variable, el
estadístico de prueba es semejante al que usábamos para una sola
muestra, porque resume las diferencias para cada caso:</p>
<p><span class="math display">\[t = \frac{\overline{d} - \overline{D}}{\frac{s_{d}}{\sqrt{n}}} = \frac{\overline{d}}{\frac{s_{d}}{\sqrt{n}}}\]</span></p>
<p>La última igualdad se debe a que, bajo la <span class="math inline">\(H_0\)</span>, <span class="math inline">\(\overline{D} = 0\)</span>.</p>
<p><span class="math inline">\(s_{d}\)</span> es la desviación estándar de la variable <span class="math inline">\(d\)</span>, que mide las
diferencias individuales.</p>
<p>Ejemplo (parcial<a href="#fn91" class="footnote-ref" id="fnref91"><sup>91</sup></a>): se busca detectar el eventual efecto que
tendría una intervención terapéutica sobre el bienestar de personas
diagnosticadas de depresión. Disponemos de un test que nos permite
evaluar el bienestar con nivel cuantitativo, en una
escala que va de 0 (mínimo bienestar) a 10 (máximo bienestar). Para
evaluar la terapia, nos interesamos por los cambios que suceden en el
bienestar entre el momento previo y el posterior a la misma. Hacemos esto por medio de la aplicación del test a una muestra de 7 pacientes con depresión, en dos momentos: antes de la terapia y al cabo de ella.</p>
<p>Esperamos que la terapia tenga por efecto el de aumentar el bienestar de quienes la reciben, dicho de otro modo, esperamos cambios
positivos en el puntaje del test. Las hipótesis son entonces:</p>
<p><span class="math display">\[H_{0}:\ \overline{D} = 0\]</span></p>
<p><span class="math display">\[H_{1}:\ \overline{D} &gt; 0\]</span></p>
<p>Fijado el nivel de significación en el 5% y suponiendo que la variable
se distribuye de manera normal en la población, el punto crítico de la
distribución <em>t</em> con 6 grados de libertad, de una cola derecha es
<span class="math inline">\(t_{c} =+1.943\)</span>.</p>
<p>Los siguientes son los datos recogidos:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
persona
</th>
<th style="text-align:center;">
antes <span class="math inline">\(x_1\)</span>
</th>
<th style="text-align:center;">
después <span class="math inline">\(x_2\)</span>
</th>
<th style="text-align:center;">
diferencia <span class="math inline">\(d_i\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
1
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
2
</td>
</tr>
<tr>
<td style="text-align:center;">
2
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
3
</td>
</tr>
<tr>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
0
</td>
</tr>
<tr>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
3
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
2
</td>
</tr>
<tr>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
4
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
5
</td>
<td style="text-align:center;">
6
</td>
<td style="text-align:center;">
1
</td>
</tr>
<tr>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
7
</td>
<td style="text-align:center;">
0
</td>
</tr>
</tbody>
</table>
<p>Esta tabla indica, para cada persona, el puntaje que obtuvo en la
prueba que mide bienestar tomada antes de la terapia (<span class="math inline">\(x_1\)</span>) y en la
tomada después (<span class="math inline">\(x_2\)</span>). Además, muestra la diferencia para cada caso, que es la resta de la segunda menos la primera, a esas diferencias las
llamamos <span class="math inline">\(d_i\)</span>, el subíndice <span class="math inline">\(i\)</span> se refiere a cada caso y va desde 1
hasta 7.</p>
<p>La hipótesis nula de la prueba es que no hay diferencia en las dos
mediciones, es decir que no hay efectos de la terapia, que el bienestar
luego del tratamiento es igual que antes de él. El cambio
respecto de las pruebas para muestras independientes es que ahora
pasamos a trabajar con <span class="math inline">\(d\)</span> como variable, sus medidas descriptivas son;
la media de las <span class="math inline">\(d_i\)</span>, <span class="math inline">\(\overline{d} = 1.286\)</span>, y desviación estándar,
<span class="math inline">\(s_{d} = 1.113\)</span>.</p>
<p>Con esa información se llega al estadístico de prueba:</p>
<p><span class="math display">\[t_{\text{obs}} = \frac{\overline{d}}{\frac{s_{d}}{\sqrt{n}}} = \frac{1.286}{\frac{1.113}{\sqrt{7}}} = 3.057\]</span></p>
<p>Por ser mayor que el punto crítico (<span class="math inline">\(t_{\text{obs}} &gt; t_{c}\)</span>), está en
la zona de rechazo de <span class="math inline">\(H_0\)</span>, y se concluye que hay evidencia para
considerar que los puntajes en el test de bienestar son mayores luego de la terapia.</p>
<!--falta-->
<p>La salida R para esta prueba es:</p>
<pre><code>## 
##  Paired t-test
## 
## data:  antes and despues
## t = -3.0571, df = 6, p-value = 0.01115
## alternative hypothesis: true mean difference is less than 0
## 95 percent confidence interval:
##        -Inf -0.4684903
## sample estimates:
## mean difference 
##       -1.285714</code></pre>
<p>Que indica, las dos variables que se comparan (antes y después), el valor t, los grados de libertad y el valor <span class="math inline">\(p\)</span>, que
vale 0.01115. Es una probabilidad pequeña (menos del 0.05) que confirma
el rechazo de <span class="math inline">\(H_0\)</span>.</p>
</div>
<div id="coeficiente-r-de-pearson" class="section level3 hasAnchor" number="12.1.3">
<h3><span class="header-section-number">12.1.3</span> Coeficiente r de Pearson<a href="prueba-de-hipótesis-las-aplicaciones.html#coeficiente-r-de-pearson" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el análisis de relaciones entre variables a partir de datos de
muestras, se han calculado coeficientes para medir el grado (o
intensidad) de la asociación. Luego de haber visto los procedimientos de
inferencia, corresponde generalizar las conclusiones obtenidas en estos
análisis a toda la población de referencia. Ahora se dispone de las
herramientas necesarias para hacer esa generalización. Para el
coeficiente <em>r de Pearson</em> la lógica para la prueba de hipótesis es la
que ya conocemos, solo cambia la forma de calcular el estadístico de
prueba. Para niveles de medición más bajos (ordinales o nominales), se
usan otras pruebas, que se desarrollan en el próximo capítulo</p>
<p>Si ha sido obtenido en una muestra representativa, el coeficiente de
correlación de Pearson allí calculado es un estimador del coeficiente de
correlación poblacional, es decir que mide la intensidad de la
asociación entre las variables en la población; así como <span class="math inline">\(\overline{x}\)</span>
es el estimador de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\widehat{p}\)</span> el estimador de <span class="math inline">\(P\)</span>.
Manteniendo la notación anterior, usaremos la letra griega <span class="math inline">\(\rho\)</span> (rho)
para referirnos al coeficiente de correlación paramétrico (o
poblacional) que es estimado por el muestral: <span class="math inline">\(r\)</span>.</p>
<p>Si se extraen todas las muestras posibles de una población dada y en
cada una se calcula <span class="math inline">\(r\)</span>, la media de todos los coeficientes de
correlación encontrados, coincide con el coeficiente de correlación
paramétrico. A esa media, que no calculamos, porque no es posible
extraer “todas las muestras de la población”, la llamamos esperanza.</p>
<p>Dicho de otra manera, <span class="math inline">\(r\)</span> es un estimador insesgado de <span class="math inline">\(\rho\)</span>. Los
escribimos: <span class="math inline">\(E(r) = \rho\)</span>.</p>
<p>Por su parte, la varianza de r es:</p>
<p><span class="math display">\[\sigma_{r}^{2} = \frac{1 - r^{2}}{n - 2}\]</span></p>
<p>Por lo que el error estándar del estimador tiene la forma:</p>
<p><span class="math display">\[\sigma_{r} = \sqrt{\frac{1 - r^{2}}{n - 2}}\]</span></p>
<p>Y, tal como sucedió con la media y la proporción, el Teorema Central del Límite indica que a medida que aumenta el tamaño de las muestras, la distribución de los <span class="math inline">\(r\)</span> tiende a ser normal. Si podemos suponer que en la población, la variable bajo análisis tiene distribución normal, es válido usar la distribución <span class="math inline">\(t\)</span> cuando la muestra es pequeña. Cuando
aumenta el tamaño de la muestra esta distribución tiende a la normal. En consecuencia, y como sucedió con la media, usaremos distribución <em>t de Student</em> siempre.</p>
<p>Para esta prueba de hipótesis, la distribución <span class="math inline">\(t\)</span> tiene grados de
libertad que se calculan como el tamaño de la muestra menos dos:</p>
<p><span class="math display">\[gl = n - 2\]</span></p>
<p>Conociendo la distribución de probabilidades para <span class="math inline">\(r\)</span> podemos construir
el estadístico de prueba restando el estimador menos el parámetro y
dividiendo por el error estándar del estimador:</p>
<p><span class="math display">\[t = \frac{r - \rho}{\sqrt{\frac{1 - r^{2}}{n - 2}}}\]</span></p>
<p>La hipótesis de carácter conservador (aquella que señala la
no-diferencia) será la que afirme que en la población no hay relación
entre las variables, por lo que si en la muestra hallamos un valor de
<span class="math inline">\(r\)</span> no nulo, habrá sido por azar. Nuevamente se trata de decidir si un
valor muestral observado es evidencia suficiente para rechazar la <span class="math inline">\(H_0\)</span>; a la que escribiremos:</p>
<p><span class="math display">\[H_{0}:\rho = 0\]</span></p>
<p>La hipótesis alternativa puede ser bilateral:</p>
<p><span class="math display">\[H_{1}:\rho \neq 0\]</span></p>
<p>O unilateral derecha:</p>
<p><span class="math display">\[H_{1}:\rho &gt; 0\]</span></p>
<p>O unilateral izquierda:</p>
<p><span class="math display">\[H_{1}:\rho &lt; 0\]</span></p>
<p>Y en todos los casos transformaremos el coeficiente <span class="math inline">\(r\)</span> observado a puntaje t, haciendo:</p>
<p><span class="math display">\[t = \frac{r_{\text{obs}} - \rho}{\sqrt{\frac{1 - r_{\text{obs}}^{2}}{n - 2}}} = \frac{r_{\text{obs}}}{\sqrt{\frac{1 - r_{\text{obs}}^{2}}{n - 2}}}\]</span></p>
<p>La última igualdad se debe a que la hipótesis nula afirma que <span class="math inline">\(\rho = 0\)</span>.</p>
<p>Ejemplo (datos ficticios): se observa la relación entre el tiempo que se dedicó a preparar el examen de una materia y la calificación obtenida en ese examen, a partir de una muestra de 27 estudiantes. Se obtiene un coeficiente de correlación lineal de Pearson de <span class="math inline">\(r_{obs} = + 0.37\)</span>. El signo positivo de este coeficiente indica que la relación es directa, por lo que, en la muestra, quienes dedican más tiempo a la preparación, tienden a tener notas más altas. El valor absoluto indica que se trata de una relación moderada entre las dos variables. Ahora nos interesa probar si este resultado es suficiente evidencia para creer que en la población, las dos variables están relacionadas, es decir, que en la población el coeficiente de correlación no es cero. La pregunta es si hemos encontrado <span class="math inline">\(r=+0.37\)</span> porque en la población las variables están correlacionadas o solo por las variaciones propias del procedimiento aleatorio de muestreo, es decir, solo por azar.</p>
<p>Las hipótesis correspondientes a este problema son:</p>
<p><span class="math display">\[H_{0}:\rho = 0\]</span></p>
<p><span class="math display">\[H_{1}:\rho \neq 0\]</span></p>
<p>Es bilateral porque nuestro interés es saber si <span class="math inline">\(\rho\)</span> difiere de cero.</p>
<p>Fijamos el nivel de significación en el 5% y hallamos en una
distribución <em>t de Student</em> con 25 grados de libertad (<span class="math inline">\(n-2=27-2=25\)</span>)
los valores críticos correspondientes son <span class="math inline">\(±2.05\)</span>, gráficamente:</p>
<!--falta-->
<p><img src="imagenes/image209.png" width="324" style="display: block; margin: auto;" /></p>
<p>El área sombreada constituye la probabilidad extrema de 0.05, repartida
en dos colas de 0.025 cada una. La zona de rechazo de <span class="math inline">\(H_0\)</span> se constituye
por el conjunto de los valores <span class="math inline">\(t\)</span> mayores a 2.05 así como los menores a -2.05.</p>
<p>Ahora transformamos el valor de <span class="math inline">\(r\)</span> obtenido a puntaje <span class="math inline">\(t\)</span>, calculando
el estadístico de prueba:</p>
<p><span class="math display">\[t = \frac{r_{\text{obs}}}{\sqrt{\frac{1 - r_{\text{obs}}^{2}}{n - 2}}} = \frac{0.37}{\sqrt{\frac{1 - {0.37}^{2}}{27 - 2}}} = 1.99\]</span></p>
<p>Un valor que no se encuentra en la zona de rechazo, por lo que la
decisión es la de aceptar <span class="math inline">\(H_0\)</span> y concluir que no hay suficiente
evidencia para afirmar que haya una correlación lineal no nula entre el
tiempo que se dedica a preparar una materia y la nota que se
obtiene en el examen. Diremos que el coeficiente de correlación hallado
en la muestra no difiere significativamente de cero o, más simplemente,
que no es significativo.</p>
<p>Como siempre puede hacerse en las pruebas de hipótesis, vamos a llegar a
la misma conclusión calculando el valor <span class="math inline">\(p\)</span> asociado al coeficiente <span class="math inline">\(r\)</span>
muestral. Se trata de encontrar la probabilidad de hallar un valor de
<span class="math inline">\(r\)</span> como el observado o uno más extremo que él, si la hipótesis nula
fuera cierta. Como la prueba es bilateral debemos tratar a la expresión
“más extremo” como incluyendo dos posibilidades, que <span class="math inline">\(r\)</span> sea mayor que
el observado o menor que su opuesto, por lo que la probabilidad que
buscamos se escribe:</p>
<p><span class="math display">\[P( r &lt; -r_{obs} \cup r &gt; r_{obs} / H_0 \; es \; verdadera) = P(r &lt; -0.37 \cup r &gt; 0.37/ \rho = 0)\]</span></p>
<p>Que se lee como “la probabilidad que <span class="math inline">\(r\)</span> sea menor que el opuesto al
valor observado o mayor que el valor observado, dado que la hipótesis
nula es verdadera”</p>
<p>Usando el estadístico de prueba, transformamos los dos valores de
<span class="math inline">\(r_{obs}\)</span> en puntajes <span class="math inline">\(t\)</span> y entonces esa probabilidad, expresada en
términos de <span class="math inline">\(t\)</span>, nos queda:</p>
<p><span class="math display">\[P(t &lt; - 1.99 \cup t &gt; 1.99)\]</span></p>
<p>En la que no incluimos la condición que <span class="math inline">\(H_0\)</span> sea verdadera
<span class="math inline">\((\rho = 0)\)</span> porque está implícita en la distribución <span class="math inline">\(t\)</span>
de <span class="math inline">\(r\)</span>. Esta probabilidad es 0.0576. Debido a que es mayor a nuestro nivel de significación
<span class="math inline">\((\alpha = 0.05)\)</span>, la decisión es la de no rechazar <span class="math inline">\(H_0\)</span>.
La lectura de este valor <span class="math inline">\(p\)</span> es “si en la población no existiera
correlación entre las variables, la probabilidad de haber hallado un
valor como el observado o más extremo que él sería de 0.0576.
Consideramos a este valor como elevado, por lo que no rechazamos la
hipótesis de ausencia de correlación”.</p>
<p><em>Dos consecuencias de este resultado:</em></p>
<p>Primera: un coeficiente que, a nivel muestral habríamos juzgado como
moderado no puede generalizarse como significativo a toda la población.
Esto se debe principalmente al reducido tamaño de la muestra. Así, para
que este valor de <span class="math inline">\(r\)</span> hubiese representado una asociación significativa
en la población, habría sido necesario que proviniese de una muestra de
mayor tamaño.</p>
<p>Segunda: el valor de <span class="math inline">\(t_{obs}\)</span> es cercano al punto crítico (1.99 frente a 2.05), de modo que es “poco lo que le falta” para que la hipótesis sea rechazada. En el procedimiento a través del valor <span class="math inline">\(p\)</span>, eso equivale a que dicho valor de probabilidad apenas supera al nivel de significación establecido: 5.6% frente a 5%. Aun así, nuestro criterio fijado a priori indica que no debemos rechazar <span class="math inline">\(H_0\)</span>. Pero esto debe informarse en el reporte, para que el lector pueda interpretar los resultados.</p>
<p>La salida R para esta operación es:</p>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  tiempo_prep and calif
## t = 2.0035, df = 25, p-value = 0.05608
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.009391405  0.658839508
## sample estimates:
##     cor 
## 0.37195</code></pre>
<p>La lectura es que el puntaje <span class="math inline">\(t\)</span> asociado al valor muestral es 2.0035, al que, con 25 grados de libertad, le corresponde una probabilidad extrema de 0.05608. El intervalo de confianza estima, al 95%, el coeficiente poblacional. Que este intervalo incluya al cero es consistente con que al un nivel del 5% la <span class="math inline">\(H_0\)</span> no sea rechazada.<br />
Al final está el coeficiente de correlación muestral, de 0.37195 cuya probabilidad de haber sido encontrado por puro azar es 0.05608.<br />
A un nivel de significación del 5% no se rechaza la <span class="math inline">\(H_0\)</span> según la cual las variables no están correlacionadas. Aunque sí se rechaza si se fija un nivel de significación “más tolerante” del 10%.</p>
<p>Resumen de pruebas tratadas en el capítulo</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:center;">
Parámetro
</th>
<th style="text-align:center;">
Estimador
</th>
<th style="text-align:center;">
Estadístico de prueba
</th>
<th style="text-align:center;">
Supuestos
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\mu_{1} - \mu_{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\({\overline{x}}_{1} - {\overline{x}}_{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(t = \frac{{(\overline{x}}_{1} - {\overline{x}}_{2})}{s_{comb}*\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}\)</span>
</td>
<td style="text-align:center;">
Grupos independientes
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(gl = n_{1} + n_{2} - 2\)</span>
</td>
<td style="text-align:center;">
Distribución normal en la dos poblaciones ó <span class="math inline">\(n_{1} &gt; 30\)</span> y <span class="math inline">\(n_{2} &gt; 30\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(s_{comb}^{2} = \frac{(n_{1} - 1)*s_{1}^{2} + (n_{2} - 1)*s_{2}^{2}}{n_{1} + n_{2} - 2}\)</span>
</td>
<td style="text-align:center;">
Varianzas iguales
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\mu_{1} - \mu_{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\({\overline{x}}_{1} - {\overline{x}}_{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(t = \frac{{(\overline{x}}_{1} - {\overline{x}}_{2})}{\sqrt{\frac{s_{1}^{2}}{n_{1}} + \frac{s_{2}^{2}}{n_{2}}}}\)</span>
</td>
<td style="text-align:center;">
Grupos independientes
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
<span class="math inline">\(gl = \frac{( \frac{s_{1}^{2}}{n_{1}} + \frac{s_{2}^{2}}{n_{2}} )^{2}}{\frac{( \frac{s_{1}^{2}}{n_{1}} )^{2}}{n_{1} - 1} + \frac{( \frac{s_{2}^{2}}{n_{2}} )^{2}}{n_{2} - 1}}\)</span>
</td>
<td style="text-align:center;">
Distribución normal en la dos poblaciones ó <span class="math inline">\(n_{1} &gt; 30\)</span> y <span class="math inline">\(n_{2} &gt; 30\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
</td>
<td style="text-align:center;">
Varianzas diferentes
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(P_{1} - P_{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\({\widehat{p}}_{1} - {\widehat{p}}_{2}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(z = \frac{{(\widehat{p}}_{1} - {\widehat{p}}_{1})}{\sqrt{\frac{{\widehat{p}}_{1}*(1 - {\widehat{p}}_{1})}{n_{1}} + \frac{{\widehat{p}}_{2}*(1 - {\widehat{p}}_{2})}{n_{2}}}}\)</span>
</td>
<td style="text-align:center;">
Grupos independientes y <span class="math inline">\(n_{1} &gt; 100\)</span> y <span class="math inline">\(n_{2} &gt; 100\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\overline{D}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(\overline{d}\)</span>
</td>
<td style="text-align:center;">
<span class="math inline">\(t = \frac{\overline{d}}{\frac{s_{d}}{\sqrt{n}}};gl = n - 2\)</span>
</td>
<td style="text-align:center;">
Distribución normal de <span class="math inline">\(d\)</span> ó <span class="math inline">\(n &gt; 30\)</span>
</td>
</tr>
<tr>
<td style="text-align:center;">
<span class="math inline">\(\rho\)</span>
</td>
<td style="text-align:center;">
r
</td>
<td style="text-align:center;">
<span class="math inline">\(t = \frac{r}{\sqrt{\frac{1 - r^{2}}{n - 2}}}\)</span>
</td>
<td style="text-align:center;">
Distribución normal
</td>
</tr>
</tbody>
</table>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="hacerlo-en-r-10" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Hacerlo en R<a href="prueba-de-hipótesis-las-aplicaciones.html#hacerlo-en-r-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="ejemplo-1." class="section level3 hasAnchor" number="12.2.1">
<h3><span class="header-section-number">12.2.1</span> Ejemplo 1.<a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-1." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Diferencia de medias muestras grandes</p>
<p>Generamos datos ficticios:</p>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb609-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb609-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb609-2"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb609-2" tabindex="-1"></a>duracion <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="fl">6.7</span>, <span class="fl">1.2</span>), <span class="fu">rnorm</span>(<span class="dv">150</span>, <span class="fl">6.3</span>, <span class="fl">1.5</span>))</span>
<span id="cb609-3"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb609-3" tabindex="-1"></a>trabaja <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;si&quot;</span>, <span class="dv">100</span>), <span class="fu">rep</span>(<span class="st">&quot;no&quot;</span>, <span class="dv">150</span>))</span>
<span id="cb609-4"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb609-4" tabindex="-1"></a>datos.ejemplo<span class="fl">.1</span> <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(trabaja, duracion)</span></code></pre></div>
<p>Y solicitamos la prueba <span class="math inline">\(t\)</span> a la que hay que indicar:<br />
- qué variable se compara (la duración de la carrera)<br />
- entre quiénes se compara (quienes trabajan y quienes no)<br />
- de dónde provienen los datos (la matriz de datos)</p>
<p>La variable cuyas medias se comparan y la que define los grupos se separan con el signo <code>~</code> (alt+0126 en windows), los datos, luego de una coma.</p>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb610-1" tabindex="-1"></a><span class="fu">t.test</span>(duracion <span class="sc">~</span> trabaja, <span class="at">data =</span> datos.ejemplo<span class="fl">.1</span>)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  duracion by trabaja
## t = -3.5765, df = 246.64, p-value = 0.000419
## alternative hypothesis: true difference in means between group no and group si is not equal to 0
## 95 percent confidence interval:
##  -0.9058173 -0.2624402
## sample estimates:
## mean in group no mean in group si 
##         6.246536         6.830665</code></pre>
<p>La salida indica que es una prueba t de Welch, implica que introduce la corrección en el cálculo de la varianza combinada cuando las varianzas poblacionales se consideran diferentes a un nivel del 5%.<br />
Los valores que interesan son:<br />
- el puntaje <span class="math inline">\(t\)</span> que indica la cantidad de desviaciones estándar que la diferencia observada se aleja de cero. El signo depende del modo en que han sido elegidas para restar, no tiene interpretación en pruebas bilaterales.<br />
- la lateralidad de la prueba, indicada en “alternative hypothesis: true difference in means is not equal to 0”<br />
- el valor p que indica la probabilidad de encontrar una diferencia entre las medias muestrales como la observada o más extrema si en la población la diferencia fuera cero. Por ser un valor pequeño (&lt;0.01), se decide rechazar <span class="math inline">\(H_{0}\)</span> y concluir que las media poblacionales difieren significativamente.<br />
- los valores de las medias muestrales</p>
<p>Los valores numéricos no son los mismos que se obtuvieron manualmente, porque la generación aleatoria produce las cantidades de casos que se piden (100 y 150) extraídos de distribuciones con los parámetros (<span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>) indicados, pero los estadísticos muestrales (<span class="math inline">\(\bar{x}\)</span> y <span class="math inline">\(s\)</span>) no necesariamente coinciden con ellos, como sabemos desde que tratamos las distribuciones en el muestreo.<br />
La conclusión de la prueba sí es la misma.</p>
</div>
<div id="ejemplo-2." class="section level3 hasAnchor" number="12.2.2">
<h3><span class="header-section-number">12.2.2</span> Ejemplo 2.<a href="prueba-de-hipótesis-las-aplicaciones.html#ejemplo-2." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Diferencia de medias muestras grandes</p>
<p>Generamos datos ficticios igual que antes, pero con 20 y 25 observaciones:</p>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb612-1" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb612-2"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb612-2" tabindex="-1"></a>duracion<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">20</span>, <span class="fl">6.7</span>, <span class="fl">1.2</span>), <span class="fu">rnorm</span>(<span class="dv">25</span>, <span class="fl">6.3</span>, <span class="fl">1.5</span>))</span>
<span id="cb612-3"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb612-3" tabindex="-1"></a>trabaja<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;si&quot;</span>, <span class="dv">20</span>), <span class="fu">rep</span>(<span class="st">&quot;no&quot;</span>, <span class="dv">25</span>))</span>
<span id="cb612-4"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb612-4" tabindex="-1"></a>datos.ejemplo<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(trabaja<span class="fl">.2</span>, duracion<span class="fl">.2</span>)</span></code></pre></div>
<p>Solicitamos la prueba como antes:</p>
<div class="sourceCode" id="cb613"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb613-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb613-1" tabindex="-1"></a><span class="fu">t.test</span>(duracion<span class="fl">.2</span> <span class="sc">~</span> trabaja<span class="fl">.2</span>, <span class="at">data =</span> datos.ejemplo<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  duracion.2 by trabaja.2
## t = -1.8173, df = 42.347, p-value = 0.07625
## alternative hypothesis: true difference in means between group no and group si is not equal to 0
## 95 percent confidence interval:
##  -1.32432188  0.06917121
## sample estimates:
## mean in group no mean in group si 
##         6.301053         6.928629</code></pre>
<p>Ahora la lectura es que el valor p es grande por lo que no se rechaza la <span class="math inline">\(H_{0}\)</span>. No hay evidencia para considerar que las medias poblacionales difieran.</p>
</div>
<div id="aplicación-a-los-datos-de-población-adulta-mayor" class="section level3 hasAnchor" number="12.2.3">
<h3><span class="header-section-number">12.2.3</span> Aplicación a los datos de Población Adulta Mayor<a href="#aplicaci%C3%B3n-a-los-datos-de-poblaci%C3%B3n-adulta-mayor" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se lee la base y se la nombra como <code>adultes_mayores</code>:</p>
<div class="sourceCode" id="cb615"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb615-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb615-1" tabindex="-1"></a>adultes_mayores <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;bases/archivostxt/Adultos.mayores.txt&quot;</span>,</span>
<span id="cb615-2"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb615-2" tabindex="-1"></a>  <span class="at">sep =</span> <span class="st">&quot;;&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">fileEncoding =</span> <span class="st">&quot;latin1&quot;</span></span>
<span id="cb615-3"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb615-3" tabindex="-1"></a>)</span></code></pre></div>
<p>Luego, se llevan a numéricas la edad y la cantidad de hijas e hijos, porque fueron leídas como factores:</p>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb616-1" tabindex="-1"></a>adultes_mayores<span class="sc">$</span>edad <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">as.character</span>(adultes_mayores<span class="sc">$</span>edad))</span>
<span id="cb616-2"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb616-2" tabindex="-1"></a>adultes_mayores<span class="sc">$</span>hijes <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">as.character</span>(adultes_mayores<span class="sc">$</span>hijos))</span></code></pre></div>
<p>Se construye la variable que agrupa las edades (1 para menores de 66, 2 para el resto):</p>
<div class="sourceCode" id="cb617"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb617-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb617-1" tabindex="-1"></a>adultes_mayores<span class="sc">$</span>grupo_edad <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(adultes_mayores<span class="sc">$</span>edad <span class="sc">&lt;</span> <span class="dv">66</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span></code></pre></div>
<p>Y se solicita la prueba de <code>hijes</code> según <code>grupo_edad</code>, unilateral izquierda:</p>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb618-1" tabindex="-1"></a><span class="fu">t.test</span>(hijes <span class="sc">~</span> grupo_edad, <span class="at">data =</span> adultes_mayores, <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  hijes by grupo_edad
## t = -0.93523, df = 495.19, p-value = 0.1751
## alternative hypothesis: true difference in means between group 1 and group 2 is less than 0
## 95 percent confidence interval:
##        -Inf 0.08990955
## sample estimates:
## mean in group 1 mean in group 2 
##        2.489712        2.607692</code></pre>
</div>
<div id="prueba-apareada" class="section level3 hasAnchor" number="12.2.4">
<h3><span class="header-section-number">12.2.4</span> Prueba apareada<a href="prueba-de-hipótesis-las-aplicaciones.html#prueba-apareada" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se contruye la matriz de datos ficticios:</p>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb620-1" tabindex="-1"></a>antes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">7</span>)</span>
<span id="cb620-2"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb620-2" tabindex="-1"></a>despues <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">7</span>, <span class="dv">7</span>, <span class="dv">6</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>)</span>
<span id="cb620-3"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb620-3" tabindex="-1"></a>para_prueba_apareada <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(antes, despues)</span></code></pre></div>
<p>Y se solicita la prueba <span class="math inline">\(t\)</span>, indicando en el argumento que es apareada:</p>
<div class="sourceCode" id="cb621"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb621-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb621-1" tabindex="-1"></a><span class="fu">t.test</span>(antes, despues, <span class="at">data =</span> para_prueba_apareada, <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  antes and despues
## t = -3.0571, df = 6, p-value = 0.02231
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -2.3147876 -0.2566409
## sample estimates:
## mean difference 
##       -1.285714</code></pre>
</div>
<div id="coeficiente-de-correlación" class="section level3 hasAnchor" number="12.2.5">
<h3><span class="header-section-number">12.2.5</span> Coeficiente de correlación<a href="#coeficiente-de-correlaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea que se cuenta con datos de 27 estudiantes sobre el tiempo dedicado a preparar un parcial (<code>tiempo_prep</code>) y la calificación obtenida (<code>calif</code>). Para solicitar la prueba de significación sobre el coeficiente r de Pearson, simplememente se solicita:</p>
<div class="sourceCode" id="cb623"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb623-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb623-1" tabindex="-1"></a><span class="fu">cor.test</span>(tiempo_prep, calif)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  tiempo_prep and calif
## t = 2.0035, df = 25, p-value = 0.05608
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.009391405  0.658839508
## sample estimates:
##     cor 
## 0.37195</code></pre>
<p>Como sucedió con el comando <em>cor</em> que ofrecía el coeficiente de correlación, esta prueba por defecto calcula el coeficiente de Pearson, si se necesita el coeficiente de Spearman, debe indicarse en el argumento <em>method</em>:</p>
<div class="sourceCode" id="cb625"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb625-1"><a href="prueba-de-hipótesis-las-aplicaciones.html#cb625-1" tabindex="-1"></a><span class="fu">cor.test</span>(tiempo_prep, calif, <span class="at">method =</span> <span class="st">&quot;spearman&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Spearman&#39;s rank correlation rho
## 
## data:  tiempo_prep and calif
## S = 1956, p-value = 0.03811
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.4029304</code></pre>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Gertler2017" class="csl-entry">
Gertler, Paul J., Sebastian Martinez, Patrick Premand, Laura B. Rawlings, and Christel M. J. Vermeersch. 2017. <em><span class="nocase">La evaluaci<span class="nocase">ó</span>n de impacto en la pr<span class="nocase">á</span>ctica</span></em>. Edited by Banco Interamericano de Desarrollo y Banco Mundial. Segunda. Wahington, DC.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="82">
<li id="fn82"><p>La fórmula de este promedio tiene en cuenta que las varianzas provienen de muestras de diferente tamaño y que los denominadores de las varianzas son <span class="math inline">\(n-1\)</span>. Por eso no es simplemente la suma de ambas dividida dos. Solo en el caso que las muestras son de igual tamaño (<span class="math inline">\(n_1=n_2\)</span>), se trata del promedio simple y <span class="math inline">\(s_{comb}^{2} = \frac{s_{1}^{2} + s_{2}^{2}}{2}\)</span><a href="prueba-de-hipótesis-las-aplicaciones.html#fnref82" class="footnote-back">↩︎</a></p></li>
<li id="fn83"><p>Esta expresión se conoce como la ecuación de Welch–Satterthwaite y fue desarrollada en el campo de la teoría de errores, los programas de análisis de datos la aplican de manera automática cuando las varianzas son diferentes a cierto nivel de significación.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref83" class="footnote-back">↩︎</a></p></li>
<li id="fn84"><p>Se llama homogeneidad aquello que coloquialmente podría expresarse como “suficientemente parecidas como para tratarlas como iguales”.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref84" class="footnote-back">↩︎</a></p></li>
<li id="fn85"><p>Con algunos programas de análisis de datos se verifica si puede suponerse que las varianzas poblacionales son iguales o no y, en base al resultado de esa verificación, se calcula el error estándar de la diferencia con una fórmula o con otra. Otros programas ofrecen ambos resultados e incluyen la prueba de homogeneidad de varianzas, para que el usuario elija.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref85" class="footnote-back">↩︎</a></p></li>
<li id="fn86"><p>Recordemos que la distribución normal vale para muestras grandes, por el Teorema Central del Límite.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref86" class="footnote-back">↩︎</a></p></li>
<li id="fn87"><p>Recordemos que esta distribución tiende a la normal cuando las muestras son grandes.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref87" class="footnote-back">↩︎</a></p></li>
<li id="fn88"><p>Se trata de una versión muy simplificada, solo para ilustrar un uso de esta prueba.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref88" class="footnote-back">↩︎</a></p></li>
<li id="fn89"><p>Redondeado al entero.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref89" class="footnote-back">↩︎</a></p></li>
<li id="fn90"><p>Aunque la prueba se usa principalmente para comparar variables nominales, no hay inconveniente en usarla con variables métricas, definiendo con precisión qué se compara. Por ejemplo, si la variable es la edad, podemos comparar la proporción de personas mayores de 65 años en dos muestras. Todos los mayores de 65 constituyen una categoría y el resto la otra. En ese caso decimos que hemos “dicotomizado” una variable métrica, la hemos transformado en una variable con dos categorías: <em>mayores de 65</em> y <em>65 o menos</em>. De mismo modo que se definen como promocionados, quienes tienen notas 7 o mayores. Se trata de dicotomías artificiales.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref90" class="footnote-back">↩︎</a></p></li>
<li id="fn91"><p>Es un ejemplo incompleto porque no hay grupo control, por lo que no es seguro que los cambios observados se deban a la intervención terapéutica o a otros factores.<a href="prueba-de-hipótesis-las-aplicaciones.html#fnref91" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="prueba-de-hipótesis-la-lógica.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cuando-los-supuestos-no-se-cumplen.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/jcrodriguez1989/EstadisticaParaCienciasSocialesConR/edit/master/13-capitulo12.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["EstadisticaParaCienciasSocialesConR.pdf", "EstadisticaParaCienciasSocialesConR.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
